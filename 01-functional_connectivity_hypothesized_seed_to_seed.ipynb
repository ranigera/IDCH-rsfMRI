{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES:\n",
    "\n",
    "- This is like what Cadence was wroking on, but after normalization etc and without correlation to behavior (and do sub-group analysis, logistic regression). So these need to be added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dirs:\n",
    "rs_data_path_IDCH_sub_Nums_normed_concat = 'data/pre_proc_data_IDCH_subNums_normed_concat' # Here each voxel time series will be normed and concatenated\n",
    "masks_dir = 'masks'\n",
    "connectiviity_data_dir = 'data/connectivity_data'\n",
    "time_series_dir = 'data/time_series'\n",
    "\n",
    "# file_format:\n",
    "any_session_file_format = '_space-MNI152NLin6Asym_desc-smoothAROMAnonaggr_bold.nii.gz'\n",
    "\n",
    "# R01 to IDCH mapping:\n",
    "mapping_R01_to_IDCH = {'222': '101', '183': '102', '216': '103', '192': '104', '251': '105', '206': '106', '180': '107', '184': '108', '169': '109', '207': '110',\n",
    "                       '159': '111', '115': '112', '114': '113', '232': '114', '173': '115', '171': '117', '215': '118', '265': '119', '177': '120', '269': '121',\n",
    "                       '261': '122'}\n",
    "\n",
    "mapping_R01_to_IDCH_more = {'094': '123', '253': '124', '247': '125', '233': '126', '229': '127', '246': '128', '214': '129', '205': '130', '234': '131', '230': '132',\n",
    "                                        '218': '133', '213': '134', '237': '135', '129': '136', '126': '137', '228': '138', '141': '139', '197': '140', '202': '141', '196': '142',\n",
    "                                        '181': '143', '189': '144', '142': '145', '176': '148', '163': '149', '099': '152', '052': '153', '063': '154', '082': '155'}\n",
    "\n",
    "# concatenate the two mappings:\n",
    "mapping_R01_to_IDCH.update(mapping_R01_to_IDCH_more)\n",
    "# masks: * mask files should end with _mask.nii.gz\n",
    "masks_to_apply = ['L_SMA_mask.nii.gz', 'R_SMA_mask.nii.gz', 'L_post_putamen_mask.nii.gz', 'R_post_putamen_mask.nii.gz', 'R_premotor_mask.nii.gz', 'L_premotor_mask.nii.gz', 'L_anterior_caudate_mask.nii.gz', 'R_anterior_caudate_mask.nii.gz', 'vmpfc_mask.nii.gz', 'L_vlpfc_mask.nii.gz', 'R_vlpfc_mask.nii.gz', 'L_anterior_putamen_mask.nii.gz', 'R_anterior_putamen_mask.nii.gz', 'R_frontopolar_mask.nii.gz']\n",
    "\n",
    "# regions to test connectivity between: * add pairs of regions to test connectivity between\n",
    "connectivity_regions = [['L_SMA', 'L_post_putamen'], ['R_SMA', 'R_post_putamen'], ['L_premotor', 'L_post_putamen'], ['R_premotor', 'R_post_putamen'], ['L_anterior_caudate', 'vmpfc'], ['R_anterior_caudate', 'vmpfc'], ['L_vlpfc', 'L_post_putamen'], ['R_vlpfc', 'R_post_putamen'], ['L_vlpfc', 'L_anterior_putamen'], ['R_vlpfc', 'R_anterior_putamen'], ['L_vlpfc', 'L_anterior_caudate'], ['R_vlpfc', 'R_anterior_caudate'], ['R_frontopolar', 'R_anterior_caudate'], ['R_frontopolar', 'R_post_putamen'], ['R_post_putamen', 'L_post_putamen'], ['R_anterior_caudate', 'L_anterior_caudate']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create IDCH sub id folders + Extract time series using masks (directly from the data) for each session separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Processing sub-101\n",
      ">> Processing sub-102\n",
      ">> Processing sub-103\n",
      ">> Processing sub-104\n",
      ">> Processing sub-105\n",
      ">> Processing sub-106\n",
      ">> Processing sub-107\n",
      ">> Processing sub-108\n",
      ">> Processing sub-109\n",
      ">> Processing sub-110\n",
      ">> Processing sub-111\n",
      ">> Processing sub-112\n",
      ">> Processing sub-113\n",
      ">> Processing sub-114\n",
      ">> Processing sub-115\n",
      ">> Processing sub-117\n",
      ">> Processing sub-118\n",
      ">> Processing sub-119\n",
      ">> Processing sub-120\n",
      ">> Processing sub-121\n",
      ">> Processing sub-122\n",
      ">> Processing sub-123\n",
      ">> Processing sub-124\n",
      ">> Processing sub-125\n",
      ">> Processing sub-126\n",
      ">> Processing sub-127\n",
      ">> Processing sub-128\n",
      ">> Processing sub-129\n",
      ">> Processing sub-130\n",
      ">> Processing sub-131\n",
      ">> Processing sub-132\n",
      ">> Processing sub-133\n",
      ">> Processing sub-134\n",
      ">> Processing sub-135\n",
      ">> Processing sub-136\n",
      ">> Processing sub-137\n",
      ">> Processing sub-138\n",
      ">> Processing sub-139\n",
      ">> Processing sub-140\n",
      ">> Processing sub-141\n",
      ">> Processing sub-142\n",
      ">> Processing sub-143\n",
      ">> Processing sub-144\n",
      ">> Processing sub-145\n",
      ">> Processing sub-148\n",
      ">> Processing sub-149\n",
      ">> Processing sub-152\n",
      ">> Processing sub-153\n",
      ">> Processing sub-154\n",
      ">> Processing sub-155\n"
     ]
    }
   ],
   "source": [
    "# get all directories in the root directory\n",
    "subs_files = os.listdir(rs_data_path_IDCH_sub_Nums_normed_concat)\n",
    "subs_files = [f for f in subs_files if f.endswith('.nii.gz')]\n",
    "subs_files.sort()\n",
    "subs_files\n",
    "\n",
    "for sub_file in subs_files:    \n",
    "    # get sub (IDCH) id:\n",
    "    sub_id = sub_file.split('_')[0].split('-')[1]\n",
    "    print(f'>> Processing sub-{sub_id}')\n",
    "\n",
    "    # create a new foler for the sub according to sub_id:\n",
    "    sub_ts_dir = os.path.join(time_series_dir, 'sub-' + sub_id)\n",
    "    if not os.path.exists(sub_ts_dir):\n",
    "        os.makedirs(sub_ts_dir)\n",
    "\n",
    "    for mask in masks_to_apply:\n",
    "        mask_name = mask.split('_mask')[0]\n",
    "        input_file = os.path.join(rs_data_path_IDCH_sub_Nums_normed_concat, sub_file)\n",
    "        output_file = os.path.join(sub_ts_dir, f\"sub-{sub_id}_IDCH_{mask_name}_time_series.txt\")\n",
    "        if os.path.exists(output_file):\n",
    "            continue\n",
    "        print(f'>> Extracting time series for sub-{sub_id}, using {mask}:')\n",
    "        # fslmeants -i <input_file> -o <output_file> -m <mask_file>\n",
    "        os.system(f'fslmeants -i {input_file} -o {output_file} -m {os.path.join(masks_dir, mask)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate correlations (connectivity) and plot each subject's timeseries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing connectivity between L_SMA and L_post_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between L_SMA and L_post_putamen: r=0.6917043630972877, p=1.5139927139354282e-171, z-score=0.8512163079608521\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between L_SMA and L_post_putamen: r=0.6485072876694717, p=3.9040880115265387e-144, z-score=0.7727182526556606\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between L_SMA and L_post_putamen: r=0.6538507099040197, p=2.784511153356039e-147, z-score=0.7819957276054\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between L_SMA and L_post_putamen: r=0.6016496239526503, p=4.7583633557760423e-119, z-score=0.6957287161145137\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between L_SMA and L_post_putamen: r=0.4384188305117284, p=1.5511867074253952e-57, z-score=0.47027171644291077\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between L_SMA and L_post_putamen: r=0.5378816811456433, p=6.095912912642107e-91, z-score=0.6011701285310708\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between L_SMA and L_post_putamen: r=0.6843867948612963, p=1.4438058360498684e-166, z-score=0.8373197135570593\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between L_SMA and L_post_putamen: r=0.6659234611832552, p=1.241240135692048e-154, z-score=0.8033823775733857\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between L_SMA and L_post_putamen: r=0.5775233773541539, p=1.1057186757856594e-107, z-score=0.6587386496484189\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between L_SMA and L_post_putamen: r=0.7207019815478843, p=7.706648978113806e-193, z-score=0.9091041185600001\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between L_SMA and L_post_putamen: r=0.6598348867374744, p=6.978445931858144e-151, z-score=0.7925211418042778\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between L_SMA and L_post_putamen: r=0.29655781898515, p=8.689463300308102e-26, z-score=0.3057412573143871\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between L_SMA and L_post_putamen: r=0.5456027495585145, p=4.994673059709524e-94, z-score=0.6120987129958719\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between L_SMA and L_post_putamen: r=0.5194737273621897, p=6.743308424881698e-84, z-score=0.5756187086339444\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between L_SMA and L_post_putamen: r=0.6695949113917917, p=6.157589443230914e-157, z-score=0.8100084325363825\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between L_SMA and L_post_putamen: r=0.6291213635132924, p=3.1138986796429917e-133, z-score=0.7399606119795988\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between L_SMA and L_post_putamen: r=0.5478357883868261, p=6.176625398920121e-95, z-score=0.6152837773927173\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between L_SMA and L_post_putamen: r=0.618066791254943, p=2.346053533375081e-127, z-score=0.7218708148986078\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between L_SMA and L_post_putamen: r=0.6146582794452623, p=1.3660300474604906e-125, z-score=0.7163740475602365\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between L_SMA and L_post_putamen: r=0.7301960529260628, p=2.0696223911349924e-200, z-score=0.9291472165830048\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between L_SMA and L_post_putamen: r=0.5564263546960884, p=1.7135715668349117e-98, z-score=0.6276419156575443\n",
      "Analyzing subject 123\n",
      ">> Subject 123: correlation between L_SMA and L_post_putamen: r=0.27125819057744777, p=1.1027016382292622e-21, z-score=0.2782214459434607\n",
      "Analyzing subject 124\n",
      ">> Subject 124: correlation between L_SMA and L_post_putamen: r=0.5665510328126627, p=8.058403871390612e-103, z-score=0.6424288104617816\n",
      "Analyzing subject 125\n",
      ">> Subject 125: correlation between L_SMA and L_post_putamen: r=0.261114783351074, p=3.720501799338155e-20, z-score=0.26730438556246117\n",
      "Analyzing subject 126\n",
      ">> Subject 126: correlation between L_SMA and L_post_putamen: r=0.5787272668622031, p=3.15382108537814e-108, z-score=0.6605469139954722\n",
      "Analyzing subject 127\n",
      ">> Subject 127: correlation between L_SMA and L_post_putamen: r=0.7267904301018703, p=1.1707875135165886e-197, z-score=0.921890282844519\n",
      "Analyzing subject 128\n",
      ">> Subject 128: correlation between L_SMA and L_post_putamen: r=0.7336120129682355, p=3.253151951402077e-203, z-score=0.9365042678828942\n",
      "Analyzing subject 129\n",
      ">> Subject 129: correlation between L_SMA and L_post_putamen: r=0.2995683567878444, p=2.644205851256964e-26, z-score=0.30904533845537413\n",
      "Analyzing subject 130\n",
      ">> Subject 130: correlation between L_SMA and L_post_putamen: r=0.4559478762197303, p=1.1894702915437082e-62, z-score=0.492183685388863\n",
      "Analyzing subject 131\n",
      ">> Subject 131: correlation between L_SMA and L_post_putamen: r=0.7111106568089012, p=1.6675992959776326e-185, z-score=0.889427113153742\n",
      "Analyzing subject 132\n",
      ">> Subject 132: correlation between L_SMA and L_post_putamen: r=0.5705524006003715, p=1.426206605679778e-104, z-score=0.6483414768597844\n",
      "Analyzing subject 133\n",
      ">> Subject 133: correlation between L_SMA and L_post_putamen: r=0.5194829995984637, p=6.690106270369759e-84, z-score=0.5756314078532127\n",
      "Analyzing subject 134\n",
      ">> Subject 134: correlation between L_SMA and L_post_putamen: r=0.4401779757462566, p=4.905922028023743e-58, z-score=0.47245152990903144\n",
      "Analyzing subject 135\n",
      ">> Subject 135: correlation between L_SMA and L_post_putamen: r=0.8103252608568876, p=2.386001230399106e-280, z-score=1.127975552153254\n",
      "Analyzing subject 136\n",
      ">> Subject 136: correlation between L_SMA and L_post_putamen: r=0.5500888814612193, p=7.376849437874437e-96, z-score=0.6185087511249437\n",
      "Analyzing subject 137\n",
      ">> Subject 137: correlation between L_SMA and L_post_putamen: r=0.4528585704320597, p=9.970296688822855e-62, z-score=0.48829049930693147\n",
      "Analyzing subject 138\n",
      ">> Subject 138: correlation between L_SMA and L_post_putamen: r=0.7253936934418221, p=1.532326135465416e-196, z-score=0.9189360360465202\n",
      "Analyzing subject 139\n",
      ">> Subject 139: correlation between L_SMA and L_post_putamen: r=0.6120983474977582, p=2.7988666742526183e-124, z-score=0.7122700481291714\n",
      "Analyzing subject 140\n",
      ">> Subject 140: correlation between L_SMA and L_post_putamen: r=0.5087692130459616, p=5.372746096877456e-80, z-score=0.5610677274256929\n",
      "Analyzing subject 141\n",
      ">> Subject 141: correlation between L_SMA and L_post_putamen: r=0.7002810397745238, p=1.414803009625476e-177, z-score=0.8678517987790809\n",
      "Analyzing subject 142\n",
      ">> Subject 142: correlation between L_SMA and L_post_putamen: r=0.5686315487937054, p=9.960046728332722e-104, z-score=0.6454981465947891\n",
      "Analyzing subject 143\n",
      ">> Subject 143: correlation between L_SMA and L_post_putamen: r=0.8130573944315986, p=9.865087970181378e-284, z-score=1.1359841098819046\n",
      "Analyzing subject 144\n",
      ">> Subject 144: correlation between L_SMA and L_post_putamen: r=0.6917361853040572, p=1.4392759664431549e-171, z-score=0.8512773257932289\n",
      "Analyzing subject 145\n",
      ">> Subject 145: correlation between L_SMA and L_post_putamen: r=0.666451125882985, p=5.8168114701052935e-155, z-score=0.8043310831099352\n",
      "Analyzing subject 148\n",
      ">> Subject 148: correlation between L_SMA and L_post_putamen: r=0.4097371887431167, p=8.675678603462081e-50, z-score=0.43529534725454266\n",
      "Analyzing subject 149\n",
      ">> Subject 149: correlation between L_SMA and L_post_putamen: r=0.6035916829576912, p=5.247395509928974e-120, z-score=0.6987782052992985\n",
      "Analyzing subject 152\n",
      ">> Subject 152: correlation between L_SMA and L_post_putamen: r=0.6957153608573335, p=2.4375942537033886e-174, z-score=0.8589481981378699\n",
      "Analyzing subject 153\n",
      ">> Subject 153: correlation between L_SMA and L_post_putamen: r=0.33470326015714424, p=8.449052730787291e-33, z-score=0.3481155513183794\n",
      "Analyzing subject 154\n",
      ">> Subject 154: correlation between L_SMA and L_post_putamen: r=0.5738994443216981, p=4.677479314215027e-106, z-score=0.6533180884456222\n",
      "Analyzing subject 155\n",
      ">> Subject 155: correlation between L_SMA and L_post_putamen: r=0.40035404690089205, p=2.059789975974621e-47, z-score=0.42407048569602107\n",
      "Analyzing connectivity between R_SMA and R_post_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_SMA and R_post_putamen: r=0.7610811323135442, p=1.882716708009886e-227, z-score=0.9987795753051586\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_SMA and R_post_putamen: r=0.6399933351631615, p=2.99465826089226e-139, z-score=0.7581624560853191\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_SMA and R_post_putamen: r=0.7780596489713812, p=3.843676661596852e-244, z-score=1.0404346535776718\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_SMA and R_post_putamen: r=0.5494492899166854, p=1.3507249746350796e-95, z-score=0.6175921076180082\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_SMA and R_post_putamen: r=0.374388041954525, p=3.172032821600829e-41, z-score=0.39351677353197473\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_SMA and R_post_putamen: r=0.5656909470851711, p=1.9042533151471714e-102, z-score=0.6411630605557247\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_SMA and R_post_putamen: r=0.6188107313890693, p=9.598192427194254e-128, z-score=0.7230755112092496\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_SMA and R_post_putamen: r=0.7557516119129487, p=1.6925640096344236e-222, z-score=0.9862333108265291\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_SMA and R_post_putamen: r=0.6113830649289507, p=6.475797803349419e-124, z-score=0.7111270100280555\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_SMA and R_post_putamen: r=0.7098185755745887, p=1.5391532723939232e-184, z-score=0.8868181094362322\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_SMA and R_post_putamen: r=0.7387590197378222, p=1.603087354800319e-207, z-score=0.9477418266687186\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_SMA and R_post_putamen: r=0.4162097031610654, p=1.7983602106033035e-51, z-score=0.4430987605766498\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_SMA and R_post_putamen: r=0.48695520807787046, p=1.8341041400682018e-72, z-score=0.5320613343086203\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_SMA and R_post_putamen: r=0.6615838747756515, p=5.964712875258451e-152, z-score=0.7956251449545709\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_SMA and R_post_putamen: r=0.5862533206001185, p=1.0989541738471904e-111, z-score=0.6719381056759449\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_SMA and R_post_putamen: r=0.7614232898431278, p=8.960023194279943e-228, z-score=0.9995932770695227\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_SMA and R_post_putamen: r=0.5694949325416918, p=4.164411653289269e-104, z-score=0.6467750263350743\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_SMA and R_post_putamen: r=0.8444217462057815, p=0.0, z-score=1.2363861228939632\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_SMA and R_post_putamen: r=0.413109213949777, p=1.1638405119511312e-50, z-score=0.4393544619295529\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_SMA and R_post_putamen: r=0.7600716618057524, p=1.6711998434379885e-226, z-score=0.9963847581204041\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_SMA and R_post_putamen: r=0.6135889833539686, p=4.839000183603855e-125, z-score=0.7146572731624768\n",
      "Analyzing subject 123\n",
      ">> Subject 123: correlation between R_SMA and R_post_putamen: r=0.4881555568791608, p=7.293249292559327e-73, z-score=0.5336359969978989\n",
      "Analyzing subject 124\n",
      ">> Subject 124: correlation between R_SMA and R_post_putamen: r=0.6321467523245442, p=6.967984238186199e-135, z-score=0.7449836890528915\n",
      "Analyzing subject 125\n",
      ">> Subject 125: correlation between R_SMA and R_post_putamen: r=0.27946239202605205, p=5.727281423819854e-23, z-score=0.2870988256650687\n",
      "Analyzing subject 126\n",
      ">> Subject 126: correlation between R_SMA and R_post_putamen: r=0.5938980979174506, p=2.719552567447546e-115, z-score=0.6836669051565097\n",
      "Analyzing subject 127\n",
      ">> Subject 127: correlation between R_SMA and R_post_putamen: r=0.6212946965304339, p=4.770850014812857e-129, z-score=0.7271109826053181\n",
      "Analyzing subject 128\n",
      ">> Subject 128: correlation between R_SMA and R_post_putamen: r=0.6132696447138983, p=7.053271537656214e-125, z-score=0.7141452700153782\n",
      "Analyzing subject 129\n",
      ">> Subject 129: correlation between R_SMA and R_post_putamen: r=0.618512552695033, p=1.373689424975419e-127, z-score=0.7225924412185634\n",
      "Analyzing subject 130\n",
      ">> Subject 130: correlation between R_SMA and R_post_putamen: r=0.5568466847101918, p=1.1407573784672365e-98, z-score=0.6282509521219912\n",
      "Analyzing subject 131\n",
      ">> Subject 131: correlation between R_SMA and R_post_putamen: r=0.632200138543515, p=6.513622269950928e-135, z-score=0.7450726132140539\n",
      "Analyzing subject 132\n",
      ">> Subject 132: correlation between R_SMA and R_post_putamen: r=0.4339499238959841, p=2.8025242267122383e-56, z-score=0.46475277600178805\n",
      "Analyzing subject 133\n",
      ">> Subject 133: correlation between R_SMA and R_post_putamen: r=0.5735263220446949, p=6.859815890211607e-106, z-score=0.652761898039326\n",
      "Analyzing subject 134\n",
      ">> Subject 134: correlation between R_SMA and R_post_putamen: r=0.7407516140052957, p=3.235333706672219e-209, z-score=0.9521428197964559\n",
      "Analyzing subject 135\n",
      ">> Subject 135: correlation between R_SMA and R_post_putamen: r=0.6984225060928702, p=2.9886658104529942e-176, z-score=0.8642140753128444\n",
      "Analyzing subject 136\n",
      ">> Subject 136: correlation between R_SMA and R_post_putamen: r=0.7231880317526247, p=8.610781800289054e-195, z-score=0.914296450159775\n",
      "Analyzing subject 137\n",
      ">> Subject 137: correlation between R_SMA and R_post_putamen: r=0.24771446301323824, p=3.0871281426425616e-18, z-score=0.2529763858843044\n",
      "Analyzing subject 138\n",
      ">> Subject 138: correlation between R_SMA and R_post_putamen: r=0.7156119174809353, p=6.569575959164354e-189, z-score=0.8985926530235554\n",
      "Analyzing subject 139\n",
      ">> Subject 139: correlation between R_SMA and R_post_putamen: r=0.7543204780427292, p=3.4438822420638665e-221, z-score=0.9829044692934561\n",
      "Analyzing subject 140\n",
      ">> Subject 140: correlation between R_SMA and R_post_putamen: r=0.6656365473914767, p=1.8730814778940778e-154, z-score=0.8028670286494888\n",
      "Analyzing subject 141\n",
      ">> Subject 141: correlation between R_SMA and R_post_putamen: r=0.8273253646350143, p=2.3571742177162394e-302, z-score=1.179599762030823\n",
      "Analyzing subject 142\n",
      ">> Subject 142: correlation between R_SMA and R_post_putamen: r=0.6689505033301701, p=1.5713690844677662e-156, z-score=0.8088411828874191\n",
      "Analyzing subject 143\n",
      ">> Subject 143: correlation between R_SMA and R_post_putamen: r=0.8360203492067642, p=1.4522771016e-314, z-score=1.207806657484221\n",
      "Analyzing subject 144\n",
      ">> Subject 144: correlation between R_SMA and R_post_putamen: r=0.7834748101874477, p=8.847851590452859e-250, z-score=1.0543059950214064\n",
      "Analyzing subject 145\n",
      ">> Subject 145: correlation between R_SMA and R_post_putamen: r=0.5809074709107087, p=3.209316028050005e-109, z-score=0.6638312905664241\n",
      "Analyzing subject 148\n",
      ">> Subject 148: correlation between R_SMA and R_post_putamen: r=0.30894720610125026, p=5.928615170584617e-28, z-score=0.31938110530249036\n",
      "Analyzing subject 149\n",
      ">> Subject 149: correlation between R_SMA and R_post_putamen: r=0.5750744302325982, p=1.3961163800306276e-106, z-score=0.6550718919026806\n",
      "Analyzing subject 152\n",
      ">> Subject 152: correlation between R_SMA and R_post_putamen: r=0.16225779353849845, p=1.582108286193206e-08, z-score=0.16370467123793608\n",
      "Analyzing subject 153\n",
      ">> Subject 153: correlation between R_SMA and R_post_putamen: r=0.5392181170759519, p=1.8051760933346505e-91, z-score=0.6030525291270176\n",
      "Analyzing subject 154\n",
      ">> Subject 154: correlation between R_SMA and R_post_putamen: r=0.5101377009879897, p=1.7344432519095732e-80, z-score=0.5629158945862216\n",
      "Analyzing subject 155\n",
      ">> Subject 155: correlation between R_SMA and R_post_putamen: r=0.47180508525636067, p=1.5263983686431984e-67, z-score=0.5123897516588524\n",
      "Analyzing connectivity between L_premotor and L_post_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between L_premotor and L_post_putamen: r=0.6400618272610794, p=2.7394782096959465e-139, z-score=0.7582784726741087\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between L_premotor and L_post_putamen: r=0.6551294619826868, p=4.810211650164944e-148, z-score=0.7842327075158929\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between L_premotor and L_post_putamen: r=0.6974780994929186, p=1.3955589083216507e-175, z-score=0.8623726422523229\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between L_premotor and L_post_putamen: r=0.4781014157786554, p=1.475056756287739e-69, z-score=0.5205202150740318\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between L_premotor and L_post_putamen: r=0.4405537309115151, p=3.83310200236708e-58, z-score=0.472917682335398\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between L_premotor and L_post_putamen: r=0.5608304639164357, p=2.3430421391821985e-100, z-score=0.6340438908790014\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between L_premotor and L_post_putamen: r=0.7261163567314034, p=4.0583855868734584e-197, z-score=0.9204629634385755\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between L_premotor and L_post_putamen: r=0.7346710562714298, p=4.307987354068428e-204, z-score=0.9388013640879695\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between L_premotor and L_post_putamen: r=0.5539029562883352, p=1.947435503135138e-97, z-score=0.6239942830689028\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between L_premotor and L_post_putamen: r=0.6877602368810389, p=7.627083385805637e-169, z-score=0.8436931305416662\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between L_premotor and L_post_putamen: r=0.7625787751610502, p=7.231935105854661e-229, z-score=1.0023486726239994\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between L_premotor and L_post_putamen: r=0.3408346695081536, p=5.043699380353784e-34, z-score=0.3550366014093385\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between L_premotor and L_post_putamen: r=0.5558859064021396, p=2.8889421376233218e-98, z-score=0.6268594400655554\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between L_premotor and L_post_putamen: r=0.5719534260281096, p=3.427743934691778e-105, z-score=0.6504211689943808\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between L_premotor and L_post_putamen: r=0.6339431130342448, p=7.154129237672455e-136, z-score=0.7479813550388236\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between L_premotor and L_post_putamen: r=0.8068178838799569, p=4.380766591053842e-276, z-score=1.1178445755000526\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between L_premotor and L_post_putamen: r=0.5223068471741249, p=5.926726184541703e-85, z-score=0.5795067696518653\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between L_premotor and L_post_putamen: r=0.7888447166325706, p=1.5595257904058847e-255, z-score=1.0683657389154542\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between L_premotor and L_post_putamen: r=0.5972950506251478, p=6.319428853096383e-117, z-score=0.6889313629723322\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between L_premotor and L_post_putamen: r=0.7174549935386261, p=2.5369599624059225e-190, z-score=0.9023804831564859\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between L_premotor and L_post_putamen: r=0.5151239426830262, p=2.697581594560376e-82, z-score=0.5696796092971285\n",
      "Analyzing subject 123\n",
      ">> Subject 123: correlation between L_premotor and L_post_putamen: r=0.2762831046973336, p=1.8235413833769724e-22, z-score=0.28365351042695314\n",
      "Analyzing subject 124\n",
      ">> Subject 124: correlation between L_premotor and L_post_putamen: r=0.49534905045223815, p=2.6858046090228387e-75, z-score=0.5431239679282529\n",
      "Analyzing subject 125\n",
      ">> Subject 125: correlation between L_premotor and L_post_putamen: r=0.2822481526546824, p=2.0502131924333514e-23, z-score=0.2901231463819642\n",
      "Analyzing subject 126\n",
      ">> Subject 126: correlation between L_premotor and L_post_putamen: r=0.6424787951726404, p=1.1651806812827872e-140, z-score=0.7623835828026099\n",
      "Analyzing subject 127\n",
      ">> Subject 127: correlation between L_premotor and L_post_putamen: r=0.8149273372490262, p=4.426160721008349e-286, z-score=1.1415260958666902\n",
      "Analyzing subject 128\n",
      ">> Subject 128: correlation between L_premotor and L_post_putamen: r=0.7118944460668359, p=4.305200050377122e-186, z-score=0.8910144898824924\n",
      "Analyzing subject 129\n",
      ">> Subject 129: correlation between L_premotor and L_post_putamen: r=0.3628131726789323, p=1.2126802196038139e-38, z-score=0.3801217232824919\n",
      "Analyzing subject 130\n",
      ">> Subject 130: correlation between L_premotor and L_post_putamen: r=0.47035317073929506, p=4.388818315168848e-67, z-score=0.5105237392880834\n",
      "Analyzing subject 131\n",
      ">> Subject 131: correlation between L_premotor and L_post_putamen: r=0.6803988191762186, p=6.484307922203858e-164, z-score=0.8298562640065076\n",
      "Analyzing subject 132\n",
      ">> Subject 132: correlation between L_premotor and L_post_putamen: r=0.7245799753437379, p=6.805188669909967e-196, z-score=0.9172207562202973\n",
      "Analyzing subject 133\n",
      ">> Subject 133: correlation between L_premotor and L_post_putamen: r=0.4915977323867593, p=5.076211108982628e-74, z-score=0.5381650642245084\n",
      "Analyzing subject 134\n",
      ">> Subject 134: correlation between L_premotor and L_post_putamen: r=0.38812166916798135, p=1.986586832335961e-44, z-score=0.4095866691046159\n",
      "Analyzing subject 135\n",
      ">> Subject 135: correlation between L_premotor and L_post_putamen: r=0.8593673974736202, p=0.0, z-score=1.2909203830323879\n",
      "Analyzing subject 136\n",
      ">> Subject 136: correlation between L_premotor and L_post_putamen: r=0.5072131150806831, p=1.9312627213746665e-79, z-score=0.5589704034663324\n",
      "Analyzing subject 137\n",
      ">> Subject 137: correlation between L_premotor and L_post_putamen: r=0.6051652533068241, p=8.694745382499106e-121, z-score=0.7012573386324601\n",
      "Analyzing subject 138\n",
      ">> Subject 138: correlation between L_premotor and L_post_putamen: r=0.7011042831985947, p=3.635733434107886e-178, z-score=0.8694690790980081\n",
      "Analyzing subject 139\n",
      ">> Subject 139: correlation between L_premotor and L_post_putamen: r=0.5123294899818651, p=2.8056707843992604e-81, z-score=0.5658832281146589\n",
      "Analyzing subject 140\n",
      ">> Subject 140: correlation between L_premotor and L_post_putamen: r=0.6333176229602087, p=1.5831119698604503e-135, z-score=0.746936280557966\n",
      "Analyzing subject 141\n",
      ">> Subject 141: correlation between L_premotor and L_post_putamen: r=0.7628851075584815, p=3.7018922957163954e-229, z-score=1.003081104829317\n",
      "Analyzing subject 142\n",
      ">> Subject 142: correlation between L_premotor and L_post_putamen: r=0.5358641572524763, p=3.788109383756352e-90, z-score=0.5983355982933621\n",
      "Analyzing subject 143\n",
      ">> Subject 143: correlation between L_premotor and L_post_putamen: r=0.82331479600258, p=5.96931552494391e-297, z-score=1.167020899654646\n",
      "Analyzing subject 144\n",
      ">> Subject 144: correlation between L_premotor and L_post_putamen: r=0.6594949790085297, p=1.1233599735990014e-150, z-score=0.7919193670664257\n",
      "Analyzing subject 145\n",
      ">> Subject 145: correlation between L_premotor and L_post_putamen: r=0.7626763853232078, p=5.842944174856889e-229, z-score=1.0025819669741618\n",
      "Analyzing subject 148\n",
      ">> Subject 148: correlation between L_premotor and L_post_putamen: r=0.48329652411378865, p=2.9810942694762056e-71, z-score=0.5272765543109402\n",
      "Analyzing subject 149\n",
      ">> Subject 149: correlation between L_premotor and L_post_putamen: r=0.4890296932724816, p=3.717541626396083e-73, z-score=0.5347842469448311\n",
      "Analyzing subject 152\n",
      ">> Subject 152: correlation between L_premotor and L_post_putamen: r=0.6385700927769812, p=1.8961179585803687e-138, z-score=0.7557555586577263\n",
      "Analyzing subject 153\n",
      ">> Subject 153: correlation between L_premotor and L_post_putamen: r=0.49021251881231465, p=1.4889730005098347e-73, z-score=0.5363400417622103\n",
      "Analyzing subject 154\n",
      ">> Subject 154: correlation between L_premotor and L_post_putamen: r=0.585580702857524, p=2.2579173796395746e-111, z-score=0.6709138684654042\n",
      "Analyzing subject 155\n",
      ">> Subject 155: correlation between L_premotor and L_post_putamen: r=0.4445045626098164, p=2.8089001096801787e-59, z-score=0.47783064149137866\n",
      "Analyzing connectivity between R_premotor and R_post_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_premotor and R_post_putamen: r=0.7964747529823595, p=5.270435048161046e-264, z-score=1.0888957459258315\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_premotor and R_post_putamen: r=0.7215135945601598, p=1.786500310901415e-193, z-score=0.9107949675000699\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_premotor and R_post_putamen: r=0.7661119804853787, p=3.004526502300746e-232, z-score=1.0108466682641353\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_premotor and R_post_putamen: r=0.5427929484621437, p=6.777088184423654e-93, z-score=0.608106650300139\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_premotor and R_post_putamen: r=0.4530505027495608, p=8.742148340761677e-62, z-score=0.48853197457926967\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_premotor and R_post_putamen: r=0.37149312924713607, p=1.4359333346382733e-40, z-score=0.39015417037302713\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_premotor and R_post_putamen: r=0.6665983513120847, p=4.706751737992872e-155, z-score=0.8045959986580501\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_premotor and R_post_putamen: r=0.7962165623025742, p=1.033717809813122e-263, z-score=1.0881899859424928\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_premotor and R_post_putamen: r=0.7028275649099258, p=2.0832430614287596e-179, z-score=0.8728664309793113\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_premotor and R_post_putamen: r=0.8048353234969492, p=1.0307600610818576e-273, z-score=1.1121904680096228\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_premotor and R_post_putamen: r=0.8659045925256917, p=0.0, z-score=1.3164748540069011\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_premotor and R_post_putamen: r=0.5031287027574323, p=5.378820084277629e-78, z-score=0.5534864916868101\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_premotor and R_post_putamen: r=0.402402435749123, p=6.334483532862158e-48, z-score=0.42651225626199246\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_premotor and R_post_putamen: r=0.6418213552835328, p=2.7581609110534877e-140, z-score=0.761264808770985\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_premotor and R_post_putamen: r=0.6733141905963438, p=2.6358375925975484e-159, z-score=0.8167813012873548\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_premotor and R_post_putamen: r=0.8149967715660419, p=3.616809652717926e-286, z-score=1.1417328460127256\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_premotor and R_post_putamen: r=0.5701519059773061, p=2.1410717904068923e-104, z-score=0.6477478862514564\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_premotor and R_post_putamen: r=0.8938426675847464, p=0.0, z-score=1.4407204698475777\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_premotor and R_post_putamen: r=0.7611828301479613, p=1.5100587481934302e-227, z-score=0.999021322698344\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_premotor and R_post_putamen: r=0.7814688087367185, p=1.1328721751962922e-247, z-score=1.0491323601703395\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_premotor and R_post_putamen: r=0.6497150797558938, p=7.687851890968665e-145, z-score=0.7748054959448442\n",
      "Analyzing subject 123\n",
      ">> Subject 123: correlation between R_premotor and R_post_putamen: r=0.5209259316572872, p=1.9444864508974107e-84, z-score=0.5776096886429568\n",
      "Analyzing subject 124\n",
      ">> Subject 124: correlation between R_premotor and R_post_putamen: r=0.5883070380079154, p=1.2066179470740762e-112, z-score=0.6750730691753177\n",
      "Analyzing subject 125\n",
      ">> Subject 125: correlation between R_premotor and R_post_putamen: r=0.22740217626651954, p=1.5371166998923655e-15, z-score=0.23144826480219532\n",
      "Analyzing subject 126\n",
      ">> Subject 126: correlation between R_premotor and R_post_putamen: r=0.7595350151449533, p=5.311463648038083e-226, z-score=0.9951151856790671\n",
      "Analyzing subject 127\n",
      ">> Subject 127: correlation between R_premotor and R_post_putamen: r=0.6617516024019692, p=4.707315733975186e-152, z-score=0.7959234887488302\n",
      "Analyzing subject 128\n",
      ">> Subject 128: correlation between R_premotor and R_post_putamen: r=0.7264221474171859, p=2.310158014065951e-197, z-score=0.9211100943913243\n",
      "Analyzing subject 129\n",
      ">> Subject 129: correlation between R_premotor and R_post_putamen: r=0.6350424108309554, p=1.763460550328854e-136, z-score=0.7498214347835289\n",
      "Analyzing subject 130\n",
      ">> Subject 130: correlation between R_premotor and R_post_putamen: r=0.463682371464699, p=5.267065583299512e-65, z-score=0.5019920677454192\n",
      "Analyzing subject 131\n",
      ">> Subject 131: correlation between R_premotor and R_post_putamen: r=0.7113253165304737, p=1.151391192137415e-185, z-score=0.8898614984363873\n",
      "Analyzing subject 132\n",
      ">> Subject 132: correlation between R_premotor and R_post_putamen: r=0.7566218201443233, p=2.6820048440240614e-223, z-score=0.9882656469710167\n",
      "Analyzing subject 133\n",
      ">> Subject 133: correlation between R_premotor and R_post_putamen: r=0.6768194815707554, p=1.434432736179899e-161, z-score=0.8232215323347194\n",
      "Analyzing subject 134\n",
      ">> Subject 134: correlation between R_premotor and R_post_putamen: r=0.7076956980257625, p=5.775421653449249e-183, z-score=0.8825524030253875\n",
      "Analyzing subject 135\n",
      ">> Subject 135: correlation between R_premotor and R_post_putamen: r=0.8009590480157425, p=3.733610984702618e-269, z-score=1.1012820070145335\n",
      "Analyzing subject 136\n",
      ">> Subject 136: correlation between R_premotor and R_post_putamen: r=0.6577737527609154, p=1.2398728662336807e-149, z-score=0.7888794042421031\n",
      "Analyzing subject 137\n",
      ">> Subject 137: correlation between R_premotor and R_post_putamen: r=0.7231598860521486, p=9.062745566101538e-195, z-score=0.9142374469011818\n",
      "Analyzing subject 138\n",
      ">> Subject 138: correlation between R_premotor and R_post_putamen: r=0.732183433944444, p=4.898329719536817e-202, z-score=0.933417850555175\n",
      "Analyzing subject 139\n",
      ">> Subject 139: correlation between R_premotor and R_post_putamen: r=0.799666520687335, p=1.1746419081088418e-267, z-score=1.097686642943252\n",
      "Analyzing subject 140\n",
      ">> Subject 140: correlation between R_premotor and R_post_putamen: r=0.7870087168530167, p=1.5101893141691253e-253, z-score=1.0635235761968365\n",
      "Analyzing subject 141\n",
      ">> Subject 141: correlation between R_premotor and R_post_putamen: r=0.8574163604776793, p=0.0, z-score=1.2835064880153835\n",
      "Analyzing subject 142\n",
      ">> Subject 142: correlation between R_premotor and R_post_putamen: r=0.6429651557073466, p=6.151143759418649e-141, z-score=0.763212265004833\n",
      "Analyzing subject 143\n",
      ">> Subject 143: correlation between R_premotor and R_post_putamen: r=0.8546310280120301, p=0.0, z-score=1.2730829519024038\n",
      "Analyzing subject 144\n",
      ">> Subject 144: correlation between R_premotor and R_post_putamen: r=0.7313560082209255, p=2.3373340539585154e-201, z-score=0.9316365739071114\n",
      "Analyzing subject 145\n",
      ">> Subject 145: correlation between R_premotor and R_post_putamen: r=0.8085456948390961, p=3.565365135066383e-278, z-score=1.122814576489951\n",
      "Analyzing subject 148\n",
      ">> Subject 148: correlation between R_premotor and R_post_putamen: r=0.5771161902261812, p=1.6881086462356868e-107, z-score=0.6581279011665394\n",
      "Analyzing subject 149\n",
      ">> Subject 149: correlation between R_premotor and R_post_putamen: r=0.5504229355764129, p=5.375766254614197e-96, z-score=0.6189878751849978\n",
      "Analyzing subject 152\n",
      ">> Subject 152: correlation between R_premotor and R_post_putamen: r=0.6783408900363412, p=1.4591243864735978e-162, z-score=0.826034349462361\n",
      "Analyzing subject 153\n",
      ">> Subject 153: correlation between R_premotor and R_post_putamen: r=0.6101830438318354, p=2.632703229412465e-123, z-score=0.7092129287739672\n",
      "Analyzing subject 154\n",
      ">> Subject 154: correlation between R_premotor and R_post_putamen: r=0.49767286353051426, p=4.2691512289829195e-76, z-score=0.5462080921745518\n",
      "Analyzing subject 155\n",
      ">> Subject 155: correlation between R_premotor and R_post_putamen: r=0.5594153102187843, p=9.371770544229392e-100, z-score=0.631981771824575\n",
      "Analyzing connectivity between L_anterior_caudate and vmpfc\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between L_anterior_caudate and vmpfc: r=0.1587848364393173, p=3.2049835195165175e-08, z-score=0.16013985523262858\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between L_anterior_caudate and vmpfc: r=0.4600915342605163, p=6.635461820074931e-64, z-score=0.49742739506787315\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between L_anterior_caudate and vmpfc: r=0.6732355437923087, p=2.960476123659646e-159, z-score=0.8166374442044392\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between L_anterior_caudate and vmpfc: r=0.22859178523560464, p=1.0855635925763167e-15, z-score=0.2327031037731667\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between L_anterior_caudate and vmpfc: r=0.3985015878175411, p=5.941095407991e-47, z-score=0.42186637618256867\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between L_anterior_caudate and vmpfc: r=0.37017058715676526, p=2.847859554349868e-40, z-score=0.3886207588941623\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between L_anterior_caudate and vmpfc: r=0.25643047376516387, p=1.7956414206061846e-19, z-score=0.26228387429251077\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between L_anterior_caudate and vmpfc: r=0.7046773076469293, p=9.456382042503735e-181, z-score=0.8765312392737075\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between L_anterior_caudate and vmpfc: r=0.31292419753256456, p=1.1356615232592418e-28, z-score=0.32378375792625086\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between L_anterior_caudate and vmpfc: r=0.506645350676771, p=3.075116382262922e-79, z-score=0.5582062755164736\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between L_anterior_caudate and vmpfc: r=0.5798837947171709, p=9.4041839841427e-109, z-score=0.6622876117076449\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between L_anterior_caudate and vmpfc: r=0.21612836911093414, p=3.768850941870226e-14, z-score=0.21959117641205442\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between L_anterior_caudate and vmpfc: r=0.26898998077346614, p=2.4541135832766303e-21, z-score=0.27577470323177083\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between L_anterior_caudate and vmpfc: r=0.4108652722640035, p=4.441788020181364e-50, z-score=0.4366517830715416\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between L_anterior_caudate and vmpfc: r=0.5024004059031291, p=9.688704791332487e-78, z-score=0.5525118264604308\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between L_anterior_caudate and vmpfc: r=0.5822765178517663, p=7.574976474698001e-110, z-score=0.6659001177201075\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between L_anterior_caudate and vmpfc: r=0.3631095558248475, p=1.0445608410016404e-38, z-score=0.3804630766500066\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between L_anterior_caudate and vmpfc: r=0.5241536196466205, p=1.1995651964449928e-85, z-score=0.5820497298334557\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between L_anterior_caudate and vmpfc: r=0.26691980949391564, p=5.059525736504935e-21, z-score=0.2735443951795581\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between L_anterior_caudate and vmpfc: r=0.15998171232076422, p=2.5171724992244e-08, z-score=0.16136792804416716\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between L_anterior_caudate and vmpfc: r=0.4379922783631877, p=2.0485480186320936e-57, z-score=0.46974378959713925\n",
      "Analyzing subject 123\n",
      ">> Subject 123: correlation between L_anterior_caudate and vmpfc: r=0.33499845848799975, p=7.387664810489564e-33, z-score=0.3484480287133602\n",
      "Analyzing subject 124\n",
      ">> Subject 124: correlation between L_anterior_caudate and vmpfc: r=0.3473581041817029, p=2.3435807093857583e-35, z-score=0.3624362069044168\n",
      "Analyzing subject 125\n",
      ">> Subject 125: correlation between L_anterior_caudate and vmpfc: r=0.2582563864113244, p=9.758827546461101e-20, z-score=0.2642392860319457\n",
      "Analyzing subject 126\n",
      ">> Subject 126: correlation between L_anterior_caudate and vmpfc: r=0.3881118423567913, p=1.9973523817036801e-44, z-score=0.4095750995123338\n",
      "Analyzing subject 127\n",
      ">> Subject 127: correlation between L_anterior_caudate and vmpfc: r=0.900978948253033, p=0.0, z-score=1.4773958984754463\n",
      "Analyzing subject 128\n",
      ">> Subject 128: correlation between L_anterior_caudate and vmpfc: r=0.6787676033062038, p=7.666867862123075e-163, z-score=0.8268251976594115\n",
      "Analyzing subject 129\n",
      ">> Subject 129: correlation between L_anterior_caudate and vmpfc: r=0.3567679755361909, p=2.459577088249641e-37, z-score=0.37317757795964157\n",
      "Analyzing subject 130\n",
      ">> Subject 130: correlation between L_anterior_caudate and vmpfc: r=0.24787789900190943, p=2.9297203105252455e-18, z-score=0.253150513843362\n",
      "Analyzing subject 131\n",
      ">> Subject 131: correlation between L_anterior_caudate and vmpfc: r=0.38469428144708884, p=1.2939312876177624e-43, z-score=0.4055577056044374\n",
      "Analyzing subject 132\n",
      ">> Subject 132: correlation between L_anterior_caudate and vmpfc: r=0.3022988602360489, p=8.878370943316075e-27, z-score=0.31204774561728565\n",
      "Analyzing subject 133\n",
      ">> Subject 133: correlation between L_anterior_caudate and vmpfc: r=0.31863268100249115, p=1.0133519874852167e-29, z-score=0.3301245442353693\n",
      "Analyzing subject 134\n",
      ">> Subject 134: correlation between L_anterior_caudate and vmpfc: r=0.37314733590270455, p=6.070403557015621e-41, z-score=0.39207459097613084\n",
      "Analyzing subject 135\n",
      ">> Subject 135: correlation between L_anterior_caudate and vmpfc: r=0.5514040478882162, p=2.1179159161983566e-96, z-score=0.6203965192859785\n",
      "Analyzing subject 136\n",
      ">> Subject 136: correlation between L_anterior_caudate and vmpfc: r=0.490731839647101, p=9.952415080444139e-74, z-score=0.5370238652279046\n",
      "Analyzing subject 137\n",
      ">> Subject 137: correlation between L_anterior_caudate and vmpfc: r=0.24447919053609782, p=8.631155005512251e-18, z-score=0.24953253761370775\n",
      "Analyzing subject 138\n",
      ">> Subject 138: correlation between L_anterior_caudate and vmpfc: r=0.5029281408416482, p=6.326029627963966e-78, z-score=0.5532179883243098\n",
      "Analyzing subject 139\n",
      ">> Subject 139: correlation between L_anterior_caudate and vmpfc: r=0.4414318852378464, p=2.1506197906022078e-58, z-score=0.4740078460048929\n",
      "Analyzing subject 140\n",
      ">> Subject 140: correlation between L_anterior_caudate and vmpfc: r=0.36229988777420613, p=1.5697445678142604e-38, z-score=0.37953075754295185\n",
      "Analyzing subject 141\n",
      ">> Subject 141: correlation between L_anterior_caudate and vmpfc: r=0.6893040846062956, p=6.757615635339307e-170, z-score=0.8466286345026306\n",
      "Analyzing subject 142\n",
      ">> Subject 142: correlation between L_anterior_caudate and vmpfc: r=0.3455791191883009, p=5.45143212901492e-35, z-score=0.36041453907168164\n",
      "Analyzing subject 143\n",
      ">> Subject 143: correlation between L_anterior_caudate and vmpfc: r=0.5748177724838878, p=1.8188680675961319e-106, z-score=0.6546884984505178\n",
      "Analyzing subject 144\n",
      ">> Subject 144: correlation between L_anterior_caudate and vmpfc: r=0.7853880491596676, p=8.238367097392309e-252, z-score=1.0592797737585073\n",
      "Analyzing subject 145\n",
      ">> Subject 145: correlation between L_anterior_caudate and vmpfc: r=0.15862579917973307, p=3.309080357140257e-08, z-score=0.1599767087403097\n",
      "Analyzing subject 148\n",
      ">> Subject 148: correlation between L_anterior_caudate and vmpfc: r=0.4135026568948786, p=9.192837566289296e-51, z-score=0.4398289593952239\n",
      "Analyzing subject 149\n",
      ">> Subject 149: correlation between L_anterior_caudate and vmpfc: r=0.37223299764805207, p=9.776052300248956e-41, z-score=0.39101276748214236\n",
      "Analyzing subject 152\n",
      ">> Subject 152: correlation between L_anterior_caudate and vmpfc: r=0.15527843427201216, p=6.436898969050187e-08, z-score=0.15654479874701624\n",
      "Analyzing subject 153\n",
      ">> Subject 153: correlation between L_anterior_caudate and vmpfc: r=0.46371526925250384, p=5.145497842154382e-65, z-score=0.5020339766413847\n",
      "Analyzing subject 154\n",
      ">> Subject 154: correlation between L_anterior_caudate and vmpfc: r=0.48018241191964917, p=3.115836770138222e-70, z-score=0.5232213262900313\n",
      "Analyzing subject 155\n",
      ">> Subject 155: correlation between L_anterior_caudate and vmpfc: r=0.048567277657017335, p=0.09263500078866378, z-score=0.04860551830756576\n",
      "Analyzing connectivity between R_anterior_caudate and vmpfc\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_anterior_caudate and vmpfc: r=0.16959983367386186, p=3.3825500034872843e-09, z-score=0.17125461703989006\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_anterior_caudate and vmpfc: r=0.36853151906026826, p=6.624546873300908e-40, z-score=0.3867227654594642\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_anterior_caudate and vmpfc: r=0.6863874933369694, p=6.497457668014107e-168, z-score=0.8410928867538\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_anterior_caudate and vmpfc: r=0.16525274320467664, p=8.502092399480485e-09, z-score=0.16678214843381223\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_anterior_caudate and vmpfc: r=0.33409938981853615, p=1.1114055819762485e-32, z-score=0.34743565168471\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_anterior_caudate and vmpfc: r=0.3684626051506642, p=6.86317150715464e-40, z-score=0.3866430233638902\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_anterior_caudate and vmpfc: r=0.32538239053790463, p=5.434320566035732e-31, z-score=0.337655133784539\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_anterior_caudate and vmpfc: r=0.7980492348177763, p=8.483747089775193e-266, z-score=1.0932168333939747\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_anterior_caudate and vmpfc: r=0.31875877014024484, p=9.601089676057994e-30, z-score=0.33026488762567385\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_anterior_caudate and vmpfc: r=0.5922331860308548, p=1.691110377612102e-114, z-score=0.6810986763444046\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_anterior_caudate and vmpfc: r=0.5822970330763783, p=7.412462888005752e-110, z-score=0.6659311570868994\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_anterior_caudate and vmpfc: r=0.23376430982840743, p=2.338545671064932e-16, z-score=0.23816768869630536\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_anterior_caudate and vmpfc: r=0.30362675103578296, p=5.1999352604223206e-27, z-score=0.3135098369044986\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_anterior_caudate and vmpfc: r=0.5334112774705008, p=3.433957820002086e-89, z-score=0.5949009679079024\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_anterior_caudate and vmpfc: r=0.48762681218862747, p=1.0953075361206941e-72, z-score=0.532942071849885\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_anterior_caudate and vmpfc: r=0.5080127608556451, p=1.001535335513311e-79, z-score=0.5600476155902414\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_anterior_caudate and vmpfc: r=0.33112642106118384, p=4.247956055356137e-32, z-score=0.34409286191199856\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_anterior_caudate and vmpfc: r=0.5793212722834905, p=1.69507563087737e-108, z-score=0.6614405169629591\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_anterior_caudate and vmpfc: r=0.17065905018538285, p=2.6923150785204957e-09, z-score=0.17234540547549737\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_anterior_caudate and vmpfc: r=0.27971495130698143, p=5.2204757878602303e-23, z-score=0.2873728015988338\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_anterior_caudate and vmpfc: r=0.4446439658226764, p=2.5598446958161114e-59, z-score=0.4780043843298785\n",
      "Analyzing subject 123\n",
      ">> Subject 123: correlation between R_anterior_caudate and vmpfc: r=0.3086098267027134, p=6.812917318302375e-28, z-score=0.3190081685532929\n",
      "Analyzing subject 124\n",
      ">> Subject 124: correlation between R_anterior_caudate and vmpfc: r=0.29226944722035936, p=4.61782058110299e-25, z-score=0.3010458834962307\n",
      "Analyzing subject 125\n",
      ">> Subject 125: correlation between R_anterior_caudate and vmpfc: r=0.2240594413811906, p=4.042098872626953e-15, z-score=0.22792605379088102\n",
      "Analyzing subject 126\n",
      ">> Subject 126: correlation between R_anterior_caudate and vmpfc: r=0.36183065855610486, p=1.9866094054682878e-38, z-score=0.37899073623405544\n",
      "Analyzing subject 127\n",
      ">> Subject 127: correlation between R_anterior_caudate and vmpfc: r=0.8729678506085646, p=0.0, z-score=1.3454196692042066\n",
      "Analyzing subject 128\n",
      ">> Subject 128: correlation between R_anterior_caudate and vmpfc: r=0.6293308961199534, p=2.396650688097479e-133, z-score=0.7403074775053612\n",
      "Analyzing subject 129\n",
      ">> Subject 129: correlation between R_anterior_caudate and vmpfc: r=0.41396143920651596, p=6.979429773339815e-51, z-score=0.44038249227700105\n",
      "Analyzing subject 130\n",
      ">> Subject 130: correlation between R_anterior_caudate and vmpfc: r=0.25961288376682773, p=6.184373463566459e-20, z-score=0.265693269087617\n",
      "Analyzing subject 131\n",
      ">> Subject 131: correlation between R_anterior_caudate and vmpfc: r=0.21484590749958238, p=5.36404498050598e-14, z-score=0.2182462639653653\n",
      "Analyzing subject 132\n",
      ">> Subject 132: correlation between R_anterior_caudate and vmpfc: r=0.662415421456982, p=1.8416267333802116e-152, z-score=0.7971054074584893\n",
      "Analyzing subject 133\n",
      ">> Subject 133: correlation between R_anterior_caudate and vmpfc: r=0.44828255231113734, p=2.233994671568321e-60, z-score=0.4825488208116516\n",
      "Analyzing subject 134\n",
      ">> Subject 134: correlation between R_anterior_caudate and vmpfc: r=0.23042449108036192, p=6.328174272471966e-16, z-score=0.2346377139059013\n",
      "Analyzing subject 135\n",
      ">> Subject 135: correlation between R_anterior_caudate and vmpfc: r=0.5468958917042762, p=1.491642859478379e-94, z-score=0.6139418163490832\n",
      "Analyzing subject 136\n",
      ">> Subject 136: correlation between R_anterior_caudate and vmpfc: r=0.5229000010466487, p=3.5517849882546296e-85, z-score=0.5803227906083147\n",
      "Analyzing subject 137\n",
      ">> Subject 137: correlation between R_anterior_caudate and vmpfc: r=0.8565643735508721, p=0.0, z-score=1.280298304661505\n",
      "Analyzing subject 138\n",
      ">> Subject 138: correlation between R_anterior_caudate and vmpfc: r=0.5289495443059965, p=1.8078765577902727e-87, z-score=0.5886854966720124\n",
      "Analyzing subject 139\n",
      ">> Subject 139: correlation between R_anterior_caudate and vmpfc: r=0.501925453536824, p=1.421040191856948e-77, z-score=0.551876721055238\n",
      "Analyzing subject 140\n",
      ">> Subject 140: correlation between R_anterior_caudate and vmpfc: r=0.42918465352299295, p=5.8505322119617566e-55, z-score=0.45889680856590537\n",
      "Analyzing subject 141\n",
      ">> Subject 141: correlation between R_anterior_caudate and vmpfc: r=0.6355253983259526, p=9.514121082367914e-137, z-score=0.7506312535693789\n",
      "Analyzing subject 142\n",
      ">> Subject 142: correlation between R_anterior_caudate and vmpfc: r=0.4154159882566567, p=2.9060740202353905e-51, z-score=0.44213912412815815\n",
      "Analyzing subject 143\n",
      ">> Subject 143: correlation between R_anterior_caudate and vmpfc: r=0.5382442546665501, p=4.3841645853230043e-91, z-score=0.6016804445558637\n",
      "Analyzing subject 144\n",
      ">> Subject 144: correlation between R_anterior_caudate and vmpfc: r=0.6801489518904824, p=9.476329198034794e-164, z-score=0.829391158768796\n",
      "Analyzing subject 145\n",
      ">> Subject 145: correlation between R_anterior_caudate and vmpfc: r=0.264897980570906, p=1.0193846375300892e-20, z-score=0.2713687293071479\n",
      "Analyzing subject 148\n",
      ">> Subject 148: correlation between R_anterior_caudate and vmpfc: r=0.3316496601909369, p=3.35861361593226e-32, z-score=0.3446806508916164\n",
      "Analyzing subject 149\n",
      ">> Subject 149: correlation between R_anterior_caudate and vmpfc: r=0.42753708650107053, p=1.6541046466307043e-54, z-score=0.45687898390645726\n",
      "Analyzing subject 152\n",
      ">> Subject 152: correlation between R_anterior_caudate and vmpfc: r=0.36708411532166807, p=1.3904653099062377e-39, z-score=0.38504891895469684\n",
      "Analyzing subject 153\n",
      ">> Subject 153: correlation between R_anterior_caudate and vmpfc: r=0.5584760425894267, p=2.343202325450954e-99, z-score=0.6306157223757531\n",
      "Analyzing subject 154\n",
      ">> Subject 154: correlation between R_anterior_caudate and vmpfc: r=0.45211697807918927, p=1.655582380563585e-61, z-score=0.48735797752092547\n",
      "Analyzing subject 155\n",
      ">> Subject 155: correlation between R_anterior_caudate and vmpfc: r=0.335173763060386, p=6.821107587813971e-33, z-score=0.3486455066418297\n",
      "Analyzing connectivity between L_vlpfc and L_post_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between L_vlpfc and L_post_putamen: r=0.18461671788131223, p=1.1627700624130406e-10, z-score=0.18675813446197434\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between L_vlpfc and L_post_putamen: r=0.43873890215892414, p=1.2586923775455902e-57, z-score=0.4706680170896512\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between L_vlpfc and L_post_putamen: r=0.5733914721976021, p=7.877029499561921e-106, z-score=0.6525609729494718\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between L_vlpfc and L_post_putamen: r=0.17755257638329172, p=5.885620883867153e-10, z-score=0.1794544589040613\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between L_vlpfc and L_post_putamen: r=0.3579859381754586, p=1.3482640911364144e-37, z-score=0.3745738733284629\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between L_vlpfc and L_post_putamen: r=0.5459823204800438, p=3.505014352237615e-94, z-score=0.6126393272358281\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between L_vlpfc and L_post_putamen: r=0.24046337780675897, p=3.0292109203286124e-17, z-score=0.24526587044036438\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between L_vlpfc and L_post_putamen: r=0.41234962074739334, p=1.833530934613576e-50, z-score=0.43843890810753583\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between L_vlpfc and L_post_putamen: r=0.3576161014266537, p=1.6187304361629344e-37, z-score=0.37414973811633256\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between L_vlpfc and L_post_putamen: r=0.37977368170097725, p=1.8341936837600907e-42, z-score=0.39979516249397445\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between L_vlpfc and L_post_putamen: r=0.640956024659598, p=8.546388175100258e-140, z-score=0.7597947089341681\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between L_vlpfc and L_post_putamen: r=0.33758919201092347, p=2.260003941218242e-33, z-score=0.3513691214079249\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between L_vlpfc and L_post_putamen: r=0.1926854233684307, p=1.6846131480256968e-11, z-score=0.19512464985154682\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between L_vlpfc and L_post_putamen: r=0.3055203817222012, p=2.4131660492308213e-27, z-score=0.3155970928909941\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between L_vlpfc and L_post_putamen: r=0.3388089541951682, p=1.2888910270851072e-33, z-score=0.35274641701211473\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between L_vlpfc and L_post_putamen: r=0.6522502208721236, p=2.4773395788845987e-146, z-score=0.7792051061865495\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between L_vlpfc and L_post_putamen: r=0.3346120037118599, p=8.806798020856118e-33, z-score=0.3480127855451309\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between L_vlpfc and L_post_putamen: r=0.5713444262348109, p=6.375559613809978e-105, z-score=0.6495165581207919\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between L_vlpfc and L_post_putamen: r=0.24434814972465915, p=8.995351241976502e-18, z-score=0.24939317133328529\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between L_vlpfc and L_post_putamen: r=0.30623014987383645, p=1.8071069689800117e-27, z-score=0.3163801209415236\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between L_vlpfc and L_post_putamen: r=0.2972195876611159, p=6.697924225716187e-26, z-score=0.3064669946193448\n",
      "Analyzing subject 123\n",
      ">> Subject 123: correlation between L_vlpfc and L_post_putamen: r=0.18531977878282896, p=9.859585389048798e-11, z-score=0.18748610151873513\n",
      "Analyzing subject 124\n",
      ">> Subject 124: correlation between L_vlpfc and L_post_putamen: r=0.4288969374706008, p=7.017758386499424e-55, z-score=0.4585441825143357\n",
      "Analyzing subject 125\n",
      ">> Subject 125: correlation between L_vlpfc and L_post_putamen: r=0.2692601751659217, p=2.2319319646241995e-21, z-score=0.2760659954272882\n",
      "Analyzing subject 126\n",
      ">> Subject 126: correlation between L_vlpfc and L_post_putamen: r=0.4049831093129572, p=1.4170871974893072e-48, z-score=0.42959538350112486\n",
      "Analyzing subject 127\n",
      ">> Subject 127: correlation between L_vlpfc and L_post_putamen: r=0.5570246355425144, p=9.60076160900297e-99, z-score=0.6285089181788388\n",
      "Analyzing subject 128\n",
      ">> Subject 128: correlation between L_vlpfc and L_post_putamen: r=0.5773086227291528, p=1.3822656415629276e-107, z-score=0.6584164810246241\n",
      "Analyzing subject 129\n",
      ">> Subject 129: correlation between L_vlpfc and L_post_putamen: r=0.46724971930639475, p=4.124690442061943e-66, z-score=0.5065460951385702\n",
      "Analyzing subject 130\n",
      ">> Subject 130: correlation between L_vlpfc and L_post_putamen: r=0.3150324665288058, p=4.680708761746924e-29, z-score=0.3261225964680207\n",
      "Analyzing subject 131\n",
      ">> Subject 131: correlation between L_vlpfc and L_post_putamen: r=0.4943704970879311, p=5.802041826284621e-75, z-score=0.5418280657790897\n",
      "Analyzing subject 132\n",
      ">> Subject 132: correlation between L_vlpfc and L_post_putamen: r=0.4656458968525262, p=1.3011654797036106e-65, z-score=0.504496287904054\n",
      "Analyzing subject 133\n",
      ">> Subject 133: correlation between L_vlpfc and L_post_putamen: r=0.36151095967669833, p=2.3318640097655194e-38, z-score=0.37862292559412775\n",
      "Analyzing subject 134\n",
      ">> Subject 134: correlation between L_vlpfc and L_post_putamen: r=0.24655021926977375, p=4.4769582347485886e-18, z-score=0.25173641126589374\n",
      "Analyzing subject 135\n",
      ">> Subject 135: correlation between L_vlpfc and L_post_putamen: r=0.6852197033533387, p=3.982541257934526e-167, z-score=0.838888148758442\n",
      "Analyzing subject 136\n",
      ">> Subject 136: correlation between L_vlpfc and L_post_putamen: r=0.3221358822552841, p=2.2404445505176732e-30, z-score=0.3340284744740129\n",
      "Analyzing subject 137\n",
      ">> Subject 137: correlation between L_vlpfc and L_post_putamen: r=0.6660670612663518, p=1.0100463451235677e-154, z-score=0.8036404420974781\n",
      "Analyzing subject 138\n",
      ">> Subject 138: correlation between L_vlpfc and L_post_putamen: r=0.5041580404793077, p=2.335656014103359e-78, z-score=0.5548656665710903\n",
      "Analyzing subject 139\n",
      ">> Subject 139: correlation between L_vlpfc and L_post_putamen: r=0.22163417190463766, p=8.073756918476502e-15, z-score=0.22537404843137374\n",
      "Analyzing subject 140\n",
      ">> Subject 140: correlation between L_vlpfc and L_post_putamen: r=0.35421263999995956, p=8.60866012158159e-37, z-score=0.37025260071122723\n",
      "Analyzing subject 141\n",
      ">> Subject 141: correlation between L_vlpfc and L_post_putamen: r=0.3770361455357304, p=7.862958498792423e-42, z-score=0.39660012463876815\n",
      "Analyzing subject 142\n",
      ">> Subject 142: correlation between L_vlpfc and L_post_putamen: r=0.26280641221317347, p=2.090811318107548e-20, z-score=0.2691206533758846\n",
      "Analyzing subject 143\n",
      ">> Subject 143: correlation between L_vlpfc and L_post_putamen: r=0.6274031113403953, p=2.6448671548356875e-132, z-score=0.7371218661627136\n",
      "Analyzing subject 144\n",
      ">> Subject 144: correlation between L_vlpfc and L_post_putamen: r=0.5268123508169897, p=1.182082669824962e-86, z-score=0.5857226895253376\n",
      "Analyzing subject 145\n",
      ">> Subject 145: correlation between L_vlpfc and L_post_putamen: r=0.6013524222325839, p=6.659011204743194e-119, z-score=0.695263026123551\n",
      "Analyzing subject 148\n",
      ">> Subject 148: correlation between L_vlpfc and L_post_putamen: r=0.30114162436271485, p=1.411975770655798e-26, z-score=0.31077460946185426\n",
      "Analyzing subject 149\n",
      ">> Subject 149: correlation between L_vlpfc and L_post_putamen: r=0.4020173946968002, p=7.911310109694737e-48, z-score=0.42605290458540124\n",
      "Analyzing subject 152\n",
      ">> Subject 152: correlation between L_vlpfc and L_post_putamen: r=0.3565245850751517, p=2.7726672403503297e-37, z-score=0.3728987173884694\n",
      "Analyzing subject 153\n",
      ">> Subject 153: correlation between L_vlpfc and L_post_putamen: r=0.34953300755396843, p=8.287551291534823e-36, z-score=0.3649116682063911\n",
      "Analyzing subject 154\n",
      ">> Subject 154: correlation between L_vlpfc and L_post_putamen: r=0.27493483892233295, p=2.966358648867486e-22, z-score=0.2821944106972485\n",
      "Analyzing subject 155\n",
      ">> Subject 155: correlation between L_vlpfc and L_post_putamen: r=0.17386512056265108, p=1.3375545623370502e-09, z-score=0.17564952625617147\n",
      "Analyzing connectivity between R_vlpfc and R_post_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_vlpfc and R_post_putamen: r=0.6199528355699977, p=2.422505988512278e-128, z-score=0.7249284760086554\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_vlpfc and R_post_putamen: r=0.45071052983339854, p=4.316733463676889e-61, z-score=0.48559158267645397\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_vlpfc and R_post_putamen: r=0.5174512742630151, p=3.77283781105192e-83, z-score=0.572852755768665\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_vlpfc and R_post_putamen: r=0.47001626063037655, p=5.603593584877515e-67, z-score=0.5100912078620397\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_vlpfc and R_post_putamen: r=0.46608511370473577, p=9.50513768987376e-66, z-score=0.5050572509633223\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_vlpfc and R_post_putamen: r=0.2623388277560071, p=2.4528926677611577e-20, z-score=0.26861844442148164\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_vlpfc and R_post_putamen: r=0.1104260215821728, p=0.00012658453784290965, z-score=0.11087817585534121\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_vlpfc and R_post_putamen: r=0.7187251598017483, p=2.653233558206858e-191, z-score=0.9050029192539898\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_vlpfc and R_post_putamen: r=0.5518422905883393, p=1.3956542041385581e-96, z-score=0.621026439143567\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_vlpfc and R_post_putamen: r=0.6713965342768053, p=4.4302940962202175e-158, z-score=0.8132815257682559\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_vlpfc and R_post_putamen: r=0.713265912811091, p=3.982689172993489e-187, z-score=0.8938007288560433\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_vlpfc and R_post_putamen: r=0.3974197747011184, p=1.099454489853192e-46, z-score=0.42058099328082554\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_vlpfc and R_post_putamen: r=0.1408206784268814, p=9.705812777158708e-07, z-score=0.14176275967596738\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_vlpfc and R_post_putamen: r=0.504723930969741, p=1.4747343195547929e-78, z-score=0.5556247017345952\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_vlpfc and R_post_putamen: r=0.607916280371474, p=3.663237420461865e-122, z-score=0.7056094982347215\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_vlpfc and R_post_putamen: r=0.6823816315646817, p=3.1508400424125976e-165, z-score=0.8335575717545903\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_vlpfc and R_post_putamen: r=0.39609414367421747, p=2.3301449860341672e-46, z-score=0.4190077002172589\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_vlpfc and R_post_putamen: r=0.7305520112771742, p=1.0610997700111772e-200, z-score=0.929910169143747\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_vlpfc and R_post_putamen: r=0.3499343759953114, p=6.834756939727508e-36, z-score=0.3653689710381659\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_vlpfc and R_post_putamen: r=0.4997896641143371, p=7.895526224696011e-77, z-score=0.5490257357991389\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_vlpfc and R_post_putamen: r=0.4115198767607411, p=3.008375213077148e-50, z-score=0.4374395893857032\n",
      "Analyzing subject 123\n",
      ">> Subject 123: correlation between R_vlpfc and R_post_putamen: r=0.4399763925531588, p=5.599629717556268e-58, z-score=0.4722015296898165\n",
      "Analyzing subject 124\n",
      ">> Subject 124: correlation between R_vlpfc and R_post_putamen: r=0.4061526648989037, p=7.157856659051234e-49, z-score=0.4309951863850565\n",
      "Analyzing subject 125\n",
      ">> Subject 125: correlation between R_vlpfc and R_post_putamen: r=0.07385740250029332, p=0.010487560349746827, z-score=0.07399213906848201\n",
      "Analyzing subject 126\n",
      ">> Subject 126: correlation between R_vlpfc and R_post_putamen: r=0.5923127472253873, p=1.5500651398495385e-114, z-score=0.6812212266128951\n",
      "Analyzing subject 127\n",
      ">> Subject 127: correlation between R_vlpfc and R_post_putamen: r=0.3534171842485263, p=1.2684827228533245e-36, z-score=0.36934331609723847\n",
      "Analyzing subject 128\n",
      ">> Subject 128: correlation between R_vlpfc and R_post_putamen: r=0.6743826457146005, p=5.4209322299547203e-160, z-score=0.8187384372438354\n",
      "Analyzing subject 129\n",
      ">> Subject 129: correlation between R_vlpfc and R_post_putamen: r=0.4923126319740643, p=2.907391700623008e-74, z-score=0.5391082284051775\n",
      "Analyzing subject 130\n",
      ">> Subject 130: correlation between R_vlpfc and R_post_putamen: r=0.39091391980734824, p=4.2455491832008173e-45, z-score=0.4128783509128511\n",
      "Analyzing subject 131\n",
      ">> Subject 131: correlation between R_vlpfc and R_post_putamen: r=0.5098885116425192, p=2.1317678990352328e-80, z-score=0.5625791006246967\n",
      "Analyzing subject 132\n",
      ">> Subject 132: correlation between R_vlpfc and R_post_putamen: r=0.6577064097528371, p=1.3615674615235559e-149, z-score=0.7887607126291396\n",
      "Analyzing subject 133\n",
      ">> Subject 133: correlation between R_vlpfc and R_post_putamen: r=0.4360185557190627, p=7.380454528827123e-57, z-score=0.4673041602944424\n",
      "Analyzing subject 134\n",
      ">> Subject 134: correlation between R_vlpfc and R_post_putamen: r=0.48402780748431484, p=1.7120195076105681e-71, z-score=0.5282311440964025\n",
      "Analyzing subject 135\n",
      ">> Subject 135: correlation between R_vlpfc and R_post_putamen: r=0.8355840098700897, p=6.190804423e-314, z-score=1.2063591149537942\n",
      "Analyzing subject 136\n",
      ">> Subject 136: correlation between R_vlpfc and R_post_putamen: r=0.5308472411043847, p=3.37416286153973e-88, z-score=0.5913240930667085\n",
      "Analyzing subject 137\n",
      ">> Subject 137: correlation between R_vlpfc and R_post_putamen: r=0.8664276618472981, p=0.0, z-score=1.318569175825939\n",
      "Analyzing subject 138\n",
      ">> Subject 138: correlation between R_vlpfc and R_post_putamen: r=0.6010539650671145, p=9.328761809380291e-119, z-score=0.6947956312903878\n",
      "Analyzing subject 139\n",
      ">> Subject 139: correlation between R_vlpfc and R_post_putamen: r=0.6730209363212061, p=4.0637607562095424e-159, z-score=0.8162450358733575\n",
      "Analyzing subject 140\n",
      ">> Subject 140: correlation between R_vlpfc and R_post_putamen: r=0.6087305874308911, p=1.4261153153752428e-122, z-score=0.7069021672794804\n",
      "Analyzing subject 141\n",
      ">> Subject 141: correlation between R_vlpfc and R_post_putamen: r=0.7539639486215605, p=7.27148823352324e-221, z-score=0.982077771699787\n",
      "Analyzing subject 142\n",
      ">> Subject 142: correlation between R_vlpfc and R_post_putamen: r=0.5539729424115944, p=1.8209961512028905e-97, z-score=0.6240952508909999\n",
      "Analyzing subject 143\n",
      ">> Subject 143: correlation between R_vlpfc and R_post_putamen: r=0.6993133344902537, p=6.946480716025003e-177, z-score=0.8659553916882801\n",
      "Analyzing subject 144\n",
      ">> Subject 144: correlation between R_vlpfc and R_post_putamen: r=0.4946585351168774, p=4.626274097530216e-75, z-score=0.5422093431351397\n",
      "Analyzing subject 145\n",
      ">> Subject 145: correlation between R_vlpfc and R_post_putamen: r=0.7151962848637938, p=1.3635712999551259e-188, z-score=0.897741290346995\n",
      "Analyzing subject 148\n",
      ">> Subject 148: correlation between R_vlpfc and R_post_putamen: r=0.5728905300579086, p=1.3158097129905493e-105, z-score=0.6518149786399795\n",
      "Analyzing subject 149\n",
      ">> Subject 149: correlation between R_vlpfc and R_post_putamen: r=0.5209302214196918, p=1.9373393424858332e-84, z-score=0.5776155760470079\n",
      "Analyzing subject 152\n",
      ">> Subject 152: correlation between R_vlpfc and R_post_putamen: r=0.6777412241874748, p=3.5978223060915937e-162, z-score=0.8249243919701298\n",
      "Analyzing subject 153\n",
      ">> Subject 153: correlation between R_vlpfc and R_post_putamen: r=0.5518125488707519, p=1.4357503870629318e-96, z-score=0.6209836752399601\n",
      "Analyzing subject 154\n",
      ">> Subject 154: correlation between R_vlpfc and R_post_putamen: r=0.3869438846890766, p=3.7918726722140017e-44, z-score=0.40820074379858745\n",
      "Analyzing subject 155\n",
      ">> Subject 155: correlation between R_vlpfc and R_post_putamen: r=0.39745158903329836, p=1.0797675008751798e-46, z-score=0.4206187755095255\n",
      "Analyzing connectivity between L_vlpfc and L_anterior_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between L_vlpfc and L_anterior_putamen: r=0.07419220439179953, p=0.010141739744239202, z-score=0.07432878567603153\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between L_vlpfc and L_anterior_putamen: r=0.4773069296367597, p=2.663018185214462e-69, z-score=0.5194908194090516\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between L_vlpfc and L_anterior_putamen: r=0.4315030013886194, p=1.3421854583593077e-55, z-score=0.46174209376031344\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between L_vlpfc and L_anterior_putamen: r=0.14617355331262313, p=3.663451310909827e-07, z-score=0.14722818968663304\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between L_vlpfc and L_anterior_putamen: r=0.30134292822984193, p=1.3026944296667498e-26, z-score=0.3109960042200046\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between L_vlpfc and L_anterior_putamen: r=0.4524448968223704, p=1.3232153355894767e-61, z-score=0.48777022476182513\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between L_vlpfc and L_anterior_putamen: r=0.21220893897675028, p=1.1005879670431389e-13, z-score=0.21548331997653766\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between L_vlpfc and L_anterior_putamen: r=0.4174794642910517, p=8.32280032049086e-52, z-score=0.4446355544849719\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between L_vlpfc and L_anterior_putamen: r=0.30381911175338006, p=4.8110660022801264e-27, z-score=0.3137217457053501\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between L_vlpfc and L_anterior_putamen: r=0.3654079168567585, p=3.265939536344636e-39, z-score=0.38311304972074767\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between L_vlpfc and L_anterior_putamen: r=0.6549939061549921, p=5.796679720272604e-148, z-score=0.78399526276429\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between L_vlpfc and L_anterior_putamen: r=0.304676621662782, p=3.399786743338349e-27, z-score=0.31466672981799937\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between L_vlpfc and L_anterior_putamen: r=0.15177944801541093, p=1.2712025394175607e-07, z-score=0.152961342343996\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between L_vlpfc and L_anterior_putamen: r=0.3091762896484266, p=5.393987059471968e-28, z-score=0.3196343815905374\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between L_vlpfc and L_anterior_putamen: r=0.37784902033674295, p=5.11106519116063e-42, z-score=0.3975480426835146\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between L_vlpfc and L_anterior_putamen: r=0.6180657951525013, p=2.3488589189853643e-127, z-score=0.7218692030668593\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between L_vlpfc and L_anterior_putamen: r=0.16694580136326787, p=5.954844514325558e-09, z-score=0.16852324203149052\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between L_vlpfc and L_anterior_putamen: r=0.617188671623711, p=6.716675700940163e-127, z-score=0.7204511401047599\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between L_vlpfc and L_anterior_putamen: r=0.3444900134890908, p=9.115824521122881e-35, z-score=0.3591782549827157\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between L_vlpfc and L_anterior_putamen: r=0.34801195829805465, p=1.7160532036172848e-35, z-score=0.3631799708816876\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between L_vlpfc and L_anterior_putamen: r=0.31609842485146367, p=2.9819439275598955e-29, z-score=0.3273064443611339\n",
      "Analyzing subject 123\n",
      ">> Subject 123: correlation between L_vlpfc and L_anterior_putamen: r=0.07921072764477806, p=0.006043809575274906, z-score=0.07937701911235322\n",
      "Analyzing subject 124\n",
      ">> Subject 124: correlation between L_vlpfc and L_anterior_putamen: r=0.2611035002366451, p=3.734778291657411e-20, z-score=0.26729227690411805\n",
      "Analyzing subject 125\n",
      ">> Subject 125: correlation between L_vlpfc and L_anterior_putamen: r=0.14584112400078042, p=3.8959805758091816e-07, z-score=0.14688851922799953\n",
      "Analyzing subject 126\n",
      ">> Subject 126: correlation between L_vlpfc and L_anterior_putamen: r=0.412973765381072, p=1.2622043109698868e-50, z-score=0.43919115218330285\n",
      "Analyzing subject 127\n",
      ">> Subject 127: correlation between L_vlpfc and L_anterior_putamen: r=0.5598170614956839, p=6.327056549140853e-100, z-score=0.6325667076314715\n",
      "Analyzing subject 128\n",
      ">> Subject 128: correlation between L_vlpfc and L_anterior_putamen: r=0.4995741266362337, p=9.380986951557646e-77, z-score=0.548738474291739\n",
      "Analyzing subject 129\n",
      ">> Subject 129: correlation between L_vlpfc and L_anterior_putamen: r=0.4710802671070988, p=2.587760567131498e-67, z-score=0.511457799391613\n",
      "Analyzing subject 130\n",
      ">> Subject 130: correlation between L_vlpfc and L_anterior_putamen: r=0.24006975775104974, p=3.421697082714989e-17, z-score=0.24484813535720398\n",
      "Analyzing subject 131\n",
      ">> Subject 131: correlation between L_vlpfc and L_anterior_putamen: r=0.3064863172936337, p=1.627669819948811e-27, z-score=0.3166628213104658\n",
      "Analyzing subject 132\n",
      ">> Subject 132: correlation between L_vlpfc and L_anterior_putamen: r=0.4276337196520024, p=1.5565330487935833e-54, z-score=0.45699723722657426\n",
      "Analyzing subject 133\n",
      ">> Subject 133: correlation between L_vlpfc and L_anterior_putamen: r=0.2615912371066457, p=3.1643980728296654e-20, z-score=0.26781576962115855\n",
      "Analyzing subject 134\n",
      ">> Subject 134: correlation between L_vlpfc and L_anterior_putamen: r=0.29019651953433917, p=1.024893644620269e-24, z-score=0.29878084141570227\n",
      "Analyzing subject 135\n",
      ">> Subject 135: correlation between L_vlpfc and L_anterior_putamen: r=0.6460885422162344, p=9.889322439422376e-143, z-score=0.7685552047756814\n",
      "Analyzing subject 136\n",
      ">> Subject 136: correlation between L_vlpfc and L_anterior_putamen: r=0.25931423872026793, p=6.839265196390964e-20, z-score=0.26537306764813845\n",
      "Analyzing subject 137\n",
      ">> Subject 137: correlation between L_vlpfc and L_anterior_putamen: r=0.42556867360199396, p=5.682760978544414e-54, z-score=0.45447276422116045\n",
      "Analyzing subject 138\n",
      ">> Subject 138: correlation between L_vlpfc and L_anterior_putamen: r=0.39003712414376734, p=6.903552468933074e-45, z-score=0.4118438188609517\n",
      "Analyzing subject 139\n",
      ">> Subject 139: correlation between L_vlpfc and L_anterior_putamen: r=0.18044090567409296, p=3.0564528223045286e-10, z-score=0.18243839537094134\n",
      "Analyzing subject 140\n",
      ">> Subject 140: correlation between L_vlpfc and L_anterior_putamen: r=0.3339215652082441, p=1.2047124453297665e-32, z-score=0.34723549724393143\n",
      "Analyzing subject 141\n",
      ">> Subject 141: correlation between L_vlpfc and L_anterior_putamen: r=0.2385677087353888, p=5.4360252550474496e-17, z-score=0.24325483197807643\n",
      "Analyzing subject 142\n",
      ">> Subject 142: correlation between L_vlpfc and L_anterior_putamen: r=0.24454545435540326, p=8.452563644307318e-18, z-score=0.24960301501436064\n",
      "Analyzing subject 143\n",
      ">> Subject 143: correlation between L_vlpfc and L_anterior_putamen: r=0.5760689336104472, p=4.9982938968820505e-107, z-score=0.6565590731586103\n",
      "Analyzing subject 144\n",
      ">> Subject 144: correlation between L_vlpfc and L_anterior_putamen: r=0.6325245283508018, p=4.3227218523767646e-135, z-score=0.7456131567237276\n",
      "Analyzing subject 145\n",
      ">> Subject 145: correlation between L_vlpfc and L_anterior_putamen: r=0.30379273126095074, p=4.862641177302415e-27, z-score=0.31369268276009443\n",
      "Analyzing subject 148\n",
      ">> Subject 148: correlation between L_vlpfc and L_anterior_putamen: r=-0.07148261496584435, p=0.01325592131470117, z-score=-0.07160474271477568\n",
      "Analyzing subject 149\n",
      ">> Subject 149: correlation between L_vlpfc and L_anterior_putamen: r=0.25642447269071217, p=1.799229326676597e-19, z-score=0.2622774508438792\n",
      "Analyzing subject 152\n",
      ">> Subject 152: correlation between L_vlpfc and L_anterior_putamen: r=0.16471337926419044, p=9.51618462675424e-09, z-score=0.1662276925151284\n",
      "Analyzing subject 153\n",
      ">> Subject 153: correlation between L_vlpfc and L_anterior_putamen: r=0.34018079173196614, p=6.832915698134172e-34, z-score=0.35429696620905043\n",
      "Analyzing subject 154\n",
      ">> Subject 154: correlation between L_vlpfc and L_anterior_putamen: r=0.24069074833372414, p=2.823073232383199e-17, z-score=0.2455072089983651\n",
      "Analyzing subject 155\n",
      ">> Subject 155: correlation between L_vlpfc and L_anterior_putamen: r=0.15692978973977745, p=4.6439060134553376e-08, z-score=0.1582374008004711\n",
      "Analyzing connectivity between R_vlpfc and R_anterior_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_vlpfc and R_anterior_putamen: r=0.45158297595950336, p=2.383447142363028e-61, z-score=0.48668697858954835\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_vlpfc and R_anterior_putamen: r=0.5574472235836259, p=6.37213441034645e-99, z-score=0.6291218193371593\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_vlpfc and R_anterior_putamen: r=0.5706956277656184, p=1.2331640832083642e-104, z-score=0.6485538577392204\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_vlpfc and R_anterior_putamen: r=0.39143381705524743, p=3.180068899038833e-45, z-score=0.4134921734675637\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_vlpfc and R_anterior_putamen: r=0.3215045571627398, p=2.9450570083342092e-30, z-score=0.3333242098945489\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_vlpfc and R_anterior_putamen: r=0.3949867126660973, p=4.352687638437292e-46, z-score=0.4176948744572594\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_vlpfc and R_anterior_putamen: r=-0.05161023908007652, p=0.07391179484068801, z-score=-0.051656135752699346\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_vlpfc and R_anterior_putamen: r=0.6973132127785251, p=1.825280225561242e-175, z-score=0.8620516256979825\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_vlpfc and R_anterior_putamen: r=0.49356065151872774, p=1.095459929140072e-74, z-score=0.5407568384860011\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_vlpfc and R_anterior_putamen: r=0.5700429047078998, p=2.3911823357287752e-104, z-score=0.6475864002447165\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_vlpfc and R_anterior_putamen: r=0.6137839409153858, p=3.843824381812788e-125, z-score=0.7149700114172165\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_vlpfc and R_anterior_putamen: r=0.29040598712643295, p=9.45849135671334e-25, z-score=0.2990095864554624\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_vlpfc and R_anterior_putamen: r=0.18126567992626458, p=2.5298567517479245e-10, z-score=0.183291058510204\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_vlpfc and R_anterior_putamen: r=0.436244423033646, p=6.376310040854414e-57, z-score=0.46758308137946564\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_vlpfc and R_anterior_putamen: r=0.5578502946313276, p=4.307718624240857e-99, z-score=0.6297068044915507\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_vlpfc and R_anterior_putamen: r=0.6919540384050598, p=1.0176424866640764e-171, z-score=0.8516951889679641\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_vlpfc and R_anterior_putamen: r=0.3070206282503472, p=1.308246008879607e-27, z-score=0.3172526321239288\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_vlpfc and R_anterior_putamen: r=0.8039436019310184, p=1.1775485547386281e-272, z-score=1.1096640371282478\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_vlpfc and R_anterior_putamen: r=0.342731863430064, p=2.0815222495190165e-34, z-score=0.35718473190100936\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_vlpfc and R_anterior_putamen: r=0.47502190952288426, p=1.4438582294363983e-68, z-score=0.5165357966405806\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_vlpfc and R_anterior_putamen: r=0.43041006893993417, p=2.6906396288079225e-55, z-score=0.460399880456316\n",
      "Analyzing subject 123\n",
      ">> Subject 123: correlation between R_vlpfc and R_anterior_putamen: r=0.38025640563561797, p=1.4169291411434277e-42, z-score=0.4003593635268608\n",
      "Analyzing subject 124\n",
      ">> Subject 124: correlation between R_vlpfc and R_anterior_putamen: r=0.31850668365086604, p=1.0694779828107825e-29, z-score=0.32998431554445196\n",
      "Analyzing subject 125\n",
      ">> Subject 125: correlation between R_vlpfc and R_anterior_putamen: r=0.18739262798079542, p=6.039843636146532e-11, z-score=0.18963352881399784\n",
      "Analyzing subject 126\n",
      ">> Subject 126: correlation between R_vlpfc and R_anterior_putamen: r=0.4998071366362226, p=7.785914151403636e-77, z-score=0.5490490262357925\n",
      "Analyzing subject 127\n",
      ">> Subject 127: correlation between R_vlpfc and R_anterior_putamen: r=0.6895119994970407, p=4.8700721865075986e-170, z-score=0.8470248768104601\n",
      "Analyzing subject 128\n",
      ">> Subject 128: correlation between R_vlpfc and R_anterior_putamen: r=0.6452356024613315, p=3.069769807113243e-142, z-score=0.7670924880400852\n",
      "Analyzing subject 129\n",
      ">> Subject 129: correlation between R_vlpfc and R_anterior_putamen: r=0.5218421258176372, p=8.84560104268866e-85, z-score=0.5788679231275832\n",
      "Analyzing subject 130\n",
      ">> Subject 130: correlation between R_vlpfc and R_anterior_putamen: r=0.2796508734569363, p=5.344697127882965e-23, z-score=0.28730328606795436\n",
      "Analyzing subject 131\n",
      ">> Subject 131: correlation between R_vlpfc and R_anterior_putamen: r=0.5162483091233299, p=1.0448994653994015e-82, z-score=0.5712113026986808\n",
      "Analyzing subject 132\n",
      ">> Subject 132: correlation between R_vlpfc and R_anterior_putamen: r=0.4213896344724464, p=7.599579697017437e-53, z-score=0.44938049033258076\n",
      "Analyzing subject 133\n",
      ">> Subject 133: correlation between R_vlpfc and R_anterior_putamen: r=0.36107183315765523, p=2.9051015203038303e-38, z-score=0.3781178739235274\n",
      "Analyzing subject 134\n",
      ">> Subject 134: correlation between R_vlpfc and R_anterior_putamen: r=0.3822129513986058, p=4.955254703075574e-43, z-score=0.4026486326111347\n",
      "Analyzing subject 135\n",
      ">> Subject 135: correlation between R_vlpfc and R_anterior_putamen: r=0.6855133950255964, p=2.5262695388579636e-167, z-score=0.8394419990586403\n",
      "Analyzing subject 136\n",
      ">> Subject 136: correlation between R_vlpfc and R_anterior_putamen: r=0.3294639695669394, p=8.933174505719481e-32, z-score=0.34222683581733854\n",
      "Analyzing subject 137\n",
      ">> Subject 137: correlation between R_vlpfc and R_anterior_putamen: r=0.8301865383924687, p=2.6995902145594482e-306, z-score=1.1887363121286387\n",
      "Analyzing subject 138\n",
      ">> Subject 138: correlation between R_vlpfc and R_anterior_putamen: r=0.5219658183199183, p=7.951779082263425e-85, z-score=0.5790379200234095\n",
      "Analyzing subject 139\n",
      ">> Subject 139: correlation between R_vlpfc and R_anterior_putamen: r=0.5965115946018725, p=1.5108733154670296e-116, z-score=0.6877142612085166\n",
      "Analyzing subject 140\n",
      ">> Subject 140: correlation between R_vlpfc and R_anterior_putamen: r=0.5701289741427472, p=2.1914275989306983e-104, z-score=0.6477139101370052\n",
      "Analyzing subject 141\n",
      ">> Subject 141: correlation between R_vlpfc and R_anterior_putamen: r=0.6843056880970442, p=1.6363514268366774e-166, z-score=0.8371671626687287\n",
      "Analyzing subject 142\n",
      ">> Subject 142: correlation between R_vlpfc and R_anterior_putamen: r=0.6256942130792887, p=2.1911573219876717e-131, z-score=0.7343085680729722\n",
      "Analyzing subject 143\n",
      ">> Subject 143: correlation between R_vlpfc and R_anterior_putamen: r=0.6222392938759808, p=1.512794255960652e-129, z-score=0.7286509056758899\n",
      "Analyzing subject 144\n",
      ">> Subject 144: correlation between R_vlpfc and R_anterior_putamen: r=0.5484913726942103, p=3.333843630879436e-95, z-score=0.6162209736154296\n",
      "Analyzing subject 145\n",
      ">> Subject 145: correlation between R_vlpfc and R_anterior_putamen: r=0.46984133844032594, p=6.360867843767332e-67, z-score=0.5098667088669897\n",
      "Analyzing subject 148\n",
      ">> Subject 148: correlation between R_vlpfc and R_anterior_putamen: r=0.35837109273717715, p=1.1142305200782032e-37, z-score=0.3750157122282428\n",
      "Analyzing subject 149\n",
      ">> Subject 149: correlation between R_vlpfc and R_anterior_putamen: r=0.48149947005677385, p=1.15826138793888e-70, z-score=0.5249344797837113\n",
      "Analyzing subject 152\n",
      ">> Subject 152: correlation between R_vlpfc and R_anterior_putamen: r=0.557087579394629, p=9.032458554585777e-99, z-score=0.628600182355095\n",
      "Analyzing subject 153\n",
      ">> Subject 153: correlation between R_vlpfc and R_anterior_putamen: r=0.5734164950063159, p=7.677532565130329e-106, z-score=0.6525982532165525\n",
      "Analyzing subject 154\n",
      ">> Subject 154: correlation between R_vlpfc and R_anterior_putamen: r=0.4200891594310662, p=1.6905717097846488e-52, z-score=0.44780028419454976\n",
      "Analyzing subject 155\n",
      ">> Subject 155: correlation between R_vlpfc and R_anterior_putamen: r=0.3449553959934155, p=7.319694062770552e-35, z-score=0.35970639880959127\n",
      "Analyzing connectivity between L_vlpfc and L_anterior_caudate\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between L_vlpfc and L_anterior_caudate: r=0.2624480689803992, p=2.363119171626267e-20, z-score=0.2687357630729237\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between L_vlpfc and L_anterior_caudate: r=0.48484081707166515, p=9.226491488855262e-72, z-score=0.5292934528154729\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between L_vlpfc and L_anterior_caudate: r=0.5106551690603532, p=1.1295375816527045e-80, z-score=0.563615652900634\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between L_vlpfc and L_anterior_caudate: r=0.34259195147549354, p=2.2223792057692907e-34, z-score=0.35702620631877163\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between L_vlpfc and L_anterior_caudate: r=0.4229431751696851, p=2.9105188000603913e-53, z-score=0.4512709596358618\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between L_vlpfc and L_anterior_caudate: r=0.4119104373300318, p=2.3833420561530044e-50, z-score=0.4379098663115289\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between L_vlpfc and L_anterior_caudate: r=0.30901174343450266, p=5.772902420866408e-28, z-score=0.31945245419431695\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between L_vlpfc and L_anterior_caudate: r=0.5951635897640473, p=6.731604218732528e-116, z-score=0.6856242569557994\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between L_vlpfc and L_anterior_caudate: r=0.4598997146148247, p=7.590664899105588e-64, z-score=0.4971840938656536\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between L_vlpfc and L_anterior_caudate: r=0.5285294686018265, p=2.6176770542300775e-87, z-score=0.5881024100679627\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between L_vlpfc and L_anterior_caudate: r=0.6250671291440473, p=4.744612851809571e-131, z-score=0.7332787026289282\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between L_vlpfc and L_anterior_caudate: r=0.36621073206364396, p=2.1710275613038596e-39, z-score=0.3840398917260269\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between L_vlpfc and L_anterior_caudate: r=0.26836561676814097, p=3.0545810525313288e-21, z-score=0.27510176100620953\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between L_vlpfc and L_anterior_caudate: r=0.4837002180368087, p=2.195234618031789e-71, z-score=0.5278034121662158\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between L_vlpfc and L_anterior_caudate: r=0.4183080490933787, p=5.025096130018069e-52, z-score=0.4456394559116187\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between L_vlpfc and L_anterior_caudate: r=0.6505058671854913, p=2.6423965330003577e-145, z-score=0.7761751659579162\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between L_vlpfc and L_anterior_caudate: r=0.10875152748169367, p=0.00016030505707160674, z-score=0.1091833267106551\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between L_vlpfc and L_anterior_caudate: r=0.6682351473503323, p=4.43344819449804e-156, z-score=0.8075475528963583\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between L_vlpfc and L_anterior_caudate: r=0.42694521397736007, p=2.3994000906025814e-54, z-score=0.4561549497715927\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between L_vlpfc and L_anterior_caudate: r=0.26001379415054054, p=5.401623736433871e-20, z-score=0.26612320117181043\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between L_vlpfc and L_anterior_caudate: r=0.2504165050493987, p=1.293183858010491e-18, z-score=0.25585713331482224\n",
      "Analyzing subject 123\n",
      ">> Subject 123: correlation between L_vlpfc and L_anterior_caudate: r=0.2725316981110034, p=7.013455886885355e-22, z-score=0.2795966157057582\n",
      "Analyzing subject 124\n",
      ">> Subject 124: correlation between L_vlpfc and L_anterior_caudate: r=0.3539242237164154, p=9.909031752064353e-37, z-score=0.3699228447476098\n",
      "Analyzing subject 125\n",
      ">> Subject 125: correlation between L_vlpfc and L_anterior_caudate: r=0.20545483650201907, p=6.645048237116346e-13, z-score=0.2084212014196482\n",
      "Analyzing subject 126\n",
      ">> Subject 126: correlation between L_vlpfc and L_anterior_caudate: r=0.36332957906311303, p=9.34921688676873e-39, z-score=0.38071653875341\n",
      "Analyzing subject 127\n",
      ">> Subject 127: correlation between L_vlpfc and L_anterior_caudate: r=0.7869144969718601, p=1.9073014455315938e-253, z-score=1.0632760794703728\n",
      "Analyzing subject 128\n",
      ">> Subject 128: correlation between L_vlpfc and L_anterior_caudate: r=0.6382020097011849, p=3.0511734118152286e-138, z-score=0.7551342828193182\n",
      "Analyzing subject 129\n",
      ">> Subject 129: correlation between L_vlpfc and L_anterior_caudate: r=0.3841752405020151, p=1.7151858590916156e-43, z-score=0.4049486526476862\n",
      "Analyzing subject 130\n",
      ">> Subject 130: correlation between L_vlpfc and L_anterior_caudate: r=0.32113633130541175, p=3.4532699487997525e-30, z-score=0.33291358869402937\n",
      "Analyzing subject 131\n",
      ">> Subject 131: correlation between L_vlpfc and L_anterior_caudate: r=0.5414420213363615, p=2.3536854552910418e-92, z-score=0.6061934490746347\n",
      "Analyzing subject 132\n",
      ">> Subject 132: correlation between L_vlpfc and L_anterior_caudate: r=0.4007043734866653, p=1.6845860830852403e-47, z-score=0.4244877516094298\n",
      "Analyzing subject 133\n",
      ">> Subject 133: correlation between L_vlpfc and L_anterior_caudate: r=0.3851720608845919, p=9.978063435347426e-44, z-score=0.406118593862252\n",
      "Analyzing subject 134\n",
      ">> Subject 134: correlation between L_vlpfc and L_anterior_caudate: r=0.45282929984692427, p=1.0172117236906933e-61, z-score=0.4882536778284883\n",
      "Analyzing subject 135\n",
      ">> Subject 135: correlation between L_vlpfc and L_anterior_caudate: r=0.6759786349745194, p=5.0430358497241616e-161, z-score=0.8216715391386256\n",
      "Analyzing subject 136\n",
      ">> Subject 136: correlation between L_vlpfc and L_anterior_caudate: r=0.38850726202341535, p=1.6067392998448884e-44, z-score=0.410040728775753\n",
      "Analyzing subject 137\n",
      ">> Subject 137: correlation between L_vlpfc and L_anterior_caudate: r=0.2866532034956127, p=3.943500286143776e-24, z-score=0.2949160086788061\n",
      "Analyzing subject 138\n",
      ">> Subject 138: correlation between L_vlpfc and L_anterior_caudate: r=0.438364073610412, p=1.607602350644143e-57, z-score=0.47020393230750834\n",
      "Analyzing subject 139\n",
      ">> Subject 139: correlation between L_vlpfc and L_anterior_caudate: r=0.22629993205073776, p=2.1179040463285e-15, z-score=0.230286219989403\n",
      "Analyzing subject 140\n",
      ">> Subject 140: correlation between L_vlpfc and L_anterior_caudate: r=0.3001595958518912, p=2.0897699978859284e-26, z-score=0.3096949934898683\n",
      "Analyzing subject 141\n",
      ">> Subject 141: correlation between L_vlpfc and L_anterior_caudate: r=0.38649923931163394, p=4.836658018198447e-44, z-score=0.4076779061751823\n",
      "Analyzing subject 142\n",
      ">> Subject 142: correlation between L_vlpfc and L_anterior_caudate: r=0.1741786079084387, p=1.248238450678307e-09, z-score=0.17597280360999393\n",
      "Analyzing subject 143\n",
      ">> Subject 143: correlation between L_vlpfc and L_anterior_caudate: r=0.558271157412987, p=2.860586767258181e-99, z-score=0.6303180188797083\n",
      "Analyzing subject 144\n",
      ">> Subject 144: correlation between L_vlpfc and L_anterior_caudate: r=0.7190647865539102, p=1.4476746599344666e-191, z-score=0.9057058037828402\n",
      "Analyzing subject 145\n",
      ">> Subject 145: correlation between L_vlpfc and L_anterior_caudate: r=0.4032343943308927, p=3.9146109745331196e-48, z-score=0.42750535834673403\n",
      "Analyzing subject 148\n",
      ">> Subject 148: correlation between L_vlpfc and L_anterior_caudate: r=0.17881268168206138, p=4.4280786493481873e-10, z-score=0.18075588338770215\n",
      "Analyzing subject 149\n",
      ">> Subject 149: correlation between L_vlpfc and L_anterior_caudate: r=0.14282428003014044, p=6.767801190796118e-07, z-score=0.14380748891742157\n",
      "Analyzing subject 152\n",
      ">> Subject 152: correlation between L_vlpfc and L_anterior_caudate: r=0.045706898128746495, p=0.11353310569591897, z-score=0.04573876715842183\n",
      "Analyzing subject 153\n",
      ">> Subject 153: correlation between L_vlpfc and L_anterior_caudate: r=0.47494569672734854, p=1.5272674283434572e-68, z-score=0.5164373801352352\n",
      "Analyzing subject 154\n",
      ">> Subject 154: correlation between L_vlpfc and L_anterior_caudate: r=0.3447150557032572, p=8.198436275776504e-35, z-score=0.35943362229892\n",
      "Analyzing subject 155\n",
      ">> Subject 155: correlation between L_vlpfc and L_anterior_caudate: r=0.348491387324784, p=1.3648463394248333e-35, z-score=0.36372556973176207\n",
      "Analyzing connectivity between R_vlpfc and R_anterior_caudate\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_vlpfc and R_anterior_caudate: r=0.40901468497109994, p=1.3302465262255136e-49, z-score=0.43442738233930617\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_vlpfc and R_anterior_caudate: r=0.4954597520479333, p=2.4612969135950775e-75, z-score=0.5432706752435521\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_vlpfc and R_anterior_caudate: r=0.7206170804955201, p=8.977319844969109e-193, z-score=0.9089274805050128\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_vlpfc and R_anterior_caudate: r=0.4974360279400459, p=5.152618963878842e-76, z-score=0.5458933352130522\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_vlpfc and R_anterior_caudate: r=0.37039477990923897, p=2.5363229969030387e-40, z-score=0.3888805748191088\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_vlpfc and R_anterior_caudate: r=0.401059850414507, p=1.3733221521268007e-47, z-score=0.4249112946513211\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_vlpfc and R_anterior_caudate: r=0.16343744325987983, p=1.2404861632720576e-08, z-score=0.1649164568788345\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_vlpfc and R_anterior_caudate: r=0.7600490312263493, p=1.7548195636400427e-226, z-score=0.9963311703006902\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_vlpfc and R_anterior_caudate: r=0.4870627513561684, p=1.6889102382310245e-72, z-score=0.532202315091607\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_vlpfc and R_anterior_caudate: r=0.72550108936665, p=1.2581136387868394e-196, z-score=0.9191627407394338\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_vlpfc and R_anterior_caudate: r=0.5837863244899868, p=1.5290354562484995e-110, z-score=0.6681874478375072\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_vlpfc and R_anterior_caudate: r=0.046301129993449625, p=0.10891116020781201, z-score=0.04633425932213603\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_vlpfc and R_anterior_caudate: r=0.2829693858521005, p=1.568410581477218e-23, z-score=0.29090698285427824\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_vlpfc and R_anterior_caudate: r=0.4578417128390398, p=3.195942180892296e-63, z-score=0.49457717027844905\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_vlpfc and R_anterior_caudate: r=0.6393484884556678, p=6.918743376654822e-139, z-score=0.7570710143218908\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_vlpfc and R_anterior_caudate: r=0.7402186442513732, p=9.22207933734641e-209, z-score=0.950962852065399\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_vlpfc and R_anterior_caudate: r=0.4205899125937114, p=1.243101025833626e-52, z-score=0.4484085002288259\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_vlpfc and R_anterior_caudate: r=0.6625188879961205, p=1.590673340944619e-152, z-score=0.7972897946762888\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_vlpfc and R_anterior_caudate: r=0.42886531291960744, p=7.159413338947914e-55, z-score=0.45850542983315473\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_vlpfc and R_anterior_caudate: r=0.3981871414196806, p=7.106684667338158e-47, z-score=0.4214926233384949\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_vlpfc and R_anterior_caudate: r=0.3726613284774266, p=7.821688083698162e-41, z-score=0.3915100846088129\n",
      "Analyzing subject 123\n",
      ">> Subject 123: correlation between R_vlpfc and R_anterior_caudate: r=0.5742066395563583, p=3.411414000002954e-106, z-score=0.6537762721145488\n",
      "Analyzing subject 124\n",
      ">> Subject 124: correlation between R_vlpfc and R_anterior_caudate: r=0.2874523386390532, p=2.9149326691960156e-24, z-score=0.2957869051380919\n",
      "Analyzing subject 125\n",
      ">> Subject 125: correlation between R_vlpfc and R_anterior_caudate: r=0.2700484122100431, p=1.6911418674187116e-21, z-score=0.27691604236458817\n",
      "Analyzing subject 126\n",
      ">> Subject 126: correlation between R_vlpfc and R_anterior_caudate: r=0.529800919932309, p=8.524811104332905e-88, z-score=0.589868354297664\n",
      "Analyzing subject 127\n",
      ">> Subject 127: correlation between R_vlpfc and R_anterior_caudate: r=0.8428314892758073, p=0.0, z-score=1.2308699870895976\n",
      "Analyzing subject 128\n",
      ">> Subject 128: correlation between R_vlpfc and R_anterior_caudate: r=0.7114429240948428, p=9.397742868682627e-186, z-score=0.8900996029021048\n",
      "Analyzing subject 129\n",
      ">> Subject 129: correlation between R_vlpfc and R_anterior_caudate: r=0.5018211317386034, p=1.5456367227392817e-77, z-score=0.5517372763771727\n",
      "Analyzing subject 130\n",
      ">> Subject 130: correlation between R_vlpfc and R_anterior_caudate: r=0.333088144921093, p=1.756562262670387e-32, z-score=0.3462977786688869\n",
      "Analyzing subject 131\n",
      ">> Subject 131: correlation between R_vlpfc and R_anterior_caudate: r=0.5216923651600387, p=1.006270511104436e-84, z-score=0.5786621397974014\n",
      "Analyzing subject 132\n",
      ">> Subject 132: correlation between R_vlpfc and R_anterior_caudate: r=0.5133075663662094, p=1.2391804328327118e-81, z-score=0.5672103025682611\n",
      "Analyzing subject 133\n",
      ">> Subject 133: correlation between R_vlpfc and R_anterior_caudate: r=0.4606678783224612, p=4.427427258943541e-64, z-score=0.49815874932109455\n",
      "Analyzing subject 134\n",
      ">> Subject 134: correlation between R_vlpfc and R_anterior_caudate: r=0.3875614870512528, p=2.7025885410608265e-44, z-score=0.4089273046366447\n",
      "Analyzing subject 135\n",
      ">> Subject 135: correlation between R_vlpfc and R_anterior_caudate: r=0.49873539896848584, p=1.8326235636333942e-76, z-score=0.5476214283591753\n",
      "Analyzing subject 136\n",
      ">> Subject 136: correlation between R_vlpfc and R_anterior_caudate: r=0.31304227503550164, p=1.0808660971872305e-28, z-score=0.32391465822736365\n",
      "Analyzing subject 137\n",
      ">> Subject 137: correlation between R_vlpfc and R_anterior_caudate: r=0.8488313436819412, p=0.0, z-score=1.2519564347859684\n",
      "Analyzing subject 138\n",
      ">> Subject 138: correlation between R_vlpfc and R_anterior_caudate: r=0.5949356939443006, p=8.659988977388201e-116, z-score=0.6852714311215851\n",
      "Analyzing subject 139\n",
      ">> Subject 139: correlation between R_vlpfc and R_anterior_caudate: r=0.499265470711151, p=1.2005151598845414e-76, z-score=0.548327250986657\n",
      "Analyzing subject 140\n",
      ">> Subject 140: correlation between R_vlpfc and R_anterior_caudate: r=0.510964126237585, p=8.740584478919036e-81, z-score=0.5640336859969846\n",
      "Analyzing subject 141\n",
      ">> Subject 141: correlation between R_vlpfc and R_anterior_caudate: r=0.721803301344428, p=1.0588621500060374e-193, z-score=0.9113995194926106\n",
      "Analyzing subject 142\n",
      ">> Subject 142: correlation between R_vlpfc and R_anterior_caudate: r=0.6475828930686462, p=1.347333595259765e-143, z-score=0.7711245713057504\n",
      "Analyzing subject 143\n",
      ">> Subject 143: correlation between R_vlpfc and R_anterior_caudate: r=0.5750389170825905, p=1.4481825503743946e-106, z-score=0.6550188325438415\n",
      "Analyzing subject 144\n",
      ">> Subject 144: correlation between R_vlpfc and R_anterior_caudate: r=0.5911417515678363, p=5.5713175792568136e-114, z-score=0.6794193025719819\n",
      "Analyzing subject 145\n",
      ">> Subject 145: correlation between R_vlpfc and R_anterior_caudate: r=0.47349025539156264, p=4.4516575680745e-68, z-score=0.5145596746177354\n",
      "Analyzing subject 148\n",
      ">> Subject 148: correlation between R_vlpfc and R_anterior_caudate: r=0.3389954852935342, p=1.1825582332248845e-33, z-score=0.3529571520206606\n",
      "Analyzing subject 149\n",
      ">> Subject 149: correlation between R_vlpfc and R_anterior_caudate: r=0.439438084773653, p=7.968083292899251e-58, z-score=0.4715341984103957\n",
      "Analyzing subject 152\n",
      ">> Subject 152: correlation between R_vlpfc and R_anterior_caudate: r=0.5642158004992848, p=8.274180747552709e-102, z-score=0.638996362950569\n",
      "Analyzing subject 153\n",
      ">> Subject 153: correlation between R_vlpfc and R_anterior_caudate: r=0.6321965750564147, p=6.543008310591871e-135, z-score=0.7450666772865321\n",
      "Analyzing subject 154\n",
      ">> Subject 154: correlation between R_vlpfc and R_anterior_caudate: r=0.38582131500982836, p=7.004445557360994e-44, z-score=0.40688117319024864\n",
      "Analyzing subject 155\n",
      ">> Subject 155: correlation between R_vlpfc and R_anterior_caudate: r=0.44679687849016214, p=6.0686296663225e-60, z-score=0.4806910500657877\n",
      "Analyzing connectivity between R_frontopolar and R_anterior_caudate\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_frontopolar and R_anterior_caudate: r=0.46924161751876825, p=9.817752357847673e-67, z-score=0.5090973730429904\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_frontopolar and R_anterior_caudate: r=0.45654506217786217, p=7.866196217313831e-63, z-score=0.4929378612806047\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_frontopolar and R_anterior_caudate: r=0.6571606266728294, p=2.9053509059582198e-149, z-score=0.7877994564160059\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_frontopolar and R_anterior_caudate: r=0.4581886692120144, p=2.5098327681039336e-63, z-score=0.49501623214312523\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_frontopolar and R_anterior_caudate: r=0.3267607717042098, p=2.9626055534301763e-31, z-score=0.3391975042685197\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_frontopolar and R_anterior_caudate: r=0.5505301439787442, p=4.856256994114029e-96, z-score=0.6191416946385645\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_frontopolar and R_anterior_caudate: r=0.5646395346051183, p=5.429871833239831e-102, z-score=0.6396182015478009\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_frontopolar and R_anterior_caudate: r=0.7401980638741139, p=9.602238991268736e-209, z-score=0.9509173294819079\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_frontopolar and R_anterior_caudate: r=0.42244761067112935, p=3.9552059809282338e-53, z-score=0.4506675902673164\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_frontopolar and R_anterior_caudate: r=0.5787277208842672, p=3.152326270425602e-108, z-score=0.6605475966589518\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_frontopolar and R_anterior_caudate: r=0.7045887390220102, p=1.0971581659407694e-180, z-score=0.876355330674786\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_frontopolar and R_anterior_caudate: r=0.40018283538751265, p=2.2722943625830873e-47, z-score=0.4238666103248553\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_frontopolar and R_anterior_caudate: r=0.3835409326662734, p=2.4187658531655776e-43, z-score=0.40420472997255696\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_frontopolar and R_anterior_caudate: r=0.6948587621618301, p=9.712996561839911e-174, z-score=0.8572899729419734\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_frontopolar and R_anterior_caudate: r=0.6394073442262753, p=6.4101765815177144e-139, z-score=0.7571705680784327\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_frontopolar and R_anterior_caudate: r=0.6765708909118956, p=2.081108012100046e-161, z-score=0.8227629487181439\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_frontopolar and R_anterior_caudate: r=0.4789563889179911, p=7.797474581028359e-70, z-score=0.5216291153318173\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_frontopolar and R_anterior_caudate: r=0.5580025294656158, p=3.71505784558609e-99, z-score=0.6299278453373552\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_frontopolar and R_anterior_caudate: r=0.49268234415457307, p=2.1782543581015075e-74, z-score=0.5395963319580813\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_frontopolar and R_anterior_caudate: r=0.5334402898874391, p=3.34593306490449e-89, z-score=0.5949415188000596\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_frontopolar and R_anterior_caudate: r=0.4428441541381137, p=8.46003959154613e-59, z-score=0.4757632778874536\n",
      "Analyzing subject 123\n",
      ">> Subject 123: correlation between R_frontopolar and R_anterior_caudate: r=0.5376223499117774, p=7.714741220750331e-91, z-score=0.6008052960436243\n",
      "Analyzing subject 124\n",
      ">> Subject 124: correlation between R_frontopolar and R_anterior_caudate: r=0.43659841276184685, p=5.0691028650644885e-57, z-score=0.46802035604763026\n",
      "Analyzing subject 125\n",
      ">> Subject 125: correlation between R_frontopolar and R_anterior_caudate: r=0.3367891522717904, p=3.262003610984636e-33, z-score=0.350466451108061\n",
      "Analyzing subject 126\n",
      ">> Subject 126: correlation between R_frontopolar and R_anterior_caudate: r=0.5574603516764702, p=6.2914456209840386e-99, z-score=0.6291408663924354\n",
      "Analyzing subject 127\n",
      ">> Subject 127: correlation between R_frontopolar and R_anterior_caudate: r=0.8015654034175789, p=7.339542436580019e-270, z-score=1.1029758384613402\n",
      "Analyzing subject 128\n",
      ">> Subject 128: correlation between R_frontopolar and R_anterior_caudate: r=0.5375540721633982, p=8.207972719117282e-91, z-score=0.6007092653085518\n",
      "Analyzing subject 129\n",
      ">> Subject 129: correlation between R_frontopolar and R_anterior_caudate: r=0.3920528867567239, p=2.2527137153627116e-45, z-score=0.4142234700734121\n",
      "Analyzing subject 130\n",
      ">> Subject 130: correlation between R_frontopolar and R_anterior_caudate: r=0.24687834872219716, p=4.032470447980275e-18, z-score=0.25208580776679373\n",
      "Analyzing subject 131\n",
      ">> Subject 131: correlation between R_frontopolar and R_anterior_caudate: r=0.4315654446840357, p=1.2897994541020606e-55, z-score=0.46181882633236204\n",
      "Analyzing subject 132\n",
      ">> Subject 132: correlation between R_frontopolar and R_anterior_caudate: r=0.633209812872638, p=1.8150476426099272e-135, z-score=0.7467562902131452\n",
      "Analyzing subject 133\n",
      ">> Subject 133: correlation between R_frontopolar and R_anterior_caudate: r=0.5464168964106112, p=2.33528579917112e-94, z-score=0.6132586759922007\n",
      "Analyzing subject 134\n",
      ">> Subject 134: correlation between R_frontopolar and R_anterior_caudate: r=0.39293228697184324, p=1.3786703613559633e-45, z-score=0.41526301233795276\n",
      "Analyzing subject 135\n",
      ">> Subject 135: correlation between R_frontopolar and R_anterior_caudate: r=0.5934717309642221, p=4.347015685255395e-115, z-score=0.683008462194852\n",
      "Analyzing subject 136\n",
      ">> Subject 136: correlation between R_frontopolar and R_anterior_caudate: r=0.5026132096892955, p=8.159267088103878e-78, z-score=0.5527965187893281\n",
      "Analyzing subject 137\n",
      ">> Subject 137: correlation between R_frontopolar and R_anterior_caudate: r=0.4491945322384947, p=1.206699798367862e-60, z-score=0.48369074615579133\n",
      "Analyzing subject 138\n",
      ">> Subject 138: correlation between R_frontopolar and R_anterior_caudate: r=0.6163613972513224, p=1.8038413516944925e-126, z-score=0.7191159401138205\n",
      "Analyzing subject 139\n",
      ">> Subject 139: correlation between R_frontopolar and R_anterior_caudate: r=0.4538315644790524, p=5.11583022825176e-62, z-score=0.4895151951923363\n",
      "Analyzing subject 140\n",
      ">> Subject 140: correlation between R_frontopolar and R_anterior_caudate: r=0.6042000660800266, p=2.6219665761415824e-120, z-score=0.6997358219546669\n",
      "Analyzing subject 141\n",
      ">> Subject 141: correlation between R_frontopolar and R_anterior_caudate: r=0.7203737563998027, p=1.3898568259196372e-192, z-score=0.9084214896238332\n",
      "Analyzing subject 142\n",
      ">> Subject 142: correlation between R_frontopolar and R_anterior_caudate: r=0.6133412196792231, p=6.482321854081793e-125, z-score=0.7142599998796836\n",
      "Analyzing subject 143\n",
      ">> Subject 143: correlation between R_frontopolar and R_anterior_caudate: r=0.6946491532845633, p=1.361275026373701e-173, z-score=0.8568847882886252\n",
      "Analyzing subject 144\n",
      ">> Subject 144: correlation between R_frontopolar and R_anterior_caudate: r=0.7293845104831619, p=9.454358687909777e-200, z-score=0.927410947212833\n",
      "Analyzing subject 145\n",
      ">> Subject 145: correlation between R_frontopolar and R_anterior_caudate: r=0.5048197294408151, p=1.364176685593427e-78, z-score=0.5557532548440869\n",
      "Analyzing subject 148\n",
      ">> Subject 148: correlation between R_frontopolar and R_anterior_caudate: r=0.5910313565454639, p=6.283767916249674e-114, z-score=0.6792496250562404\n",
      "Analyzing subject 149\n",
      ">> Subject 149: correlation between R_frontopolar and R_anterior_caudate: r=0.5793721079454526, p=1.6072614831629536e-108, z-score=0.6615170355071096\n",
      "Analyzing subject 152\n",
      ">> Subject 152: correlation between R_frontopolar and R_anterior_caudate: r=0.3967431954364339, p=1.6138110209056582e-46, z-score=0.419777766166923\n",
      "Analyzing subject 153\n",
      ">> Subject 153: correlation between R_frontopolar and R_anterior_caudate: r=0.48729250285042125, p=1.4159396451557375e-72, z-score=0.5325035661233711\n",
      "Analyzing subject 154\n",
      ">> Subject 154: correlation between R_frontopolar and R_anterior_caudate: r=0.31662422482781927, p=2.385714255948835e-29, z-score=0.3278907214279346\n",
      "Analyzing subject 155\n",
      ">> Subject 155: correlation between R_frontopolar and R_anterior_caudate: r=0.3189424871407045, p=8.874577662203742e-30, z-score=0.33046939613222615\n",
      "Analyzing connectivity between R_frontopolar and R_post_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_frontopolar and R_post_putamen: r=0.5378852410015651, p=6.076228447945276e-91, z-score=0.6011751376054751\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_frontopolar and R_post_putamen: r=0.22073320335207133, p=1.0418477075108778e-14, z-score=0.22442673512823663\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_frontopolar and R_post_putamen: r=0.5696964184758797, p=3.396361135163351e-104, z-score=0.6470732762441039\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_frontopolar and R_post_putamen: r=0.33483652650343143, p=7.952362572415301e-33, z-score=0.3482656380131864\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_frontopolar and R_post_putamen: r=0.3114715659049987, p=2.082914950766065e-28, z-score=0.32217425127604987\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_frontopolar and R_post_putamen: r=0.23998384030653092, p=3.51381033855893e-17, z-score=0.2447569653472053\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_frontopolar and R_post_putamen: r=0.34290357087736273, p=1.9207093001422512e-34, z-score=0.3573793065359454\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_frontopolar and R_post_putamen: r=0.602385161938281, p=2.0681531175031413e-119, z-score=0.6968823656276096\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_frontopolar and R_post_putamen: r=0.4614838486649922, p=2.4934262463024632e-64, z-score=0.49919502197262977\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_frontopolar and R_post_putamen: r=0.5612762147884474, p=1.5119738065434986e-100, z-score=0.6346944140033398\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_frontopolar and R_post_putamen: r=0.5723831222137941, p=2.210591121455841e-105, z-score=0.651060005187755\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_frontopolar and R_post_putamen: r=0.033987642901108936, p=0.23940337203144962, z-score=0.034000739032901614\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_frontopolar and R_post_putamen: r=0.18890732943146107, p=4.206875346222084e-11, z-score=0.19120381955195492\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_frontopolar and R_post_putamen: r=0.534261978057845, p=1.601969736759915e-89, z-score=0.5960907284905945\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_frontopolar and R_post_putamen: r=0.4210764517701552, p=9.216222576813352e-53, z-score=0.4489997501176578\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_frontopolar and R_post_putamen: r=0.6076372699167916, p=5.057930681036216e-122, z-score=0.7051670510512654\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_frontopolar and R_post_putamen: r=0.3586609608006946, p=9.65126817531437e-38, z-score=0.3753483333301806\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_frontopolar and R_post_putamen: r=0.8166446465675101, p=2.924088643617557e-288, z-score=1.146660192891317\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_frontopolar and R_post_putamen: r=0.3600297591430125, p=4.887556301406987e-38, z-score=0.37692009180091757\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_frontopolar and R_post_putamen: r=0.45846394527447665, p=2.0715132817829804e-63, z-score=0.4953647106526347\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_frontopolar and R_post_putamen: r=0.2256905508619572, p=2.5266814308662505e-15, z-score=0.2296440401818462\n",
      "Analyzing subject 123\n",
      ">> Subject 123: correlation between R_frontopolar and R_post_putamen: r=0.3258346261487981, p=4.455049341763121e-31, z-score=0.3381610020134068\n",
      "Analyzing subject 124\n",
      ">> Subject 124: correlation between R_frontopolar and R_post_putamen: r=0.40318743512059363, p=4.0225602248545784e-48, z-score=0.4274492823554958\n",
      "Analyzing subject 125\n",
      ">> Subject 125: correlation between R_frontopolar and R_post_putamen: r=0.057779327214675706, p=0.04537939685044521, z-score=0.05784375412653469\n",
      "Analyzing subject 126\n",
      ">> Subject 126: correlation between R_frontopolar and R_post_putamen: r=0.405351391843703, p=1.1432028034369426e-48, z-score=0.4300359974468083\n",
      "Analyzing subject 127\n",
      ">> Subject 127: correlation between R_frontopolar and R_post_putamen: r=0.47092067872839255, p=2.9062103575178752e-67, z-score=0.5112527147353914\n",
      "Analyzing subject 128\n",
      ">> Subject 128: correlation between R_frontopolar and R_post_putamen: r=0.5415716494605971, p=2.089160326193284e-92, z-score=0.6063768581910883\n",
      "Analyzing subject 129\n",
      ">> Subject 129: correlation between R_frontopolar and R_post_putamen: r=0.46741940519020553, p=3.6512986621990545e-66, z-score=0.5067631962526588\n",
      "Analyzing subject 130\n",
      ">> Subject 130: correlation between R_frontopolar and R_post_putamen: r=0.2723252183066021, p=7.548609063212932e-22, z-score=0.27937358302475596\n",
      "Analyzing subject 131\n",
      ">> Subject 131: correlation between R_frontopolar and R_post_putamen: r=0.29372369402503506, p=2.62914910696793e-25, z-score=0.3026366972605244\n",
      "Analyzing subject 132\n",
      ">> Subject 132: correlation between R_frontopolar and R_post_putamen: r=0.5191436375982679, p=8.938554750774041e-84, z-score=0.5751667280561998\n",
      "Analyzing subject 133\n",
      ">> Subject 133: correlation between R_frontopolar and R_post_putamen: r=0.4745406654275862, p=2.0579493770517144e-68, z-score=0.5159145019703149\n",
      "Analyzing subject 134\n",
      ">> Subject 134: correlation between R_frontopolar and R_post_putamen: r=0.5267545610403035, p=1.2434191470075213e-86, z-score=0.5856427035855637\n",
      "Analyzing subject 135\n",
      ">> Subject 135: correlation between R_frontopolar and R_post_putamen: r=0.6048451486268605, p=1.2543606302923066e-120, z-score=0.7007524167162876\n",
      "Analyzing subject 136\n",
      ">> Subject 136: correlation between R_frontopolar and R_post_putamen: r=0.5776473330047318, p=9.719736190888583e-108, z-score=0.6589246588801806\n",
      "Analyzing subject 137\n",
      ">> Subject 137: correlation between R_frontopolar and R_post_putamen: r=0.3024720963923071, p=8.281162454713327e-27, z-score=0.3122384161075389\n",
      "Analyzing subject 138\n",
      ">> Subject 138: correlation between R_frontopolar and R_post_putamen: r=0.49897296556833515, p=1.5162834165620143e-76, z-score=0.5479377011958657\n",
      "Analyzing subject 139\n",
      ">> Subject 139: correlation between R_frontopolar and R_post_putamen: r=0.5558291730988589, p=3.051593997439025e-98, z-score=0.6267773395378281\n",
      "Analyzing subject 140\n",
      ">> Subject 140: correlation between R_frontopolar and R_post_putamen: r=0.601775984121244, p=4.124365282700109e-119, z-score=0.6959267909059355\n",
      "Analyzing subject 141\n",
      ">> Subject 141: correlation between R_frontopolar and R_post_putamen: r=0.6997892005007563, p=3.178938589404221e-177, z-score=0.8668873148750286\n",
      "Analyzing subject 142\n",
      ">> Subject 142: correlation between R_frontopolar and R_post_putamen: r=0.48014249310539303, p=3.210489768108014e-70, z-score=0.5231694462139304\n",
      "Analyzing subject 143\n",
      ">> Subject 143: correlation between R_frontopolar and R_post_putamen: r=0.6607135533776469, p=2.032476424844558e-151, z-score=0.794078957273132\n",
      "Analyzing subject 144\n",
      ">> Subject 144: correlation between R_frontopolar and R_post_putamen: r=0.6599593060177771, p=5.861502084028766e-151, z-score=0.7927415339859131\n",
      "Analyzing subject 145\n",
      ">> Subject 145: correlation between R_frontopolar and R_post_putamen: r=0.4918021153179873, p=4.329148120491541e-74, z-score=0.5384346164896192\n",
      "Analyzing subject 148\n",
      ">> Subject 148: correlation between R_frontopolar and R_post_putamen: r=0.3960577828743007, p=2.3785349235436057e-46, z-score=0.41896457393073433\n",
      "Analyzing subject 149\n",
      ">> Subject 149: correlation between R_frontopolar and R_post_putamen: r=0.1551532649615794, p=6.597262413686553e-08, z-score=0.15641653941777336\n",
      "Analyzing subject 152\n",
      ">> Subject 152: correlation between R_frontopolar and R_post_putamen: r=0.26346666006417674, p=1.667760688183033e-20, z-score=0.26983001827976055\n",
      "Analyzing subject 153\n",
      ">> Subject 153: correlation between R_frontopolar and R_post_putamen: r=0.3556579749503398, p=4.244359068051252e-37, z-score=0.3719062629505856\n",
      "Analyzing subject 154\n",
      ">> Subject 154: correlation between R_frontopolar and R_post_putamen: r=0.29224304312798516, p=4.665148002001321e-25, z-score=0.30101701351124716\n",
      "Analyzing subject 155\n",
      ">> Subject 155: correlation between R_frontopolar and R_post_putamen: r=0.16866364053879326, p=4.1336383931475544e-09, z-score=0.1702908548849308\n",
      "Analyzing connectivity between R_post_putamen and L_post_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_post_putamen and L_post_putamen: r=0.6844817584504432, p=1.246894920318081e-166, z-score=0.8374983677563067\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_post_putamen and L_post_putamen: r=0.543006630281459, p=5.562778741935148e-93, z-score=0.6084096334231379\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_post_putamen and L_post_putamen: r=0.7511854263509411, p=2.3558961123517443e-218, z-score=0.9756701445858628\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_post_putamen and L_post_putamen: r=0.780374398877201, p=1.564854442096964e-246, z-score=1.0463273370355501\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_post_putamen and L_post_putamen: r=0.7050396252568051, p=5.14559567083846e-181, z-score=0.8772513028270593\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_post_putamen and L_post_putamen: r=0.5441845962341815, p=1.8683518643835353e-93, z-score=0.6100816846668545\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_post_putamen and L_post_putamen: r=0.6368388079402734, p=1.7667090054299874e-137, z-score=0.7528376567973883\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_post_putamen and L_post_putamen: r=0.6443979732931618, p=9.30430096954665e-142, z-score=0.7656587097543635\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_post_putamen and L_post_putamen: r=0.6573917925893351, p=2.107984609397276e-149, z-score=0.7882064472859557\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_post_putamen and L_post_putamen: r=0.7117889581580558, p=5.167242230876438e-186, z-score=0.8908006405224936\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_post_putamen and L_post_putamen: r=0.6434595724690257, p=3.209260747111955e-141, z-score=0.7640555798655235\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_post_putamen and L_post_putamen: r=0.6556222124323066, p=2.4395957437558055e-148, z-score=0.785096450942484\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_post_putamen and L_post_putamen: r=0.5288962217406854, p=1.8948980922091209e-87, z-score=0.5886114622916203\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_post_putamen and L_post_putamen: r=0.6510712055381769, p=1.2290441342107707e-145, z-score=0.7771558488335535\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_post_putamen and L_post_putamen: r=0.8088507506717011, p=1.516997975563446e-278, z-score=1.123696222608264\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_post_putamen and L_post_putamen: r=0.6289734336422022, p=3.7456210625732e-133, z-score=0.7397158163038693\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_post_putamen and L_post_putamen: r=0.4605908494934806, p=4.673648029782629e-64, z-score=0.4980609747387263\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_post_putamen and L_post_putamen: r=0.3364297312395673, p=3.845311659491739e-33, z-score=0.35006110156821874\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_post_putamen and L_post_putamen: r=0.3756201646413245, p=1.66031338754453e-41, z-score=0.39495052177838336\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_post_putamen and L_post_putamen: r=0.8099055409310296, p=7.808943679376098e-280, z-score=1.1267544169758408\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_post_putamen and L_post_putamen: r=0.538031431035807, p=5.320291134857053e-91, z-score=0.6013808649692766\n",
      "Analyzing subject 123\n",
      ">> Subject 123: correlation between R_post_putamen and L_post_putamen: r=0.5369539570110906, p=1.4142654592070576e-90, z-score=0.5998656463230758\n",
      "Analyzing subject 124\n",
      ">> Subject 124: correlation between R_post_putamen and L_post_putamen: r=0.7228899222077022, p=1.479856260536901e-194, z-score=0.91367176360109\n",
      "Analyzing subject 125\n",
      ">> Subject 125: correlation between R_post_putamen and L_post_putamen: r=0.5204283747080733, p=2.9794690891952925e-84, z-score=0.576927070737782\n",
      "Analyzing subject 126\n",
      ">> Subject 126: correlation between R_post_putamen and L_post_putamen: r=0.5750771155819694, p=1.392256092728188e-106, z-score=0.6550759041514453\n",
      "Analyzing subject 127\n",
      ">> Subject 127: correlation between R_post_putamen and L_post_putamen: r=0.7206053848801091, p=9.16801631623458e-193, z-score=0.9089031511058585\n",
      "Analyzing subject 128\n",
      ">> Subject 128: correlation between R_post_putamen and L_post_putamen: r=0.7126264398003574, p=1.2105181195070725e-186, z-score=0.8925002139898375\n",
      "Analyzing subject 129\n",
      ">> Subject 129: correlation between R_post_putamen and L_post_putamen: r=0.24925938331744896, p=1.879512861159277e-18, z-score=0.2546229765813852\n",
      "Analyzing subject 130\n",
      ">> Subject 130: correlation between R_post_putamen and L_post_putamen: r=0.606921730835897, p=1.155184985582339e-121, z-score=0.7040334545952649\n",
      "Analyzing subject 131\n",
      ">> Subject 131: correlation between R_post_putamen and L_post_putamen: r=0.533499493794046, p=3.1732193821228274e-89, z-score=0.5950242740272096\n",
      "Analyzing subject 132\n",
      ">> Subject 132: correlation between R_post_putamen and L_post_putamen: r=0.12105579140826041, p=2.6154796775864292e-05, z-score=0.1216523834688163\n",
      "Analyzing subject 133\n",
      ">> Subject 133: correlation between R_post_putamen and L_post_putamen: r=0.6607723749465024, p=1.8710980386759314e-151, z-score=0.7941833584321503\n",
      "Analyzing subject 134\n",
      ">> Subject 134: correlation between R_post_putamen and L_post_putamen: r=0.6029923483087052, p=1.0378716040573547e-119, z-score=0.6978359124790465\n",
      "Analyzing subject 135\n",
      ">> Subject 135: correlation between R_post_putamen and L_post_putamen: r=0.4185085548383163, p=4.446587635431819e-52, z-score=0.4458825124793605\n",
      "Analyzing subject 136\n",
      ">> Subject 136: correlation between R_post_putamen and L_post_putamen: r=0.6730666205786624, p=3.7988626741465947e-159, z-score=0.8163285518684026\n",
      "Analyzing subject 137\n",
      ">> Subject 137: correlation between R_post_putamen and L_post_putamen: r=0.21699907301486218, p=2.962007992756566e-14, z-score=0.2205047257055806\n",
      "Analyzing subject 138\n",
      ">> Subject 138: correlation between R_post_putamen and L_post_putamen: r=0.7906751230117464, p=1.5601110193121003e-257, z-score=1.0732302554944846\n",
      "Analyzing subject 139\n",
      ">> Subject 139: correlation between R_post_putamen and L_post_putamen: r=0.4959945271985019, p=1.6137300489323558e-75, z-score=0.5439796867462077\n",
      "Analyzing subject 140\n",
      ">> Subject 140: correlation between R_post_putamen and L_post_putamen: r=0.4668925319173302, p=5.330164788356152e-66, z-score=0.5060892429508551\n",
      "Analyzing subject 141\n",
      ">> Subject 141: correlation between R_post_putamen and L_post_putamen: r=0.8268121742396393, p=1.1792065519860445e-301, z-score=1.1779755209706277\n",
      "Analyzing subject 142\n",
      ">> Subject 142: correlation between R_post_putamen and L_post_putamen: r=0.5822454875042281, p=7.827559445670566e-110, z-score=0.6658531711903111\n",
      "Analyzing subject 143\n",
      ">> Subject 143: correlation between R_post_putamen and L_post_putamen: r=0.8185739688577137, p=9.756560186153803e-291, z-score=1.1524799553159712\n",
      "Analyzing subject 144\n",
      ">> Subject 144: correlation between R_post_putamen and L_post_putamen: r=0.6927725818332452, p=2.7588800164874657e-172, z-score=0.8532673977324694\n",
      "Analyzing subject 145\n",
      ">> Subject 145: correlation between R_post_putamen and L_post_putamen: r=0.20018819291602566, p=2.5880199740837792e-12, z-score=0.20292859603031005\n",
      "Analyzing subject 148\n",
      ">> Subject 148: correlation between R_post_putamen and L_post_putamen: r=0.4509665345167571, p=3.626953003932199e-61, z-score=0.4859128960322654\n",
      "Analyzing subject 149\n",
      ">> Subject 149: correlation between R_post_putamen and L_post_putamen: r=0.6766372160581076, p=1.8844765274156752e-161, z-score=0.8228852731291831\n",
      "Analyzing subject 152\n",
      ">> Subject 152: correlation between R_post_putamen and L_post_putamen: r=0.09739074758330502, p=0.0007295352567209405, z-score=0.09770042759165379\n",
      "Analyzing subject 153\n",
      ">> Subject 153: correlation between R_post_putamen and L_post_putamen: r=0.7116970571004466, p=6.057392290377295e-186, z-score=0.8906143880275437\n",
      "Analyzing subject 154\n",
      ">> Subject 154: correlation between R_post_putamen and L_post_putamen: r=0.5255287387639194, p=3.627725025933741e-86, z-score=0.5839476465464581\n",
      "Analyzing subject 155\n",
      ">> Subject 155: correlation between R_post_putamen and L_post_putamen: r=0.4765937027999559, p=4.519841098257062e-69, z-score=0.5185675702982689\n",
      "Analyzing connectivity between R_anterior_caudate and L_anterior_caudate\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_anterior_caudate and L_anterior_caudate: r=0.7001379382006718, p=1.7908739567098663e-177, z-score=0.8675710459771909\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_anterior_caudate and L_anterior_caudate: r=0.7078877561306403, p=4.166193940220611e-183, z-score=0.8829372652091552\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_anterior_caudate and L_anterior_caudate: r=0.7579565527176042, p=1.5656255110426546e-224, z-score=0.9913950598162801\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_anterior_caudate and L_anterior_caudate: r=0.625081342013898, p=4.66234646036591e-131, z-score=0.7333020298652264\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_anterior_caudate and L_anterior_caudate: r=0.8560181320929091, p=0.0, z-score=1.278250654204577\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_anterior_caudate and L_anterior_caudate: r=0.5943021219364123, p=1.7425944004238943e-115, z-score=0.6842913192373048\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_anterior_caudate and L_anterior_caudate: r=0.7526401122861066, p=1.1533162192850243e-219, z-score=0.9790171271006262\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_anterior_caudate and L_anterior_caudate: r=0.8830074872824987, p=0.0, z-score=1.3892577830093433\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_anterior_caudate and L_anterior_caudate: r=0.656570539756578, p=6.581189524440751e-149, z-score=0.7867615348938208\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_anterior_caudate and L_anterior_caudate: r=0.8020535298463172, p=1.9732007940962577e-270, z-score=1.1043427510703405\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_anterior_caudate and L_anterior_caudate: r=0.8223555791479813, p=1.116913452708462e-295, z-score=1.1640506503915529\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_anterior_caudate and L_anterior_caudate: r=0.5494054455330031, p=1.4078425271036269e-95, z-score=0.6175293049725611\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_anterior_caudate and L_anterior_caudate: r=0.5262962043200421, p=1.8566018768350618e-86, z-score=0.5850085376674079\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_anterior_caudate and L_anterior_caudate: r=0.7395391524444517, p=3.492837410821656e-208, z-score=0.9494614748026222\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_anterior_caudate and L_anterior_caudate: r=0.8649247881770475, p=0.0, z-score=1.312572127646462\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_anterior_caudate and L_anterior_caudate: r=0.8339843502645219, p=1.214935188024e-311, z-score=1.201082030117894\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_anterior_caudate and L_anterior_caudate: r=0.6665800986204076, p=4.8319854243466004e-155, z-score=0.8045631499179392\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_anterior_caudate and L_anterior_caudate: r=0.4900192268946421, p=1.7295361371211294e-73, z-score=0.5360856387990424\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_anterior_caudate and L_anterior_caudate: r=0.46080142422356174, p=4.0307604761287986e-64, z-score=0.4983282832855785\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_anterior_caudate and L_anterior_caudate: r=0.7584167226209597, p=5.854124558504534e-225, z-score=0.9924774231100696\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_anterior_caudate and L_anterior_caudate: r=0.6668241803372341, p=3.400601277958928e-155, z-score=0.8050025344326064\n",
      "Analyzing subject 123\n",
      ">> Subject 123: correlation between R_anterior_caudate and L_anterior_caudate: r=0.5771104337336533, p=1.6982293258878753e-107, z-score=0.658119269969453\n",
      "Analyzing subject 124\n",
      ">> Subject 124: correlation between R_anterior_caudate and L_anterior_caudate: r=0.6017742126952021, p=4.13264302389066e-119, z-score=0.6959240137959908\n",
      "Analyzing subject 125\n",
      ">> Subject 125: correlation between R_anterior_caudate and L_anterior_caudate: r=0.6665995364488317, p=4.698733216323519e-155, z-score=0.8045981315575422\n",
      "Analyzing subject 126\n",
      ">> Subject 126: correlation between R_anterior_caudate and L_anterior_caudate: r=0.6244962401982207, p=9.571811910292679e-131, z-score=0.7323422783642071\n",
      "Analyzing subject 127\n",
      ">> Subject 127: correlation between R_anterior_caudate and L_anterior_caudate: r=0.919935127011341, p=0.0, z-score=1.5886047290078706\n",
      "Analyzing subject 128\n",
      ">> Subject 128: correlation between R_anterior_caudate and L_anterior_caudate: r=0.8135234345849933, p=2.578570032553002e-284, z-score=1.1373606521793407\n",
      "Analyzing subject 129\n",
      ">> Subject 129: correlation between R_anterior_caudate and L_anterior_caudate: r=0.642142251483178, p=1.8116516598982386e-140, z-score=0.7618106811973663\n",
      "Analyzing subject 130\n",
      ">> Subject 130: correlation between R_anterior_caudate and L_anterior_caudate: r=0.5913081433512943, p=4.6467363577123504e-114, z-score=0.6796751116305677\n",
      "Analyzing subject 131\n",
      ">> Subject 131: correlation between R_anterior_caudate and L_anterior_caudate: r=0.6498214143962748, p=6.660688093029507e-145, z-score=0.7749895292013406\n",
      "Analyzing subject 132\n",
      ">> Subject 132: correlation between R_anterior_caudate and L_anterior_caudate: r=0.5178404255266486, p=2.7112675794293006e-83, z-score=0.5733843521369925\n",
      "Analyzing subject 133\n",
      ">> Subject 133: correlation between R_anterior_caudate and L_anterior_caudate: r=0.7215728207578029, p=1.6054116281553499e-193, z-score=0.9109185161800818\n",
      "Analyzing subject 134\n",
      ">> Subject 134: correlation between R_anterior_caudate and L_anterior_caudate: r=0.6851741215118985, p=4.273856162445307e-167, z-score=0.838802227183565\n",
      "Analyzing subject 135\n",
      ">> Subject 135: correlation between R_anterior_caudate and L_anterior_caudate: r=0.8638579077765232, p=0.0, z-score=1.3083523132642947\n",
      "Analyzing subject 136\n",
      ">> Subject 136: correlation between R_anterior_caudate and L_anterior_caudate: r=0.7944028401027068, p=1.142003062633145e-261, z-score=1.0832544231036205\n",
      "Analyzing subject 137\n",
      ">> Subject 137: correlation between R_anterior_caudate and L_anterior_caudate: r=0.20902681575483678, p=2.587307104303155e-13, z-score=0.21215348218402488\n",
      "Analyzing subject 138\n",
      ">> Subject 138: correlation between R_anterior_caudate and L_anterior_caudate: r=0.7506001643748765, p=7.88362435466168e-218, z-score=0.9743282925151118\n",
      "Analyzing subject 139\n",
      ">> Subject 139: correlation between R_anterior_caudate and L_anterior_caudate: r=0.5980207147359694, p=2.81266532102369e-117, z-score=0.6900602655292162\n",
      "Analyzing subject 140\n",
      ">> Subject 140: correlation between R_anterior_caudate and L_anterior_caudate: r=0.6668051930690004, p=3.4948571136785588e-155, z-score=0.804968345202771\n",
      "Analyzing subject 141\n",
      ">> Subject 141: correlation between R_anterior_caudate and L_anterior_caudate: r=0.8513292015847159, p=0.0, z-score=1.260962346215087\n",
      "Analyzing subject 142\n",
      ">> Subject 142: correlation between R_anterior_caudate and L_anterior_caudate: r=0.6201986431859117, p=1.7999232421138167e-128, z-score=0.7253278345722193\n",
      "Analyzing subject 143\n",
      ">> Subject 143: correlation between R_anterior_caudate and L_anterior_caudate: r=0.8404192942081059, p=5.11e-321, z-score=1.2225994576251968\n",
      "Analyzing subject 144\n",
      ">> Subject 144: correlation between R_anterior_caudate and L_anterior_caudate: r=0.7752853203639658, p=2.5809732891071313e-241, z-score=1.0334424629339276\n",
      "Analyzing subject 145\n",
      ">> Subject 145: correlation between R_anterior_caudate and L_anterior_caudate: r=0.5356690949485601, p=4.516950148912352e-90, z-score=0.5980620010168137\n",
      "Analyzing subject 148\n",
      ">> Subject 148: correlation between R_anterior_caudate and L_anterior_caudate: r=0.7445528817733846, p=1.7081955510532364e-212, z-score=0.9606190795226811\n",
      "Analyzing subject 149\n",
      ">> Subject 149: correlation between R_anterior_caudate and L_anterior_caudate: r=0.7013805638068356, p=2.3019601601895696e-178, z-score=0.8700126613869062\n",
      "Analyzing subject 152\n",
      ">> Subject 152: correlation between R_anterior_caudate and L_anterior_caudate: r=0.1189435830075087, p=3.616537737559943e-05, z-score=0.11950931418797486\n",
      "Analyzing subject 153\n",
      ">> Subject 153: correlation between R_anterior_caudate and L_anterior_caudate: r=0.6994218327787557, p=5.813281802413242e-177, z-score=0.8661677649095075\n",
      "Analyzing subject 154\n",
      ">> Subject 154: correlation between R_anterior_caudate and L_anterior_caudate: r=0.7141809644512018, p=8.072507923132358e-188, z-score=0.8956659030302553\n",
      "Analyzing subject 155\n",
      ">> Subject 155: correlation between R_anterior_caudate and L_anterior_caudate: r=0.58601399941747, p=1.4201496327087629e-111, z-score=0.6715735353956733\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subID</th>\n",
       "      <th>L_SMA_L_post_putamen</th>\n",
       "      <th>R_SMA_R_post_putamen</th>\n",
       "      <th>L_premotor_L_post_putamen</th>\n",
       "      <th>R_premotor_R_post_putamen</th>\n",
       "      <th>L_anterior_caudate_vmpfc</th>\n",
       "      <th>R_anterior_caudate_vmpfc</th>\n",
       "      <th>L_vlpfc_L_post_putamen</th>\n",
       "      <th>R_vlpfc_R_post_putamen</th>\n",
       "      <th>L_vlpfc_L_anterior_putamen</th>\n",
       "      <th>R_vlpfc_R_anterior_putamen</th>\n",
       "      <th>L_vlpfc_L_anterior_caudate</th>\n",
       "      <th>R_vlpfc_R_anterior_caudate</th>\n",
       "      <th>R_frontopolar_R_anterior_caudate</th>\n",
       "      <th>R_frontopolar_R_post_putamen</th>\n",
       "      <th>R_post_putamen_L_post_putamen</th>\n",
       "      <th>R_anterior_caudate_L_anterior_caudate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>0.851216</td>\n",
       "      <td>0.998780</td>\n",
       "      <td>0.758278</td>\n",
       "      <td>1.088896</td>\n",
       "      <td>0.160140</td>\n",
       "      <td>0.171255</td>\n",
       "      <td>0.186758</td>\n",
       "      <td>0.724928</td>\n",
       "      <td>0.074329</td>\n",
       "      <td>0.486687</td>\n",
       "      <td>0.268736</td>\n",
       "      <td>0.434427</td>\n",
       "      <td>0.509097</td>\n",
       "      <td>0.601175</td>\n",
       "      <td>0.837498</td>\n",
       "      <td>0.867571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>0.772718</td>\n",
       "      <td>0.758162</td>\n",
       "      <td>0.784233</td>\n",
       "      <td>0.910795</td>\n",
       "      <td>0.497427</td>\n",
       "      <td>0.386723</td>\n",
       "      <td>0.470668</td>\n",
       "      <td>0.485592</td>\n",
       "      <td>0.519491</td>\n",
       "      <td>0.629122</td>\n",
       "      <td>0.529293</td>\n",
       "      <td>0.543271</td>\n",
       "      <td>0.492938</td>\n",
       "      <td>0.224427</td>\n",
       "      <td>0.608410</td>\n",
       "      <td>0.882937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>0.781996</td>\n",
       "      <td>1.040435</td>\n",
       "      <td>0.862373</td>\n",
       "      <td>1.010847</td>\n",
       "      <td>0.816637</td>\n",
       "      <td>0.841093</td>\n",
       "      <td>0.652561</td>\n",
       "      <td>0.572853</td>\n",
       "      <td>0.461742</td>\n",
       "      <td>0.648554</td>\n",
       "      <td>0.563616</td>\n",
       "      <td>0.908927</td>\n",
       "      <td>0.787799</td>\n",
       "      <td>0.647073</td>\n",
       "      <td>0.975670</td>\n",
       "      <td>0.991395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>0.695729</td>\n",
       "      <td>0.617592</td>\n",
       "      <td>0.520520</td>\n",
       "      <td>0.608107</td>\n",
       "      <td>0.232703</td>\n",
       "      <td>0.166782</td>\n",
       "      <td>0.179454</td>\n",
       "      <td>0.510091</td>\n",
       "      <td>0.147228</td>\n",
       "      <td>0.413492</td>\n",
       "      <td>0.357026</td>\n",
       "      <td>0.545893</td>\n",
       "      <td>0.495016</td>\n",
       "      <td>0.348266</td>\n",
       "      <td>1.046327</td>\n",
       "      <td>0.733302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>0.470272</td>\n",
       "      <td>0.393517</td>\n",
       "      <td>0.472918</td>\n",
       "      <td>0.488532</td>\n",
       "      <td>0.421866</td>\n",
       "      <td>0.347436</td>\n",
       "      <td>0.374574</td>\n",
       "      <td>0.505057</td>\n",
       "      <td>0.310996</td>\n",
       "      <td>0.333324</td>\n",
       "      <td>0.451271</td>\n",
       "      <td>0.388881</td>\n",
       "      <td>0.339198</td>\n",
       "      <td>0.322174</td>\n",
       "      <td>0.877251</td>\n",
       "      <td>1.278251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106</td>\n",
       "      <td>0.601170</td>\n",
       "      <td>0.641163</td>\n",
       "      <td>0.634044</td>\n",
       "      <td>0.390154</td>\n",
       "      <td>0.388621</td>\n",
       "      <td>0.386643</td>\n",
       "      <td>0.612639</td>\n",
       "      <td>0.268618</td>\n",
       "      <td>0.487770</td>\n",
       "      <td>0.417695</td>\n",
       "      <td>0.437910</td>\n",
       "      <td>0.424911</td>\n",
       "      <td>0.619142</td>\n",
       "      <td>0.244757</td>\n",
       "      <td>0.610082</td>\n",
       "      <td>0.684291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107</td>\n",
       "      <td>0.837320</td>\n",
       "      <td>0.723076</td>\n",
       "      <td>0.920463</td>\n",
       "      <td>0.804596</td>\n",
       "      <td>0.262284</td>\n",
       "      <td>0.337655</td>\n",
       "      <td>0.245266</td>\n",
       "      <td>0.110878</td>\n",
       "      <td>0.215483</td>\n",
       "      <td>-0.051656</td>\n",
       "      <td>0.319452</td>\n",
       "      <td>0.164916</td>\n",
       "      <td>0.639618</td>\n",
       "      <td>0.357379</td>\n",
       "      <td>0.752838</td>\n",
       "      <td>0.979017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>108</td>\n",
       "      <td>0.803382</td>\n",
       "      <td>0.986233</td>\n",
       "      <td>0.938801</td>\n",
       "      <td>1.088190</td>\n",
       "      <td>0.876531</td>\n",
       "      <td>1.093217</td>\n",
       "      <td>0.438439</td>\n",
       "      <td>0.905003</td>\n",
       "      <td>0.444636</td>\n",
       "      <td>0.862052</td>\n",
       "      <td>0.685624</td>\n",
       "      <td>0.996331</td>\n",
       "      <td>0.950917</td>\n",
       "      <td>0.696882</td>\n",
       "      <td>0.765659</td>\n",
       "      <td>1.389258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>109</td>\n",
       "      <td>0.658739</td>\n",
       "      <td>0.711127</td>\n",
       "      <td>0.623994</td>\n",
       "      <td>0.872866</td>\n",
       "      <td>0.323784</td>\n",
       "      <td>0.330265</td>\n",
       "      <td>0.374150</td>\n",
       "      <td>0.621026</td>\n",
       "      <td>0.313722</td>\n",
       "      <td>0.540757</td>\n",
       "      <td>0.497184</td>\n",
       "      <td>0.532202</td>\n",
       "      <td>0.450668</td>\n",
       "      <td>0.499195</td>\n",
       "      <td>0.788206</td>\n",
       "      <td>0.786762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>110</td>\n",
       "      <td>0.909104</td>\n",
       "      <td>0.886818</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>1.112190</td>\n",
       "      <td>0.558206</td>\n",
       "      <td>0.681099</td>\n",
       "      <td>0.399795</td>\n",
       "      <td>0.813282</td>\n",
       "      <td>0.383113</td>\n",
       "      <td>0.647586</td>\n",
       "      <td>0.588102</td>\n",
       "      <td>0.919163</td>\n",
       "      <td>0.660548</td>\n",
       "      <td>0.634694</td>\n",
       "      <td>0.890801</td>\n",
       "      <td>1.104343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>111</td>\n",
       "      <td>0.792521</td>\n",
       "      <td>0.947742</td>\n",
       "      <td>1.002349</td>\n",
       "      <td>1.316475</td>\n",
       "      <td>0.662288</td>\n",
       "      <td>0.665931</td>\n",
       "      <td>0.759795</td>\n",
       "      <td>0.893801</td>\n",
       "      <td>0.783995</td>\n",
       "      <td>0.714970</td>\n",
       "      <td>0.733279</td>\n",
       "      <td>0.668187</td>\n",
       "      <td>0.876355</td>\n",
       "      <td>0.651060</td>\n",
       "      <td>0.764056</td>\n",
       "      <td>1.164051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>112</td>\n",
       "      <td>0.305741</td>\n",
       "      <td>0.443099</td>\n",
       "      <td>0.355037</td>\n",
       "      <td>0.553486</td>\n",
       "      <td>0.219591</td>\n",
       "      <td>0.238168</td>\n",
       "      <td>0.351369</td>\n",
       "      <td>0.420581</td>\n",
       "      <td>0.314667</td>\n",
       "      <td>0.299010</td>\n",
       "      <td>0.384040</td>\n",
       "      <td>0.046334</td>\n",
       "      <td>0.423867</td>\n",
       "      <td>0.034001</td>\n",
       "      <td>0.785096</td>\n",
       "      <td>0.617529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>113</td>\n",
       "      <td>0.612099</td>\n",
       "      <td>0.532061</td>\n",
       "      <td>0.626859</td>\n",
       "      <td>0.426512</td>\n",
       "      <td>0.275775</td>\n",
       "      <td>0.313510</td>\n",
       "      <td>0.195125</td>\n",
       "      <td>0.141763</td>\n",
       "      <td>0.152961</td>\n",
       "      <td>0.183291</td>\n",
       "      <td>0.275102</td>\n",
       "      <td>0.290907</td>\n",
       "      <td>0.404205</td>\n",
       "      <td>0.191204</td>\n",
       "      <td>0.588611</td>\n",
       "      <td>0.585009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>114</td>\n",
       "      <td>0.575619</td>\n",
       "      <td>0.795625</td>\n",
       "      <td>0.650421</td>\n",
       "      <td>0.761265</td>\n",
       "      <td>0.436652</td>\n",
       "      <td>0.594901</td>\n",
       "      <td>0.315597</td>\n",
       "      <td>0.555625</td>\n",
       "      <td>0.319634</td>\n",
       "      <td>0.467583</td>\n",
       "      <td>0.527803</td>\n",
       "      <td>0.494577</td>\n",
       "      <td>0.857290</td>\n",
       "      <td>0.596091</td>\n",
       "      <td>0.777156</td>\n",
       "      <td>0.949461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>115</td>\n",
       "      <td>0.810008</td>\n",
       "      <td>0.671938</td>\n",
       "      <td>0.747981</td>\n",
       "      <td>0.816781</td>\n",
       "      <td>0.552512</td>\n",
       "      <td>0.532942</td>\n",
       "      <td>0.352746</td>\n",
       "      <td>0.705609</td>\n",
       "      <td>0.397548</td>\n",
       "      <td>0.629707</td>\n",
       "      <td>0.445639</td>\n",
       "      <td>0.757071</td>\n",
       "      <td>0.757171</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>1.123696</td>\n",
       "      <td>1.312572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>117</td>\n",
       "      <td>0.739961</td>\n",
       "      <td>0.999593</td>\n",
       "      <td>1.117845</td>\n",
       "      <td>1.141733</td>\n",
       "      <td>0.665900</td>\n",
       "      <td>0.560048</td>\n",
       "      <td>0.779205</td>\n",
       "      <td>0.833558</td>\n",
       "      <td>0.721869</td>\n",
       "      <td>0.851695</td>\n",
       "      <td>0.776175</td>\n",
       "      <td>0.950963</td>\n",
       "      <td>0.822763</td>\n",
       "      <td>0.705167</td>\n",
       "      <td>0.739716</td>\n",
       "      <td>1.201082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>118</td>\n",
       "      <td>0.615284</td>\n",
       "      <td>0.646775</td>\n",
       "      <td>0.579507</td>\n",
       "      <td>0.647748</td>\n",
       "      <td>0.380463</td>\n",
       "      <td>0.344093</td>\n",
       "      <td>0.348013</td>\n",
       "      <td>0.419008</td>\n",
       "      <td>0.168523</td>\n",
       "      <td>0.317253</td>\n",
       "      <td>0.109183</td>\n",
       "      <td>0.448409</td>\n",
       "      <td>0.521629</td>\n",
       "      <td>0.375348</td>\n",
       "      <td>0.498061</td>\n",
       "      <td>0.804563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>119</td>\n",
       "      <td>0.721871</td>\n",
       "      <td>1.236386</td>\n",
       "      <td>1.068366</td>\n",
       "      <td>1.440720</td>\n",
       "      <td>0.582050</td>\n",
       "      <td>0.661441</td>\n",
       "      <td>0.649517</td>\n",
       "      <td>0.929910</td>\n",
       "      <td>0.720451</td>\n",
       "      <td>1.109664</td>\n",
       "      <td>0.807548</td>\n",
       "      <td>0.797290</td>\n",
       "      <td>0.629928</td>\n",
       "      <td>1.146660</td>\n",
       "      <td>0.350061</td>\n",
       "      <td>0.536086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>120</td>\n",
       "      <td>0.716374</td>\n",
       "      <td>0.439354</td>\n",
       "      <td>0.688931</td>\n",
       "      <td>0.999021</td>\n",
       "      <td>0.273544</td>\n",
       "      <td>0.172345</td>\n",
       "      <td>0.249393</td>\n",
       "      <td>0.365369</td>\n",
       "      <td>0.359178</td>\n",
       "      <td>0.357185</td>\n",
       "      <td>0.456155</td>\n",
       "      <td>0.458505</td>\n",
       "      <td>0.539596</td>\n",
       "      <td>0.376920</td>\n",
       "      <td>0.394951</td>\n",
       "      <td>0.498328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>121</td>\n",
       "      <td>0.929147</td>\n",
       "      <td>0.996385</td>\n",
       "      <td>0.902380</td>\n",
       "      <td>1.049132</td>\n",
       "      <td>0.161368</td>\n",
       "      <td>0.287373</td>\n",
       "      <td>0.316380</td>\n",
       "      <td>0.549026</td>\n",
       "      <td>0.363180</td>\n",
       "      <td>0.516536</td>\n",
       "      <td>0.266123</td>\n",
       "      <td>0.421493</td>\n",
       "      <td>0.594942</td>\n",
       "      <td>0.495365</td>\n",
       "      <td>1.126754</td>\n",
       "      <td>0.992477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>122</td>\n",
       "      <td>0.627642</td>\n",
       "      <td>0.714657</td>\n",
       "      <td>0.569680</td>\n",
       "      <td>0.774805</td>\n",
       "      <td>0.469744</td>\n",
       "      <td>0.478004</td>\n",
       "      <td>0.306467</td>\n",
       "      <td>0.437440</td>\n",
       "      <td>0.327306</td>\n",
       "      <td>0.460400</td>\n",
       "      <td>0.255857</td>\n",
       "      <td>0.391510</td>\n",
       "      <td>0.475763</td>\n",
       "      <td>0.229644</td>\n",
       "      <td>0.601381</td>\n",
       "      <td>0.805003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>123</td>\n",
       "      <td>0.278221</td>\n",
       "      <td>0.533636</td>\n",
       "      <td>0.283654</td>\n",
       "      <td>0.577610</td>\n",
       "      <td>0.348448</td>\n",
       "      <td>0.319008</td>\n",
       "      <td>0.187486</td>\n",
       "      <td>0.472202</td>\n",
       "      <td>0.079377</td>\n",
       "      <td>0.400359</td>\n",
       "      <td>0.279597</td>\n",
       "      <td>0.653776</td>\n",
       "      <td>0.600805</td>\n",
       "      <td>0.338161</td>\n",
       "      <td>0.599866</td>\n",
       "      <td>0.658119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>124</td>\n",
       "      <td>0.642429</td>\n",
       "      <td>0.744984</td>\n",
       "      <td>0.543124</td>\n",
       "      <td>0.675073</td>\n",
       "      <td>0.362436</td>\n",
       "      <td>0.301046</td>\n",
       "      <td>0.458544</td>\n",
       "      <td>0.430995</td>\n",
       "      <td>0.267292</td>\n",
       "      <td>0.329984</td>\n",
       "      <td>0.369923</td>\n",
       "      <td>0.295787</td>\n",
       "      <td>0.468020</td>\n",
       "      <td>0.427449</td>\n",
       "      <td>0.913672</td>\n",
       "      <td>0.695924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>125</td>\n",
       "      <td>0.267304</td>\n",
       "      <td>0.287099</td>\n",
       "      <td>0.290123</td>\n",
       "      <td>0.231448</td>\n",
       "      <td>0.264239</td>\n",
       "      <td>0.227926</td>\n",
       "      <td>0.276066</td>\n",
       "      <td>0.073992</td>\n",
       "      <td>0.146889</td>\n",
       "      <td>0.189634</td>\n",
       "      <td>0.208421</td>\n",
       "      <td>0.276916</td>\n",
       "      <td>0.350466</td>\n",
       "      <td>0.057844</td>\n",
       "      <td>0.576927</td>\n",
       "      <td>0.804598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>126</td>\n",
       "      <td>0.660547</td>\n",
       "      <td>0.683667</td>\n",
       "      <td>0.762384</td>\n",
       "      <td>0.995115</td>\n",
       "      <td>0.409575</td>\n",
       "      <td>0.378991</td>\n",
       "      <td>0.429595</td>\n",
       "      <td>0.681221</td>\n",
       "      <td>0.439191</td>\n",
       "      <td>0.549049</td>\n",
       "      <td>0.380717</td>\n",
       "      <td>0.589868</td>\n",
       "      <td>0.629141</td>\n",
       "      <td>0.430036</td>\n",
       "      <td>0.655076</td>\n",
       "      <td>0.732342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>127</td>\n",
       "      <td>0.921890</td>\n",
       "      <td>0.727111</td>\n",
       "      <td>1.141526</td>\n",
       "      <td>0.795923</td>\n",
       "      <td>1.477396</td>\n",
       "      <td>1.345420</td>\n",
       "      <td>0.628509</td>\n",
       "      <td>0.369343</td>\n",
       "      <td>0.632567</td>\n",
       "      <td>0.847025</td>\n",
       "      <td>1.063276</td>\n",
       "      <td>1.230870</td>\n",
       "      <td>1.102976</td>\n",
       "      <td>0.511253</td>\n",
       "      <td>0.908903</td>\n",
       "      <td>1.588605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>128</td>\n",
       "      <td>0.936504</td>\n",
       "      <td>0.714145</td>\n",
       "      <td>0.891014</td>\n",
       "      <td>0.921110</td>\n",
       "      <td>0.826825</td>\n",
       "      <td>0.740307</td>\n",
       "      <td>0.658416</td>\n",
       "      <td>0.818738</td>\n",
       "      <td>0.548738</td>\n",
       "      <td>0.767092</td>\n",
       "      <td>0.755134</td>\n",
       "      <td>0.890100</td>\n",
       "      <td>0.600709</td>\n",
       "      <td>0.606377</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>1.137361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>129</td>\n",
       "      <td>0.309045</td>\n",
       "      <td>0.722592</td>\n",
       "      <td>0.380122</td>\n",
       "      <td>0.749821</td>\n",
       "      <td>0.373178</td>\n",
       "      <td>0.440382</td>\n",
       "      <td>0.506546</td>\n",
       "      <td>0.539108</td>\n",
       "      <td>0.511458</td>\n",
       "      <td>0.578868</td>\n",
       "      <td>0.404949</td>\n",
       "      <td>0.551737</td>\n",
       "      <td>0.414223</td>\n",
       "      <td>0.506763</td>\n",
       "      <td>0.254623</td>\n",
       "      <td>0.761811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>130</td>\n",
       "      <td>0.492184</td>\n",
       "      <td>0.628251</td>\n",
       "      <td>0.510524</td>\n",
       "      <td>0.501992</td>\n",
       "      <td>0.253151</td>\n",
       "      <td>0.265693</td>\n",
       "      <td>0.326123</td>\n",
       "      <td>0.412878</td>\n",
       "      <td>0.244848</td>\n",
       "      <td>0.287303</td>\n",
       "      <td>0.332914</td>\n",
       "      <td>0.346298</td>\n",
       "      <td>0.252086</td>\n",
       "      <td>0.279374</td>\n",
       "      <td>0.704033</td>\n",
       "      <td>0.679675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>131</td>\n",
       "      <td>0.889427</td>\n",
       "      <td>0.745073</td>\n",
       "      <td>0.829856</td>\n",
       "      <td>0.889861</td>\n",
       "      <td>0.405558</td>\n",
       "      <td>0.218246</td>\n",
       "      <td>0.541828</td>\n",
       "      <td>0.562579</td>\n",
       "      <td>0.316663</td>\n",
       "      <td>0.571211</td>\n",
       "      <td>0.606193</td>\n",
       "      <td>0.578662</td>\n",
       "      <td>0.461819</td>\n",
       "      <td>0.302637</td>\n",
       "      <td>0.595024</td>\n",
       "      <td>0.774990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>132</td>\n",
       "      <td>0.648341</td>\n",
       "      <td>0.464753</td>\n",
       "      <td>0.917221</td>\n",
       "      <td>0.988266</td>\n",
       "      <td>0.312048</td>\n",
       "      <td>0.797105</td>\n",
       "      <td>0.504496</td>\n",
       "      <td>0.788761</td>\n",
       "      <td>0.456997</td>\n",
       "      <td>0.449380</td>\n",
       "      <td>0.424488</td>\n",
       "      <td>0.567210</td>\n",
       "      <td>0.746756</td>\n",
       "      <td>0.575167</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.573384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>133</td>\n",
       "      <td>0.575631</td>\n",
       "      <td>0.652762</td>\n",
       "      <td>0.538165</td>\n",
       "      <td>0.823222</td>\n",
       "      <td>0.330125</td>\n",
       "      <td>0.482549</td>\n",
       "      <td>0.378623</td>\n",
       "      <td>0.467304</td>\n",
       "      <td>0.267816</td>\n",
       "      <td>0.378118</td>\n",
       "      <td>0.406119</td>\n",
       "      <td>0.498159</td>\n",
       "      <td>0.613259</td>\n",
       "      <td>0.515915</td>\n",
       "      <td>0.794183</td>\n",
       "      <td>0.910919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>134</td>\n",
       "      <td>0.472452</td>\n",
       "      <td>0.952143</td>\n",
       "      <td>0.409587</td>\n",
       "      <td>0.882552</td>\n",
       "      <td>0.392075</td>\n",
       "      <td>0.234638</td>\n",
       "      <td>0.251736</td>\n",
       "      <td>0.528231</td>\n",
       "      <td>0.298781</td>\n",
       "      <td>0.402649</td>\n",
       "      <td>0.488254</td>\n",
       "      <td>0.408927</td>\n",
       "      <td>0.415263</td>\n",
       "      <td>0.585643</td>\n",
       "      <td>0.697836</td>\n",
       "      <td>0.838802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>135</td>\n",
       "      <td>1.127976</td>\n",
       "      <td>0.864214</td>\n",
       "      <td>1.290920</td>\n",
       "      <td>1.101282</td>\n",
       "      <td>0.620397</td>\n",
       "      <td>0.613942</td>\n",
       "      <td>0.838888</td>\n",
       "      <td>1.206359</td>\n",
       "      <td>0.768555</td>\n",
       "      <td>0.839442</td>\n",
       "      <td>0.821672</td>\n",
       "      <td>0.547621</td>\n",
       "      <td>0.683008</td>\n",
       "      <td>0.700752</td>\n",
       "      <td>0.445883</td>\n",
       "      <td>1.308352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>136</td>\n",
       "      <td>0.618509</td>\n",
       "      <td>0.914296</td>\n",
       "      <td>0.558970</td>\n",
       "      <td>0.788879</td>\n",
       "      <td>0.537024</td>\n",
       "      <td>0.580323</td>\n",
       "      <td>0.334028</td>\n",
       "      <td>0.591324</td>\n",
       "      <td>0.265373</td>\n",
       "      <td>0.342227</td>\n",
       "      <td>0.410041</td>\n",
       "      <td>0.323915</td>\n",
       "      <td>0.552797</td>\n",
       "      <td>0.658925</td>\n",
       "      <td>0.816329</td>\n",
       "      <td>1.083254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>137</td>\n",
       "      <td>0.488290</td>\n",
       "      <td>0.252976</td>\n",
       "      <td>0.701257</td>\n",
       "      <td>0.914237</td>\n",
       "      <td>0.249533</td>\n",
       "      <td>1.280298</td>\n",
       "      <td>0.803640</td>\n",
       "      <td>1.318569</td>\n",
       "      <td>0.454473</td>\n",
       "      <td>1.188736</td>\n",
       "      <td>0.294916</td>\n",
       "      <td>1.251956</td>\n",
       "      <td>0.483691</td>\n",
       "      <td>0.312238</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>0.212153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>138</td>\n",
       "      <td>0.918936</td>\n",
       "      <td>0.898593</td>\n",
       "      <td>0.869469</td>\n",
       "      <td>0.933418</td>\n",
       "      <td>0.553218</td>\n",
       "      <td>0.588685</td>\n",
       "      <td>0.554866</td>\n",
       "      <td>0.694796</td>\n",
       "      <td>0.411844</td>\n",
       "      <td>0.579038</td>\n",
       "      <td>0.470204</td>\n",
       "      <td>0.685271</td>\n",
       "      <td>0.719116</td>\n",
       "      <td>0.547938</td>\n",
       "      <td>1.073230</td>\n",
       "      <td>0.974328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>139</td>\n",
       "      <td>0.712270</td>\n",
       "      <td>0.982904</td>\n",
       "      <td>0.565883</td>\n",
       "      <td>1.097687</td>\n",
       "      <td>0.474008</td>\n",
       "      <td>0.551877</td>\n",
       "      <td>0.225374</td>\n",
       "      <td>0.816245</td>\n",
       "      <td>0.182438</td>\n",
       "      <td>0.687714</td>\n",
       "      <td>0.230286</td>\n",
       "      <td>0.548327</td>\n",
       "      <td>0.489515</td>\n",
       "      <td>0.626777</td>\n",
       "      <td>0.543980</td>\n",
       "      <td>0.690060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>140</td>\n",
       "      <td>0.561068</td>\n",
       "      <td>0.802867</td>\n",
       "      <td>0.746936</td>\n",
       "      <td>1.063524</td>\n",
       "      <td>0.379531</td>\n",
       "      <td>0.458897</td>\n",
       "      <td>0.370253</td>\n",
       "      <td>0.706902</td>\n",
       "      <td>0.347235</td>\n",
       "      <td>0.647714</td>\n",
       "      <td>0.309695</td>\n",
       "      <td>0.564034</td>\n",
       "      <td>0.699736</td>\n",
       "      <td>0.695927</td>\n",
       "      <td>0.506089</td>\n",
       "      <td>0.804968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>141</td>\n",
       "      <td>0.867852</td>\n",
       "      <td>1.179600</td>\n",
       "      <td>1.003081</td>\n",
       "      <td>1.283506</td>\n",
       "      <td>0.846629</td>\n",
       "      <td>0.750631</td>\n",
       "      <td>0.396600</td>\n",
       "      <td>0.982078</td>\n",
       "      <td>0.243255</td>\n",
       "      <td>0.837167</td>\n",
       "      <td>0.407678</td>\n",
       "      <td>0.911400</td>\n",
       "      <td>0.908421</td>\n",
       "      <td>0.866887</td>\n",
       "      <td>1.177976</td>\n",
       "      <td>1.260962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>142</td>\n",
       "      <td>0.645498</td>\n",
       "      <td>0.808841</td>\n",
       "      <td>0.598336</td>\n",
       "      <td>0.763212</td>\n",
       "      <td>0.360415</td>\n",
       "      <td>0.442139</td>\n",
       "      <td>0.269121</td>\n",
       "      <td>0.624095</td>\n",
       "      <td>0.249603</td>\n",
       "      <td>0.734309</td>\n",
       "      <td>0.175973</td>\n",
       "      <td>0.771125</td>\n",
       "      <td>0.714260</td>\n",
       "      <td>0.523169</td>\n",
       "      <td>0.665853</td>\n",
       "      <td>0.725328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>143</td>\n",
       "      <td>1.135984</td>\n",
       "      <td>1.207807</td>\n",
       "      <td>1.167021</td>\n",
       "      <td>1.273083</td>\n",
       "      <td>0.654688</td>\n",
       "      <td>0.601680</td>\n",
       "      <td>0.737122</td>\n",
       "      <td>0.865955</td>\n",
       "      <td>0.656559</td>\n",
       "      <td>0.728651</td>\n",
       "      <td>0.630318</td>\n",
       "      <td>0.655019</td>\n",
       "      <td>0.856885</td>\n",
       "      <td>0.794079</td>\n",
       "      <td>1.152480</td>\n",
       "      <td>1.222599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>144</td>\n",
       "      <td>0.851277</td>\n",
       "      <td>1.054306</td>\n",
       "      <td>0.791919</td>\n",
       "      <td>0.931637</td>\n",
       "      <td>1.059280</td>\n",
       "      <td>0.829391</td>\n",
       "      <td>0.585723</td>\n",
       "      <td>0.542209</td>\n",
       "      <td>0.745613</td>\n",
       "      <td>0.616221</td>\n",
       "      <td>0.905706</td>\n",
       "      <td>0.679419</td>\n",
       "      <td>0.927411</td>\n",
       "      <td>0.792742</td>\n",
       "      <td>0.853267</td>\n",
       "      <td>1.033442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>145</td>\n",
       "      <td>0.804331</td>\n",
       "      <td>0.663831</td>\n",
       "      <td>1.002582</td>\n",
       "      <td>1.122815</td>\n",
       "      <td>0.159977</td>\n",
       "      <td>0.271369</td>\n",
       "      <td>0.695263</td>\n",
       "      <td>0.897741</td>\n",
       "      <td>0.313693</td>\n",
       "      <td>0.509867</td>\n",
       "      <td>0.427505</td>\n",
       "      <td>0.514560</td>\n",
       "      <td>0.555753</td>\n",
       "      <td>0.538435</td>\n",
       "      <td>0.202929</td>\n",
       "      <td>0.598062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>148</td>\n",
       "      <td>0.435295</td>\n",
       "      <td>0.319381</td>\n",
       "      <td>0.527277</td>\n",
       "      <td>0.658128</td>\n",
       "      <td>0.439829</td>\n",
       "      <td>0.344681</td>\n",
       "      <td>0.310775</td>\n",
       "      <td>0.651815</td>\n",
       "      <td>-0.071605</td>\n",
       "      <td>0.375016</td>\n",
       "      <td>0.180756</td>\n",
       "      <td>0.352957</td>\n",
       "      <td>0.679250</td>\n",
       "      <td>0.418965</td>\n",
       "      <td>0.485913</td>\n",
       "      <td>0.960619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>149</td>\n",
       "      <td>0.698778</td>\n",
       "      <td>0.655072</td>\n",
       "      <td>0.534784</td>\n",
       "      <td>0.618988</td>\n",
       "      <td>0.391013</td>\n",
       "      <td>0.456879</td>\n",
       "      <td>0.426053</td>\n",
       "      <td>0.577616</td>\n",
       "      <td>0.262277</td>\n",
       "      <td>0.524934</td>\n",
       "      <td>0.143807</td>\n",
       "      <td>0.471534</td>\n",
       "      <td>0.661517</td>\n",
       "      <td>0.156417</td>\n",
       "      <td>0.822885</td>\n",
       "      <td>0.870013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>152</td>\n",
       "      <td>0.858948</td>\n",
       "      <td>0.163705</td>\n",
       "      <td>0.755756</td>\n",
       "      <td>0.826034</td>\n",
       "      <td>0.156545</td>\n",
       "      <td>0.385049</td>\n",
       "      <td>0.372899</td>\n",
       "      <td>0.824924</td>\n",
       "      <td>0.166228</td>\n",
       "      <td>0.628600</td>\n",
       "      <td>0.045739</td>\n",
       "      <td>0.638996</td>\n",
       "      <td>0.419778</td>\n",
       "      <td>0.269830</td>\n",
       "      <td>0.097700</td>\n",
       "      <td>0.119509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>153</td>\n",
       "      <td>0.348116</td>\n",
       "      <td>0.603053</td>\n",
       "      <td>0.536340</td>\n",
       "      <td>0.709213</td>\n",
       "      <td>0.502034</td>\n",
       "      <td>0.630616</td>\n",
       "      <td>0.364912</td>\n",
       "      <td>0.620984</td>\n",
       "      <td>0.354297</td>\n",
       "      <td>0.652598</td>\n",
       "      <td>0.516437</td>\n",
       "      <td>0.745067</td>\n",
       "      <td>0.532504</td>\n",
       "      <td>0.371906</td>\n",
       "      <td>0.890614</td>\n",
       "      <td>0.866168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>154</td>\n",
       "      <td>0.653318</td>\n",
       "      <td>0.562916</td>\n",
       "      <td>0.670914</td>\n",
       "      <td>0.546208</td>\n",
       "      <td>0.523221</td>\n",
       "      <td>0.487358</td>\n",
       "      <td>0.282194</td>\n",
       "      <td>0.408201</td>\n",
       "      <td>0.245507</td>\n",
       "      <td>0.447800</td>\n",
       "      <td>0.359434</td>\n",
       "      <td>0.406881</td>\n",
       "      <td>0.327891</td>\n",
       "      <td>0.301017</td>\n",
       "      <td>0.583948</td>\n",
       "      <td>0.895666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>155</td>\n",
       "      <td>0.424070</td>\n",
       "      <td>0.512390</td>\n",
       "      <td>0.477831</td>\n",
       "      <td>0.631982</td>\n",
       "      <td>0.048606</td>\n",
       "      <td>0.348646</td>\n",
       "      <td>0.175650</td>\n",
       "      <td>0.420619</td>\n",
       "      <td>0.158237</td>\n",
       "      <td>0.359706</td>\n",
       "      <td>0.363726</td>\n",
       "      <td>0.480691</td>\n",
       "      <td>0.330469</td>\n",
       "      <td>0.170291</td>\n",
       "      <td>0.518568</td>\n",
       "      <td>0.671574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subID  L_SMA_L_post_putamen  R_SMA_R_post_putamen  \\\n",
       "0    101              0.851216              0.998780   \n",
       "1    102              0.772718              0.758162   \n",
       "2    103              0.781996              1.040435   \n",
       "3    104              0.695729              0.617592   \n",
       "4    105              0.470272              0.393517   \n",
       "5    106              0.601170              0.641163   \n",
       "6    107              0.837320              0.723076   \n",
       "7    108              0.803382              0.986233   \n",
       "8    109              0.658739              0.711127   \n",
       "9    110              0.909104              0.886818   \n",
       "10   111              0.792521              0.947742   \n",
       "11   112              0.305741              0.443099   \n",
       "12   113              0.612099              0.532061   \n",
       "13   114              0.575619              0.795625   \n",
       "14   115              0.810008              0.671938   \n",
       "15   117              0.739961              0.999593   \n",
       "16   118              0.615284              0.646775   \n",
       "17   119              0.721871              1.236386   \n",
       "18   120              0.716374              0.439354   \n",
       "19   121              0.929147              0.996385   \n",
       "20   122              0.627642              0.714657   \n",
       "21   123              0.278221              0.533636   \n",
       "22   124              0.642429              0.744984   \n",
       "23   125              0.267304              0.287099   \n",
       "24   126              0.660547              0.683667   \n",
       "25   127              0.921890              0.727111   \n",
       "26   128              0.936504              0.714145   \n",
       "27   129              0.309045              0.722592   \n",
       "28   130              0.492184              0.628251   \n",
       "29   131              0.889427              0.745073   \n",
       "30   132              0.648341              0.464753   \n",
       "31   133              0.575631              0.652762   \n",
       "32   134              0.472452              0.952143   \n",
       "33   135              1.127976              0.864214   \n",
       "34   136              0.618509              0.914296   \n",
       "35   137              0.488290              0.252976   \n",
       "36   138              0.918936              0.898593   \n",
       "37   139              0.712270              0.982904   \n",
       "38   140              0.561068              0.802867   \n",
       "39   141              0.867852              1.179600   \n",
       "40   142              0.645498              0.808841   \n",
       "41   143              1.135984              1.207807   \n",
       "42   144              0.851277              1.054306   \n",
       "43   145              0.804331              0.663831   \n",
       "44   148              0.435295              0.319381   \n",
       "45   149              0.698778              0.655072   \n",
       "46   152              0.858948              0.163705   \n",
       "47   153              0.348116              0.603053   \n",
       "48   154              0.653318              0.562916   \n",
       "49   155              0.424070              0.512390   \n",
       "\n",
       "    L_premotor_L_post_putamen  R_premotor_R_post_putamen  \\\n",
       "0                    0.758278                   1.088896   \n",
       "1                    0.784233                   0.910795   \n",
       "2                    0.862373                   1.010847   \n",
       "3                    0.520520                   0.608107   \n",
       "4                    0.472918                   0.488532   \n",
       "5                    0.634044                   0.390154   \n",
       "6                    0.920463                   0.804596   \n",
       "7                    0.938801                   1.088190   \n",
       "8                    0.623994                   0.872866   \n",
       "9                    0.843693                   1.112190   \n",
       "10                   1.002349                   1.316475   \n",
       "11                   0.355037                   0.553486   \n",
       "12                   0.626859                   0.426512   \n",
       "13                   0.650421                   0.761265   \n",
       "14                   0.747981                   0.816781   \n",
       "15                   1.117845                   1.141733   \n",
       "16                   0.579507                   0.647748   \n",
       "17                   1.068366                   1.440720   \n",
       "18                   0.688931                   0.999021   \n",
       "19                   0.902380                   1.049132   \n",
       "20                   0.569680                   0.774805   \n",
       "21                   0.283654                   0.577610   \n",
       "22                   0.543124                   0.675073   \n",
       "23                   0.290123                   0.231448   \n",
       "24                   0.762384                   0.995115   \n",
       "25                   1.141526                   0.795923   \n",
       "26                   0.891014                   0.921110   \n",
       "27                   0.380122                   0.749821   \n",
       "28                   0.510524                   0.501992   \n",
       "29                   0.829856                   0.889861   \n",
       "30                   0.917221                   0.988266   \n",
       "31                   0.538165                   0.823222   \n",
       "32                   0.409587                   0.882552   \n",
       "33                   1.290920                   1.101282   \n",
       "34                   0.558970                   0.788879   \n",
       "35                   0.701257                   0.914237   \n",
       "36                   0.869469                   0.933418   \n",
       "37                   0.565883                   1.097687   \n",
       "38                   0.746936                   1.063524   \n",
       "39                   1.003081                   1.283506   \n",
       "40                   0.598336                   0.763212   \n",
       "41                   1.167021                   1.273083   \n",
       "42                   0.791919                   0.931637   \n",
       "43                   1.002582                   1.122815   \n",
       "44                   0.527277                   0.658128   \n",
       "45                   0.534784                   0.618988   \n",
       "46                   0.755756                   0.826034   \n",
       "47                   0.536340                   0.709213   \n",
       "48                   0.670914                   0.546208   \n",
       "49                   0.477831                   0.631982   \n",
       "\n",
       "    L_anterior_caudate_vmpfc  R_anterior_caudate_vmpfc  \\\n",
       "0                   0.160140                  0.171255   \n",
       "1                   0.497427                  0.386723   \n",
       "2                   0.816637                  0.841093   \n",
       "3                   0.232703                  0.166782   \n",
       "4                   0.421866                  0.347436   \n",
       "5                   0.388621                  0.386643   \n",
       "6                   0.262284                  0.337655   \n",
       "7                   0.876531                  1.093217   \n",
       "8                   0.323784                  0.330265   \n",
       "9                   0.558206                  0.681099   \n",
       "10                  0.662288                  0.665931   \n",
       "11                  0.219591                  0.238168   \n",
       "12                  0.275775                  0.313510   \n",
       "13                  0.436652                  0.594901   \n",
       "14                  0.552512                  0.532942   \n",
       "15                  0.665900                  0.560048   \n",
       "16                  0.380463                  0.344093   \n",
       "17                  0.582050                  0.661441   \n",
       "18                  0.273544                  0.172345   \n",
       "19                  0.161368                  0.287373   \n",
       "20                  0.469744                  0.478004   \n",
       "21                  0.348448                  0.319008   \n",
       "22                  0.362436                  0.301046   \n",
       "23                  0.264239                  0.227926   \n",
       "24                  0.409575                  0.378991   \n",
       "25                  1.477396                  1.345420   \n",
       "26                  0.826825                  0.740307   \n",
       "27                  0.373178                  0.440382   \n",
       "28                  0.253151                  0.265693   \n",
       "29                  0.405558                  0.218246   \n",
       "30                  0.312048                  0.797105   \n",
       "31                  0.330125                  0.482549   \n",
       "32                  0.392075                  0.234638   \n",
       "33                  0.620397                  0.613942   \n",
       "34                  0.537024                  0.580323   \n",
       "35                  0.249533                  1.280298   \n",
       "36                  0.553218                  0.588685   \n",
       "37                  0.474008                  0.551877   \n",
       "38                  0.379531                  0.458897   \n",
       "39                  0.846629                  0.750631   \n",
       "40                  0.360415                  0.442139   \n",
       "41                  0.654688                  0.601680   \n",
       "42                  1.059280                  0.829391   \n",
       "43                  0.159977                  0.271369   \n",
       "44                  0.439829                  0.344681   \n",
       "45                  0.391013                  0.456879   \n",
       "46                  0.156545                  0.385049   \n",
       "47                  0.502034                  0.630616   \n",
       "48                  0.523221                  0.487358   \n",
       "49                  0.048606                  0.348646   \n",
       "\n",
       "    L_vlpfc_L_post_putamen  R_vlpfc_R_post_putamen  \\\n",
       "0                 0.186758                0.724928   \n",
       "1                 0.470668                0.485592   \n",
       "2                 0.652561                0.572853   \n",
       "3                 0.179454                0.510091   \n",
       "4                 0.374574                0.505057   \n",
       "5                 0.612639                0.268618   \n",
       "6                 0.245266                0.110878   \n",
       "7                 0.438439                0.905003   \n",
       "8                 0.374150                0.621026   \n",
       "9                 0.399795                0.813282   \n",
       "10                0.759795                0.893801   \n",
       "11                0.351369                0.420581   \n",
       "12                0.195125                0.141763   \n",
       "13                0.315597                0.555625   \n",
       "14                0.352746                0.705609   \n",
       "15                0.779205                0.833558   \n",
       "16                0.348013                0.419008   \n",
       "17                0.649517                0.929910   \n",
       "18                0.249393                0.365369   \n",
       "19                0.316380                0.549026   \n",
       "20                0.306467                0.437440   \n",
       "21                0.187486                0.472202   \n",
       "22                0.458544                0.430995   \n",
       "23                0.276066                0.073992   \n",
       "24                0.429595                0.681221   \n",
       "25                0.628509                0.369343   \n",
       "26                0.658416                0.818738   \n",
       "27                0.506546                0.539108   \n",
       "28                0.326123                0.412878   \n",
       "29                0.541828                0.562579   \n",
       "30                0.504496                0.788761   \n",
       "31                0.378623                0.467304   \n",
       "32                0.251736                0.528231   \n",
       "33                0.838888                1.206359   \n",
       "34                0.334028                0.591324   \n",
       "35                0.803640                1.318569   \n",
       "36                0.554866                0.694796   \n",
       "37                0.225374                0.816245   \n",
       "38                0.370253                0.706902   \n",
       "39                0.396600                0.982078   \n",
       "40                0.269121                0.624095   \n",
       "41                0.737122                0.865955   \n",
       "42                0.585723                0.542209   \n",
       "43                0.695263                0.897741   \n",
       "44                0.310775                0.651815   \n",
       "45                0.426053                0.577616   \n",
       "46                0.372899                0.824924   \n",
       "47                0.364912                0.620984   \n",
       "48                0.282194                0.408201   \n",
       "49                0.175650                0.420619   \n",
       "\n",
       "    L_vlpfc_L_anterior_putamen  R_vlpfc_R_anterior_putamen  \\\n",
       "0                     0.074329                    0.486687   \n",
       "1                     0.519491                    0.629122   \n",
       "2                     0.461742                    0.648554   \n",
       "3                     0.147228                    0.413492   \n",
       "4                     0.310996                    0.333324   \n",
       "5                     0.487770                    0.417695   \n",
       "6                     0.215483                   -0.051656   \n",
       "7                     0.444636                    0.862052   \n",
       "8                     0.313722                    0.540757   \n",
       "9                     0.383113                    0.647586   \n",
       "10                    0.783995                    0.714970   \n",
       "11                    0.314667                    0.299010   \n",
       "12                    0.152961                    0.183291   \n",
       "13                    0.319634                    0.467583   \n",
       "14                    0.397548                    0.629707   \n",
       "15                    0.721869                    0.851695   \n",
       "16                    0.168523                    0.317253   \n",
       "17                    0.720451                    1.109664   \n",
       "18                    0.359178                    0.357185   \n",
       "19                    0.363180                    0.516536   \n",
       "20                    0.327306                    0.460400   \n",
       "21                    0.079377                    0.400359   \n",
       "22                    0.267292                    0.329984   \n",
       "23                    0.146889                    0.189634   \n",
       "24                    0.439191                    0.549049   \n",
       "25                    0.632567                    0.847025   \n",
       "26                    0.548738                    0.767092   \n",
       "27                    0.511458                    0.578868   \n",
       "28                    0.244848                    0.287303   \n",
       "29                    0.316663                    0.571211   \n",
       "30                    0.456997                    0.449380   \n",
       "31                    0.267816                    0.378118   \n",
       "32                    0.298781                    0.402649   \n",
       "33                    0.768555                    0.839442   \n",
       "34                    0.265373                    0.342227   \n",
       "35                    0.454473                    1.188736   \n",
       "36                    0.411844                    0.579038   \n",
       "37                    0.182438                    0.687714   \n",
       "38                    0.347235                    0.647714   \n",
       "39                    0.243255                    0.837167   \n",
       "40                    0.249603                    0.734309   \n",
       "41                    0.656559                    0.728651   \n",
       "42                    0.745613                    0.616221   \n",
       "43                    0.313693                    0.509867   \n",
       "44                   -0.071605                    0.375016   \n",
       "45                    0.262277                    0.524934   \n",
       "46                    0.166228                    0.628600   \n",
       "47                    0.354297                    0.652598   \n",
       "48                    0.245507                    0.447800   \n",
       "49                    0.158237                    0.359706   \n",
       "\n",
       "    L_vlpfc_L_anterior_caudate  R_vlpfc_R_anterior_caudate  \\\n",
       "0                     0.268736                    0.434427   \n",
       "1                     0.529293                    0.543271   \n",
       "2                     0.563616                    0.908927   \n",
       "3                     0.357026                    0.545893   \n",
       "4                     0.451271                    0.388881   \n",
       "5                     0.437910                    0.424911   \n",
       "6                     0.319452                    0.164916   \n",
       "7                     0.685624                    0.996331   \n",
       "8                     0.497184                    0.532202   \n",
       "9                     0.588102                    0.919163   \n",
       "10                    0.733279                    0.668187   \n",
       "11                    0.384040                    0.046334   \n",
       "12                    0.275102                    0.290907   \n",
       "13                    0.527803                    0.494577   \n",
       "14                    0.445639                    0.757071   \n",
       "15                    0.776175                    0.950963   \n",
       "16                    0.109183                    0.448409   \n",
       "17                    0.807548                    0.797290   \n",
       "18                    0.456155                    0.458505   \n",
       "19                    0.266123                    0.421493   \n",
       "20                    0.255857                    0.391510   \n",
       "21                    0.279597                    0.653776   \n",
       "22                    0.369923                    0.295787   \n",
       "23                    0.208421                    0.276916   \n",
       "24                    0.380717                    0.589868   \n",
       "25                    1.063276                    1.230870   \n",
       "26                    0.755134                    0.890100   \n",
       "27                    0.404949                    0.551737   \n",
       "28                    0.332914                    0.346298   \n",
       "29                    0.606193                    0.578662   \n",
       "30                    0.424488                    0.567210   \n",
       "31                    0.406119                    0.498159   \n",
       "32                    0.488254                    0.408927   \n",
       "33                    0.821672                    0.547621   \n",
       "34                    0.410041                    0.323915   \n",
       "35                    0.294916                    1.251956   \n",
       "36                    0.470204                    0.685271   \n",
       "37                    0.230286                    0.548327   \n",
       "38                    0.309695                    0.564034   \n",
       "39                    0.407678                    0.911400   \n",
       "40                    0.175973                    0.771125   \n",
       "41                    0.630318                    0.655019   \n",
       "42                    0.905706                    0.679419   \n",
       "43                    0.427505                    0.514560   \n",
       "44                    0.180756                    0.352957   \n",
       "45                    0.143807                    0.471534   \n",
       "46                    0.045739                    0.638996   \n",
       "47                    0.516437                    0.745067   \n",
       "48                    0.359434                    0.406881   \n",
       "49                    0.363726                    0.480691   \n",
       "\n",
       "    R_frontopolar_R_anterior_caudate  R_frontopolar_R_post_putamen  \\\n",
       "0                           0.509097                      0.601175   \n",
       "1                           0.492938                      0.224427   \n",
       "2                           0.787799                      0.647073   \n",
       "3                           0.495016                      0.348266   \n",
       "4                           0.339198                      0.322174   \n",
       "5                           0.619142                      0.244757   \n",
       "6                           0.639618                      0.357379   \n",
       "7                           0.950917                      0.696882   \n",
       "8                           0.450668                      0.499195   \n",
       "9                           0.660548                      0.634694   \n",
       "10                          0.876355                      0.651060   \n",
       "11                          0.423867                      0.034001   \n",
       "12                          0.404205                      0.191204   \n",
       "13                          0.857290                      0.596091   \n",
       "14                          0.757171                      0.449000   \n",
       "15                          0.822763                      0.705167   \n",
       "16                          0.521629                      0.375348   \n",
       "17                          0.629928                      1.146660   \n",
       "18                          0.539596                      0.376920   \n",
       "19                          0.594942                      0.495365   \n",
       "20                          0.475763                      0.229644   \n",
       "21                          0.600805                      0.338161   \n",
       "22                          0.468020                      0.427449   \n",
       "23                          0.350466                      0.057844   \n",
       "24                          0.629141                      0.430036   \n",
       "25                          1.102976                      0.511253   \n",
       "26                          0.600709                      0.606377   \n",
       "27                          0.414223                      0.506763   \n",
       "28                          0.252086                      0.279374   \n",
       "29                          0.461819                      0.302637   \n",
       "30                          0.746756                      0.575167   \n",
       "31                          0.613259                      0.515915   \n",
       "32                          0.415263                      0.585643   \n",
       "33                          0.683008                      0.700752   \n",
       "34                          0.552797                      0.658925   \n",
       "35                          0.483691                      0.312238   \n",
       "36                          0.719116                      0.547938   \n",
       "37                          0.489515                      0.626777   \n",
       "38                          0.699736                      0.695927   \n",
       "39                          0.908421                      0.866887   \n",
       "40                          0.714260                      0.523169   \n",
       "41                          0.856885                      0.794079   \n",
       "42                          0.927411                      0.792742   \n",
       "43                          0.555753                      0.538435   \n",
       "44                          0.679250                      0.418965   \n",
       "45                          0.661517                      0.156417   \n",
       "46                          0.419778                      0.269830   \n",
       "47                          0.532504                      0.371906   \n",
       "48                          0.327891                      0.301017   \n",
       "49                          0.330469                      0.170291   \n",
       "\n",
       "    R_post_putamen_L_post_putamen  R_anterior_caudate_L_anterior_caudate  \n",
       "0                        0.837498                               0.867571  \n",
       "1                        0.608410                               0.882937  \n",
       "2                        0.975670                               0.991395  \n",
       "3                        1.046327                               0.733302  \n",
       "4                        0.877251                               1.278251  \n",
       "5                        0.610082                               0.684291  \n",
       "6                        0.752838                               0.979017  \n",
       "7                        0.765659                               1.389258  \n",
       "8                        0.788206                               0.786762  \n",
       "9                        0.890801                               1.104343  \n",
       "10                       0.764056                               1.164051  \n",
       "11                       0.785096                               0.617529  \n",
       "12                       0.588611                               0.585009  \n",
       "13                       0.777156                               0.949461  \n",
       "14                       1.123696                               1.312572  \n",
       "15                       0.739716                               1.201082  \n",
       "16                       0.498061                               0.804563  \n",
       "17                       0.350061                               0.536086  \n",
       "18                       0.394951                               0.498328  \n",
       "19                       1.126754                               0.992477  \n",
       "20                       0.601381                               0.805003  \n",
       "21                       0.599866                               0.658119  \n",
       "22                       0.913672                               0.695924  \n",
       "23                       0.576927                               0.804598  \n",
       "24                       0.655076                               0.732342  \n",
       "25                       0.908903                               1.588605  \n",
       "26                       0.892500                               1.137361  \n",
       "27                       0.254623                               0.761811  \n",
       "28                       0.704033                               0.679675  \n",
       "29                       0.595024                               0.774990  \n",
       "30                       0.121652                               0.573384  \n",
       "31                       0.794183                               0.910919  \n",
       "32                       0.697836                               0.838802  \n",
       "33                       0.445883                               1.308352  \n",
       "34                       0.816329                               1.083254  \n",
       "35                       0.220505                               0.212153  \n",
       "36                       1.073230                               0.974328  \n",
       "37                       0.543980                               0.690060  \n",
       "38                       0.506089                               0.804968  \n",
       "39                       1.177976                               1.260962  \n",
       "40                       0.665853                               0.725328  \n",
       "41                       1.152480                               1.222599  \n",
       "42                       0.853267                               1.033442  \n",
       "43                       0.202929                               0.598062  \n",
       "44                       0.485913                               0.960619  \n",
       "45                       0.822885                               0.870013  \n",
       "46                       0.097700                               0.119509  \n",
       "47                       0.890614                               0.866168  \n",
       "48                       0.583948                               0.895666  \n",
       "49                       0.518568                               0.671574  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get sub dirs:\n",
    "IDCH_sub_dirs = [x for x in os.listdir(time_series_dir) if 'sub-' in x]\n",
    "# sort the sub dirs:\n",
    "IDCH_sub_dirs.sort()\n",
    "\n",
    "# List to collect data for DataFrame\n",
    "per_region_data = {}\n",
    "\n",
    "# Loop over the subject directories in the root directory\n",
    "for region_pair in connectivity_regions:\n",
    "    print(f\"Analyzing connectivity between {region_pair[0]} and {region_pair[1]}\")\n",
    "    region_df = []\n",
    "    for subj in IDCH_sub_dirs:\n",
    "        subject_dir = os.path.join(time_series_dir, subj)\n",
    "        sub_ID = subj.split('-')[1]\n",
    "        print(f\"Analyzing subject {sub_ID}\")\n",
    "\n",
    "        # Get the data for both regions:\n",
    "        reg1_dir = os.path.join(subject_dir, f'sub-{sub_ID}_IDCH_{region_pair[0]}_time_series.txt')\n",
    "        reg2_dir = os.path.join(subject_dir, f'sub-{sub_ID}_IDCH_{region_pair[1]}_time_series.txt')\n",
    "\n",
    "        reg1_ts_data = np.loadtxt(reg1_dir)\n",
    "        reg2_ts_data = np.loadtxt(reg2_dir)\n",
    "\n",
    "        # Calculate the Pearson correlation between the time series\n",
    "        correlation, p_val = pearsonr(reg1_ts_data, reg2_ts_data)\n",
    "        z_score = 0.5 * np.log((1 + correlation) / (1 - correlation))\n",
    "\n",
    "        # Print correlation for the subject:\n",
    "        print(f\">> Subject {sub_ID}: correlation between {region_pair[0]} and {region_pair[1]}: r={correlation}, p={p_val}, z-score={z_score}\")\n",
    "\n",
    "        # # Scatterplot\n",
    "        # fig, axs = plt.subplots(1, 2, figsize=(12, 5), sharey=False)\n",
    "        # axs[0].scatter(reg1_ts_data, reg2_ts_data)\n",
    "        # axs[0].set_title(f'Scatterplot for Subject {sub_ID}')\n",
    "        # axs[0].set_xlabel(region_pair[0])\n",
    "        # axs[0].set_ylabel(region_pair[1])\n",
    "        # # Line Plot for the Time-Series Data\n",
    "        # axs[1].plot(reg1_ts_data, color='red', label=region_pair[0])\n",
    "        # axs[1].plot(reg2_ts_data, color='blue', label=region_pair[1])\n",
    "        # axs[1].set_title(f'Time Series for Subject {sub_ID}')\n",
    "        # axs[1].set_xlabel('Time')\n",
    "        # axs[1].set_ylabel('BOLD Signal')\n",
    "        # axs[1].legend()\n",
    "        # plt.show()\n",
    "\n",
    "        #Append the data to list (with means)\n",
    "        region_df.append({\"subID\": sub_ID, \"corr\": correlation, \"p_val\": p_val, \"z_score\": z_score})\n",
    "\n",
    "    # keep data\n",
    "    region_connectivity_df = pd.DataFrame(region_df)\n",
    "    per_region_data[region_pair[0] + \"_\" + region_pair[1]] = region_connectivity_df\n",
    "\n",
    "    # save region_connectivity_df to csv\n",
    "    region_connectivity_df.to_csv(f'{connectiviity_data_dir}/{region_pair[0]}_{region_pair[1]}_connectivity.csv', index=False)\n",
    "\n",
    "    # # Plot the histogram of the Z-scores\n",
    "    # plt.hist(region_connectivity_df.z_score, alpha=0.6, color='g')\n",
    "    # plt.title(\"Histogram of Z-scores\")\n",
    "    # plt.show()\n",
    "\n",
    "    # display(region_connectivity_df)\n",
    "\n",
    "\n",
    "# create a data frame that has only the connectivity score (z-score) for each region pair (and the subject ID):\\\n",
    "connectivity_df = pd.DataFrame(columns=['subID'])\n",
    "for key in per_region_data.keys():\n",
    "    connectivity_score = per_region_data[key][['subID', 'z_score']]\n",
    "    connectivity_score = connectivity_score.rename(columns={'z_score': key})\n",
    "    connectivity_df = pd.merge(connectivity_df, connectivity_score, on='subID', how='outer')\n",
    "# save the connectivity_df to csv\n",
    "connectivity_df.to_csv(f'{connectiviity_data_dir}/all_connectivity_scores.csv', index=False)\n",
    "display(connectivity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L_SMA_L_post_putamen</th>\n",
       "      <th>R_SMA_R_post_putamen</th>\n",
       "      <th>L_premotor_L_post_putamen</th>\n",
       "      <th>R_premotor_R_post_putamen</th>\n",
       "      <th>L_anterior_caudate_vmpfc</th>\n",
       "      <th>R_anterior_caudate_vmpfc</th>\n",
       "      <th>L_vlpfc_L_post_putamen</th>\n",
       "      <th>R_vlpfc_R_post_putamen</th>\n",
       "      <th>L_vlpfc_L_anterior_putamen</th>\n",
       "      <th>R_vlpfc_R_anterior_putamen</th>\n",
       "      <th>L_vlpfc_L_anterior_caudate</th>\n",
       "      <th>R_vlpfc_R_anterior_caudate</th>\n",
       "      <th>R_frontopolar_R_anterior_caudate</th>\n",
       "      <th>R_frontopolar_R_post_putamen</th>\n",
       "      <th>R_post_putamen_L_post_putamen</th>\n",
       "      <th>R_anterior_caudate_L_anterior_caudate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.681448</td>\n",
       "      <td>0.729670</td>\n",
       "      <td>0.719305</td>\n",
       "      <td>0.851974</td>\n",
       "      <td>0.458582</td>\n",
       "      <td>0.499294</td>\n",
       "      <td>0.428985</td>\n",
       "      <td>0.613296</td>\n",
       "      <td>0.359040</td>\n",
       "      <td>0.545706</td>\n",
       "      <td>0.442980</td>\n",
       "      <td>0.580425</td>\n",
       "      <td>0.600919</td>\n",
       "      <td>0.474188</td>\n",
       "      <td>0.693495</td>\n",
       "      <td>0.872338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204702</td>\n",
       "      <td>0.245177</td>\n",
       "      <td>0.236099</td>\n",
       "      <td>0.256044</td>\n",
       "      <td>0.254991</td>\n",
       "      <td>0.261850</td>\n",
       "      <td>0.181817</td>\n",
       "      <td>0.249858</td>\n",
       "      <td>0.192625</td>\n",
       "      <td>0.230112</td>\n",
       "      <td>0.212223</td>\n",
       "      <td>0.246104</td>\n",
       "      <td>0.186129</td>\n",
       "      <td>0.218326</td>\n",
       "      <td>0.263329</td>\n",
       "      <td>0.284147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.267304</td>\n",
       "      <td>0.163705</td>\n",
       "      <td>0.283654</td>\n",
       "      <td>0.231448</td>\n",
       "      <td>0.048606</td>\n",
       "      <td>0.166782</td>\n",
       "      <td>0.175650</td>\n",
       "      <td>0.073992</td>\n",
       "      <td>-0.071605</td>\n",
       "      <td>-0.051656</td>\n",
       "      <td>0.045739</td>\n",
       "      <td>0.046334</td>\n",
       "      <td>0.252086</td>\n",
       "      <td>0.034001</td>\n",
       "      <td>0.097700</td>\n",
       "      <td>0.119509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.575622</td>\n",
       "      <td>0.606687</td>\n",
       "      <td>0.539405</td>\n",
       "      <td>0.662364</td>\n",
       "      <td>0.284843</td>\n",
       "      <td>0.321822</td>\n",
       "      <td>0.307544</td>\n",
       "      <td>0.444906</td>\n",
       "      <td>0.245013</td>\n",
       "      <td>0.383678</td>\n",
       "      <td>0.298611</td>\n",
       "      <td>0.422347</td>\n",
       "      <td>0.469956</td>\n",
       "      <td>0.314722</td>\n",
       "      <td>0.552217</td>\n",
       "      <td>0.691526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.678138</td>\n",
       "      <td>0.718625</td>\n",
       "      <td>0.695094</td>\n",
       "      <td>0.849450</td>\n",
       "      <td>0.398816</td>\n",
       "      <td>0.449509</td>\n",
       "      <td>0.374362</td>\n",
       "      <td>0.575234</td>\n",
       "      <td>0.318149</td>\n",
       "      <td>0.532846</td>\n",
       "      <td>0.408859</td>\n",
       "      <td>0.546757</td>\n",
       "      <td>0.597825</td>\n",
       "      <td>0.497280</td>\n",
       "      <td>0.721875</td>\n",
       "      <td>0.852485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.830492</td>\n",
       "      <td>0.910371</td>\n",
       "      <td>0.885628</td>\n",
       "      <td>1.039561</td>\n",
       "      <td>0.553041</td>\n",
       "      <td>0.610876</td>\n",
       "      <td>0.551606</td>\n",
       "      <td>0.807151</td>\n",
       "      <td>0.456366</td>\n",
       "      <td>0.651587</td>\n",
       "      <td>0.528921</td>\n",
       "      <td>0.683808</td>\n",
       "      <td>0.710629</td>\n",
       "      <td>0.621677</td>\n",
       "      <td>0.871255</td>\n",
       "      <td>1.023201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.135984</td>\n",
       "      <td>1.236386</td>\n",
       "      <td>1.290920</td>\n",
       "      <td>1.440720</td>\n",
       "      <td>1.477396</td>\n",
       "      <td>1.345420</td>\n",
       "      <td>0.838888</td>\n",
       "      <td>1.318569</td>\n",
       "      <td>0.783995</td>\n",
       "      <td>1.188736</td>\n",
       "      <td>1.063276</td>\n",
       "      <td>1.251956</td>\n",
       "      <td>1.102976</td>\n",
       "      <td>1.146660</td>\n",
       "      <td>1.177976</td>\n",
       "      <td>1.588605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       L_SMA_L_post_putamen  R_SMA_R_post_putamen  L_premotor_L_post_putamen  \\\n",
       "count             50.000000             50.000000                  50.000000   \n",
       "mean               0.681448              0.729670                   0.719305   \n",
       "std                0.204702              0.245177                   0.236099   \n",
       "min                0.267304              0.163705                   0.283654   \n",
       "25%                0.575622              0.606687                   0.539405   \n",
       "50%                0.678138              0.718625                   0.695094   \n",
       "75%                0.830492              0.910371                   0.885628   \n",
       "max                1.135984              1.236386                   1.290920   \n",
       "\n",
       "       R_premotor_R_post_putamen  L_anterior_caudate_vmpfc  \\\n",
       "count                  50.000000                 50.000000   \n",
       "mean                    0.851974                  0.458582   \n",
       "std                     0.256044                  0.254991   \n",
       "min                     0.231448                  0.048606   \n",
       "25%                     0.662364                  0.284843   \n",
       "50%                     0.849450                  0.398816   \n",
       "75%                     1.039561                  0.553041   \n",
       "max                     1.440720                  1.477396   \n",
       "\n",
       "       R_anterior_caudate_vmpfc  L_vlpfc_L_post_putamen  \\\n",
       "count                 50.000000               50.000000   \n",
       "mean                   0.499294                0.428985   \n",
       "std                    0.261850                0.181817   \n",
       "min                    0.166782                0.175650   \n",
       "25%                    0.321822                0.307544   \n",
       "50%                    0.449509                0.374362   \n",
       "75%                    0.610876                0.551606   \n",
       "max                    1.345420                0.838888   \n",
       "\n",
       "       R_vlpfc_R_post_putamen  L_vlpfc_L_anterior_putamen  \\\n",
       "count               50.000000                   50.000000   \n",
       "mean                 0.613296                    0.359040   \n",
       "std                  0.249858                    0.192625   \n",
       "min                  0.073992                   -0.071605   \n",
       "25%                  0.444906                    0.245013   \n",
       "50%                  0.575234                    0.318149   \n",
       "75%                  0.807151                    0.456366   \n",
       "max                  1.318569                    0.783995   \n",
       "\n",
       "       R_vlpfc_R_anterior_putamen  L_vlpfc_L_anterior_caudate  \\\n",
       "count                   50.000000                   50.000000   \n",
       "mean                     0.545706                    0.442980   \n",
       "std                      0.230112                    0.212223   \n",
       "min                     -0.051656                    0.045739   \n",
       "25%                      0.383678                    0.298611   \n",
       "50%                      0.532846                    0.408859   \n",
       "75%                      0.651587                    0.528921   \n",
       "max                      1.188736                    1.063276   \n",
       "\n",
       "       R_vlpfc_R_anterior_caudate  R_frontopolar_R_anterior_caudate  \\\n",
       "count                   50.000000                         50.000000   \n",
       "mean                     0.580425                          0.600919   \n",
       "std                      0.246104                          0.186129   \n",
       "min                      0.046334                          0.252086   \n",
       "25%                      0.422347                          0.469956   \n",
       "50%                      0.546757                          0.597825   \n",
       "75%                      0.683808                          0.710629   \n",
       "max                      1.251956                          1.102976   \n",
       "\n",
       "       R_frontopolar_R_post_putamen  R_post_putamen_L_post_putamen  \\\n",
       "count                     50.000000                      50.000000   \n",
       "mean                       0.474188                       0.693495   \n",
       "std                        0.218326                       0.263329   \n",
       "min                        0.034001                       0.097700   \n",
       "25%                        0.314722                       0.552217   \n",
       "50%                        0.497280                       0.721875   \n",
       "75%                        0.621677                       0.871255   \n",
       "max                        1.146660                       1.177976   \n",
       "\n",
       "       R_anterior_caudate_L_anterior_caudate  \n",
       "count                              50.000000  \n",
       "mean                                0.872338  \n",
       "std                                 0.284147  \n",
       "min                                 0.119509  \n",
       "25%                                 0.691526  \n",
       "50%                                 0.852485  \n",
       "75%                                 1.023201  \n",
       "max                                 1.588605  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show summary:\n",
    "connectivity_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
