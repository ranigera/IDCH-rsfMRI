{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES:\n",
    "\n",
    "- This is like what Cadence was wroking on, but after normalization etc and without correlation to behavior (and do sub-group analysis, logistic regression). So these need to be added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dirs:\n",
    "rs_data_path_IDCH_sub_Nums_normed_concat = 'data/pre_proc_data_IDCH_subNums_normed_concat' # Here each voxel time series will be normed and concatenated\n",
    "masks_dir = 'masks'\n",
    "connectiviity_data_dir = 'data/connectivity_data'\n",
    "time_series_dir = 'data/time_series'\n",
    "\n",
    "# file_format:\n",
    "any_session_file_format = '_space-MNI152NLin6Asym_desc-smoothAROMAnonaggr_bold.nii.gz'\n",
    "\n",
    "# R01 to IDCH mapping:\n",
    "mapping_R01_to_IDCH = {'222': '101', '183': '102', '216': '103', '192': '104', '251': '105', '206': '106', '180': '107', '184': '108', '169': '109', '207': '110',\n",
    "                       '159': '111', '115': '112', '114': '113', '232': '114', '173': '115', '171': '117', '215': '118', '265': '119', '177': '120', '269': '121',\n",
    "                       '261': '122'}\n",
    "\n",
    "# masks: * mask files should end with _mask.nii.gz\n",
    "masks_to_apply = ['L_SMA_mask.nii.gz', 'R_SMA_mask.nii.gz', 'L_post_putamen_mask.nii.gz', 'R_post_putamen_mask.nii.gz', 'R_premotor_mask.nii.gz', 'L_premotor_mask.nii.gz', 'L_anterior_caudate_mask.nii.gz', 'R_anterior_caudate_mask.nii.gz', 'vmpfc_mask.nii.gz', 'L_vlpfc_mask.nii.gz', 'R_vlpfc_mask.nii.gz', 'L_anterior_putamen_mask.nii.gz', 'R_anterior_putamen_mask.nii.gz', 'R_frontopolar_mask.nii.gz']\n",
    "\n",
    "# regions to test connectivity between: * add pairs of regions to test connectivity between\n",
    "connectivity_regions = [['L_SMA', 'L_post_putamen'], ['R_SMA', 'R_post_putamen'], ['L_premotor', 'L_post_putamen'], ['R_premotor', 'R_post_putamen'], ['L_anterior_caudate', 'vmpfc'], ['R_anterior_caudate', 'vmpfc'], ['L_vlpfc', 'L_post_putamen'], ['R_vlpfc', 'R_post_putamen'], ['L_vlpfc', 'L_anterior_putamen'], ['R_vlpfc', 'R_anterior_putamen'], ['L_vlpfc', 'L_anterior_caudate'], ['R_vlpfc', 'R_anterior_caudate'], ['R_frontopolar', 'R_anterior_caudate'], ['R_frontopolar', 'R_post_putamen'], ['R_post_putamen', 'L_post_putamen'], ['R_anterior_caudate', 'L_anterior_caudate']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create IDCH sub id folders + Extract time series using masks (directly from the data) for each session separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Processing sub-101\n",
      ">> Processing sub-102\n",
      ">> Processing sub-103\n",
      ">> Processing sub-104\n",
      ">> Processing sub-105\n",
      ">> Processing sub-106\n",
      ">> Processing sub-107\n",
      ">> Processing sub-108\n",
      ">> Processing sub-109\n",
      ">> Processing sub-110\n",
      ">> Processing sub-111\n",
      ">> Processing sub-112\n",
      ">> Processing sub-113\n",
      ">> Processing sub-114\n",
      ">> Processing sub-115\n",
      ">> Processing sub-117\n",
      ">> Processing sub-118\n",
      ">> Processing sub-119\n",
      ">> Processing sub-120\n",
      ">> Processing sub-121\n",
      ">> Processing sub-122\n"
     ]
    }
   ],
   "source": [
    "# get all directories in the root directory\n",
    "subs_files = os.listdir(rs_data_path_IDCH_sub_Nums_normed_concat)\n",
    "subs_files = [f for f in subs_files if f.endswith('.nii.gz')]\n",
    "subs_files.sort()\n",
    "subs_files\n",
    "\n",
    "for sub_file in subs_files:    \n",
    "    # get sub (IDCH) id:\n",
    "    sub_id = sub_file.split('_')[0].split('-')[1]\n",
    "    print(f'>> Processing sub-{sub_id}')\n",
    "\n",
    "    # create a new foler for the sub according to sub_id:\n",
    "    sub_ts_dir = os.path.join(time_series_dir, 'sub-' + sub_id)\n",
    "    if not os.path.exists(sub_ts_dir):\n",
    "        os.makedirs(sub_ts_dir)\n",
    "\n",
    "    for mask in masks_to_apply:\n",
    "        mask_name = mask.split('_mask')[0]\n",
    "        input_file = os.path.join(rs_data_path_IDCH_sub_Nums_normed_concat, sub_file)\n",
    "        output_file = os.path.join(sub_ts_dir, f\"sub-{sub_id}_IDCH_{mask_name}_time_series.txt\")\n",
    "        if os.path.exists(output_file):\n",
    "            continue\n",
    "        print(f'>> Extracting time series for sub-{sub_id}, using {mask}:')\n",
    "        # fslmeants -i <input_file> -o <output_file> -m <mask_file>\n",
    "        os.system(f'fslmeants -i {input_file} -o {output_file} -m {os.path.join(masks_dir, mask)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate correlations (connectivity) and plot each subject's timeseries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing connectivity between L_SMA and L_post_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between L_SMA and L_post_putamen: r=0.6917043630972877, p=1.5139927139354282e-171, z-score=0.8512163079608521\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between L_SMA and L_post_putamen: r=0.6485072876694717, p=3.9040880115265387e-144, z-score=0.7727182526556606\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between L_SMA and L_post_putamen: r=0.6538507099040197, p=2.784511153356039e-147, z-score=0.7819957276054\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between L_SMA and L_post_putamen: r=0.6016496239526503, p=4.7583633557760423e-119, z-score=0.6957287161145137\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between L_SMA and L_post_putamen: r=0.4384188305117284, p=1.5511867074253952e-57, z-score=0.47027171644291077\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between L_SMA and L_post_putamen: r=0.5378816811456433, p=6.095912912642107e-91, z-score=0.6011701285310708\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between L_SMA and L_post_putamen: r=0.6843867948612963, p=1.4438058360498684e-166, z-score=0.8373197135570593\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between L_SMA and L_post_putamen: r=0.6659234611832552, p=1.241240135692048e-154, z-score=0.8033823775733857\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between L_SMA and L_post_putamen: r=0.5775233773541539, p=1.1057186757856594e-107, z-score=0.6587386496484189\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between L_SMA and L_post_putamen: r=0.7207019815478843, p=7.706648978113806e-193, z-score=0.9091041185600001\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between L_SMA and L_post_putamen: r=0.6598348867374744, p=6.978445931858144e-151, z-score=0.7925211418042778\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between L_SMA and L_post_putamen: r=0.29655781898515, p=8.689463300308102e-26, z-score=0.3057412573143871\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between L_SMA and L_post_putamen: r=0.5456027495585145, p=4.994673059709524e-94, z-score=0.6120987129958719\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between L_SMA and L_post_putamen: r=0.5194737273621897, p=6.743308424881698e-84, z-score=0.5756187086339444\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between L_SMA and L_post_putamen: r=0.6695949113917917, p=6.157589443230914e-157, z-score=0.8100084325363825\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between L_SMA and L_post_putamen: r=0.6291213635132924, p=3.1138986796429917e-133, z-score=0.7399606119795988\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between L_SMA and L_post_putamen: r=0.5478357883868261, p=6.176625398920121e-95, z-score=0.6152837773927173\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between L_SMA and L_post_putamen: r=0.618066791254943, p=2.346053533375081e-127, z-score=0.7218708148986078\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between L_SMA and L_post_putamen: r=0.6146582794452623, p=1.3660300474604906e-125, z-score=0.7163740475602365\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between L_SMA and L_post_putamen: r=0.7301960529260628, p=2.0696223911349924e-200, z-score=0.9291472165830048\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between L_SMA and L_post_putamen: r=0.5564263546960884, p=1.7135715668349117e-98, z-score=0.6276419156575443\n",
      "Analyzing connectivity between R_SMA and R_post_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_SMA and R_post_putamen: r=0.7610811323135442, p=1.882716708009886e-227, z-score=0.9987795753051586\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_SMA and R_post_putamen: r=0.6399933351631615, p=2.99465826089226e-139, z-score=0.7581624560853191\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_SMA and R_post_putamen: r=0.7780596489713812, p=3.843676661596852e-244, z-score=1.0404346535776718\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_SMA and R_post_putamen: r=0.5494492899166854, p=1.3507249746350796e-95, z-score=0.6175921076180082\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_SMA and R_post_putamen: r=0.374388041954525, p=3.172032821600829e-41, z-score=0.39351677353197473\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_SMA and R_post_putamen: r=0.5656909470851711, p=1.9042533151471714e-102, z-score=0.6411630605557247\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_SMA and R_post_putamen: r=0.6188107313890693, p=9.598192427194254e-128, z-score=0.7230755112092496\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_SMA and R_post_putamen: r=0.7557516119129487, p=1.6925640096344236e-222, z-score=0.9862333108265291\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_SMA and R_post_putamen: r=0.6113830649289507, p=6.475797803349419e-124, z-score=0.7111270100280555\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_SMA and R_post_putamen: r=0.7098185755745887, p=1.5391532723939232e-184, z-score=0.8868181094362322\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_SMA and R_post_putamen: r=0.7387590197378222, p=1.603087354800319e-207, z-score=0.9477418266687186\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_SMA and R_post_putamen: r=0.4162097031610654, p=1.7983602106033035e-51, z-score=0.4430987605766498\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_SMA and R_post_putamen: r=0.48695520807787046, p=1.8341041400682018e-72, z-score=0.5320613343086203\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_SMA and R_post_putamen: r=0.6615838747756515, p=5.964712875258451e-152, z-score=0.7956251449545709\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_SMA and R_post_putamen: r=0.5862533206001185, p=1.0989541738471904e-111, z-score=0.6719381056759449\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_SMA and R_post_putamen: r=0.7614232898431278, p=8.960023194279943e-228, z-score=0.9995932770695227\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_SMA and R_post_putamen: r=0.5694949325416918, p=4.164411653289269e-104, z-score=0.6467750263350743\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_SMA and R_post_putamen: r=0.8444217462057815, p=0.0, z-score=1.2363861228939632\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_SMA and R_post_putamen: r=0.413109213949777, p=1.1638405119511312e-50, z-score=0.4393544619295529\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_SMA and R_post_putamen: r=0.7600716618057524, p=1.6711998434379885e-226, z-score=0.9963847581204041\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_SMA and R_post_putamen: r=0.6135889833539686, p=4.839000183603855e-125, z-score=0.7146572731624768\n",
      "Analyzing connectivity between L_premotor and L_post_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between L_premotor and L_post_putamen: r=0.6400618272610794, p=2.7394782096959465e-139, z-score=0.7582784726741087\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between L_premotor and L_post_putamen: r=0.6551294619826868, p=4.810211650164944e-148, z-score=0.7842327075158929\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between L_premotor and L_post_putamen: r=0.6974780994929186, p=1.3955589083216507e-175, z-score=0.8623726422523229\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between L_premotor and L_post_putamen: r=0.4781014157786554, p=1.475056756287739e-69, z-score=0.5205202150740318\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between L_premotor and L_post_putamen: r=0.4405537309115151, p=3.83310200236708e-58, z-score=0.472917682335398\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between L_premotor and L_post_putamen: r=0.5608304639164357, p=2.3430421391821985e-100, z-score=0.6340438908790014\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between L_premotor and L_post_putamen: r=0.7261163567314034, p=4.0583855868734584e-197, z-score=0.9204629634385755\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between L_premotor and L_post_putamen: r=0.7346710562714298, p=4.307987354068428e-204, z-score=0.9388013640879695\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between L_premotor and L_post_putamen: r=0.5539029562883352, p=1.947435503135138e-97, z-score=0.6239942830689028\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between L_premotor and L_post_putamen: r=0.6877602368810389, p=7.627083385805637e-169, z-score=0.8436931305416662\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between L_premotor and L_post_putamen: r=0.7625787751610502, p=7.231935105854661e-229, z-score=1.0023486726239994\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between L_premotor and L_post_putamen: r=0.3408346695081536, p=5.043699380353784e-34, z-score=0.3550366014093385\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between L_premotor and L_post_putamen: r=0.5558859064021396, p=2.8889421376233218e-98, z-score=0.6268594400655554\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between L_premotor and L_post_putamen: r=0.5719534260281096, p=3.427743934691778e-105, z-score=0.6504211689943808\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between L_premotor and L_post_putamen: r=0.6339431130342448, p=7.154129237672455e-136, z-score=0.7479813550388236\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between L_premotor and L_post_putamen: r=0.8068178838799569, p=4.380766591053842e-276, z-score=1.1178445755000526\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between L_premotor and L_post_putamen: r=0.5223068471741249, p=5.926726184541703e-85, z-score=0.5795067696518653\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between L_premotor and L_post_putamen: r=0.7888447166325706, p=1.5595257904058847e-255, z-score=1.0683657389154542\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between L_premotor and L_post_putamen: r=0.5972950506251478, p=6.319428853096383e-117, z-score=0.6889313629723322\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between L_premotor and L_post_putamen: r=0.7174549935386261, p=2.5369599624059225e-190, z-score=0.9023804831564859\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between L_premotor and L_post_putamen: r=0.5151239426830262, p=2.697581594560376e-82, z-score=0.5696796092971285\n",
      "Analyzing connectivity between R_premotor and R_post_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_premotor and R_post_putamen: r=0.7964747529823595, p=5.270435048161046e-264, z-score=1.0888957459258315\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_premotor and R_post_putamen: r=0.7215135945601598, p=1.786500310901415e-193, z-score=0.9107949675000699\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_premotor and R_post_putamen: r=0.7661119804853787, p=3.004526502300746e-232, z-score=1.0108466682641353\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_premotor and R_post_putamen: r=0.5427929484621437, p=6.777088184423654e-93, z-score=0.608106650300139\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_premotor and R_post_putamen: r=0.4530505027495608, p=8.742148340761677e-62, z-score=0.48853197457926967\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_premotor and R_post_putamen: r=0.37149312924713607, p=1.4359333346382733e-40, z-score=0.39015417037302713\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_premotor and R_post_putamen: r=0.6665983513120847, p=4.706751737992872e-155, z-score=0.8045959986580501\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_premotor and R_post_putamen: r=0.7962165623025742, p=1.033717809813122e-263, z-score=1.0881899859424928\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_premotor and R_post_putamen: r=0.7028275649099258, p=2.0832430614287596e-179, z-score=0.8728664309793113\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_premotor and R_post_putamen: r=0.8048353234969492, p=1.0307600610818576e-273, z-score=1.1121904680096228\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_premotor and R_post_putamen: r=0.8659045925256917, p=0.0, z-score=1.3164748540069011\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_premotor and R_post_putamen: r=0.5031287027574323, p=5.378820084277629e-78, z-score=0.5534864916868101\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_premotor and R_post_putamen: r=0.402402435749123, p=6.334483532862158e-48, z-score=0.42651225626199246\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_premotor and R_post_putamen: r=0.6418213552835328, p=2.7581609110534877e-140, z-score=0.761264808770985\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_premotor and R_post_putamen: r=0.6733141905963438, p=2.6358375925975484e-159, z-score=0.8167813012873548\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_premotor and R_post_putamen: r=0.8149967715660419, p=3.616809652717926e-286, z-score=1.1417328460127256\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_premotor and R_post_putamen: r=0.5701519059773061, p=2.1410717904068923e-104, z-score=0.6477478862514564\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_premotor and R_post_putamen: r=0.8938426675847464, p=0.0, z-score=1.4407204698475777\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_premotor and R_post_putamen: r=0.7611828301479613, p=1.5100587481934302e-227, z-score=0.999021322698344\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_premotor and R_post_putamen: r=0.7814688087367185, p=1.1328721751962922e-247, z-score=1.0491323601703395\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_premotor and R_post_putamen: r=0.6497150797558938, p=7.687851890968665e-145, z-score=0.7748054959448442\n",
      "Analyzing connectivity between L_anterior_caudate and vmpfc\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between L_anterior_caudate and vmpfc: r=0.1587848364393173, p=3.2049835195165175e-08, z-score=0.16013985523262858\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between L_anterior_caudate and vmpfc: r=0.4600915342605163, p=6.635461820074931e-64, z-score=0.49742739506787315\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between L_anterior_caudate and vmpfc: r=0.6732355437923087, p=2.960476123659646e-159, z-score=0.8166374442044392\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between L_anterior_caudate and vmpfc: r=0.22859178523560464, p=1.0855635925763167e-15, z-score=0.2327031037731667\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between L_anterior_caudate and vmpfc: r=0.3985015878175411, p=5.941095407991e-47, z-score=0.42186637618256867\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between L_anterior_caudate and vmpfc: r=0.37017058715676526, p=2.847859554349868e-40, z-score=0.3886207588941623\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between L_anterior_caudate and vmpfc: r=0.25643047376516387, p=1.7956414206061846e-19, z-score=0.26228387429251077\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between L_anterior_caudate and vmpfc: r=0.7046773076469293, p=9.456382042503735e-181, z-score=0.8765312392737075\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between L_anterior_caudate and vmpfc: r=0.31292419753256456, p=1.1356615232592418e-28, z-score=0.32378375792625086\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between L_anterior_caudate and vmpfc: r=0.506645350676771, p=3.075116382262922e-79, z-score=0.5582062755164736\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between L_anterior_caudate and vmpfc: r=0.5798837947171709, p=9.4041839841427e-109, z-score=0.6622876117076449\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between L_anterior_caudate and vmpfc: r=0.21612836911093414, p=3.768850941870226e-14, z-score=0.21959117641205442\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between L_anterior_caudate and vmpfc: r=0.26898998077346614, p=2.4541135832766303e-21, z-score=0.27577470323177083\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between L_anterior_caudate and vmpfc: r=0.4108652722640035, p=4.441788020181364e-50, z-score=0.4366517830715416\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between L_anterior_caudate and vmpfc: r=0.5024004059031291, p=9.688704791332487e-78, z-score=0.5525118264604308\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between L_anterior_caudate and vmpfc: r=0.5822765178517663, p=7.574976474698001e-110, z-score=0.6659001177201075\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between L_anterior_caudate and vmpfc: r=0.3631095558248475, p=1.0445608410016404e-38, z-score=0.3804630766500066\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between L_anterior_caudate and vmpfc: r=0.5241536196466205, p=1.1995651964449928e-85, z-score=0.5820497298334557\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between L_anterior_caudate and vmpfc: r=0.26691980949391564, p=5.059525736504935e-21, z-score=0.2735443951795581\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between L_anterior_caudate and vmpfc: r=0.15998171232076422, p=2.5171724992244e-08, z-score=0.16136792804416716\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between L_anterior_caudate and vmpfc: r=0.4379922783631877, p=2.0485480186320936e-57, z-score=0.46974378959713925\n",
      "Analyzing connectivity between R_anterior_caudate and vmpfc\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_anterior_caudate and vmpfc: r=0.16959983367386186, p=3.3825500034872843e-09, z-score=0.17125461703989006\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_anterior_caudate and vmpfc: r=0.36853151906026826, p=6.624546873300908e-40, z-score=0.3867227654594642\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_anterior_caudate and vmpfc: r=0.6863874933369694, p=6.497457668014107e-168, z-score=0.8410928867538\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_anterior_caudate and vmpfc: r=0.16525274320467664, p=8.502092399480485e-09, z-score=0.16678214843381223\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_anterior_caudate and vmpfc: r=0.33409938981853615, p=1.1114055819762485e-32, z-score=0.34743565168471\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_anterior_caudate and vmpfc: r=0.3684626051506642, p=6.86317150715464e-40, z-score=0.3866430233638902\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_anterior_caudate and vmpfc: r=0.32538239053790463, p=5.434320566035732e-31, z-score=0.337655133784539\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_anterior_caudate and vmpfc: r=0.7980492348177763, p=8.483747089775193e-266, z-score=1.0932168333939747\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_anterior_caudate and vmpfc: r=0.31875877014024484, p=9.601089676057994e-30, z-score=0.33026488762567385\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_anterior_caudate and vmpfc: r=0.5922331860308548, p=1.691110377612102e-114, z-score=0.6810986763444046\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_anterior_caudate and vmpfc: r=0.5822970330763783, p=7.412462888005752e-110, z-score=0.6659311570868994\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_anterior_caudate and vmpfc: r=0.23376430982840743, p=2.338545671064932e-16, z-score=0.23816768869630536\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_anterior_caudate and vmpfc: r=0.30362675103578296, p=5.1999352604223206e-27, z-score=0.3135098369044986\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_anterior_caudate and vmpfc: r=0.5334112774705008, p=3.433957820002086e-89, z-score=0.5949009679079024\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_anterior_caudate and vmpfc: r=0.48762681218862747, p=1.0953075361206941e-72, z-score=0.532942071849885\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_anterior_caudate and vmpfc: r=0.5080127608556451, p=1.001535335513311e-79, z-score=0.5600476155902414\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_anterior_caudate and vmpfc: r=0.33112642106118384, p=4.247956055356137e-32, z-score=0.34409286191199856\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_anterior_caudate and vmpfc: r=0.5793212722834905, p=1.69507563087737e-108, z-score=0.6614405169629591\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_anterior_caudate and vmpfc: r=0.17065905018538285, p=2.6923150785204957e-09, z-score=0.17234540547549737\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_anterior_caudate and vmpfc: r=0.27971495130698143, p=5.2204757878602303e-23, z-score=0.2873728015988338\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_anterior_caudate and vmpfc: r=0.4446439658226764, p=2.5598446958161114e-59, z-score=0.4780043843298785\n",
      "Analyzing connectivity between L_vlpfc and L_post_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between L_vlpfc and L_post_putamen: r=0.18461671788131223, p=1.1627700624130406e-10, z-score=0.18675813446197434\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between L_vlpfc and L_post_putamen: r=0.43873890215892414, p=1.2586923775455902e-57, z-score=0.4706680170896512\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between L_vlpfc and L_post_putamen: r=0.5733914721976021, p=7.877029499561921e-106, z-score=0.6525609729494718\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between L_vlpfc and L_post_putamen: r=0.17755257638329172, p=5.885620883867153e-10, z-score=0.1794544589040613\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between L_vlpfc and L_post_putamen: r=0.3579859381754586, p=1.3482640911364144e-37, z-score=0.3745738733284629\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between L_vlpfc and L_post_putamen: r=0.5459823204800438, p=3.505014352237615e-94, z-score=0.6126393272358281\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between L_vlpfc and L_post_putamen: r=0.24046337780675897, p=3.0292109203286124e-17, z-score=0.24526587044036438\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between L_vlpfc and L_post_putamen: r=0.41234962074739334, p=1.833530934613576e-50, z-score=0.43843890810753583\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between L_vlpfc and L_post_putamen: r=0.3576161014266537, p=1.6187304361629344e-37, z-score=0.37414973811633256\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between L_vlpfc and L_post_putamen: r=0.37977368170097725, p=1.8341936837600907e-42, z-score=0.39979516249397445\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between L_vlpfc and L_post_putamen: r=0.640956024659598, p=8.546388175100258e-140, z-score=0.7597947089341681\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between L_vlpfc and L_post_putamen: r=0.33758919201092347, p=2.260003941218242e-33, z-score=0.3513691214079249\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between L_vlpfc and L_post_putamen: r=0.1926854233684307, p=1.6846131480256968e-11, z-score=0.19512464985154682\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between L_vlpfc and L_post_putamen: r=0.3055203817222012, p=2.4131660492308213e-27, z-score=0.3155970928909941\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between L_vlpfc and L_post_putamen: r=0.3388089541951682, p=1.2888910270851072e-33, z-score=0.35274641701211473\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between L_vlpfc and L_post_putamen: r=0.6522502208721236, p=2.4773395788845987e-146, z-score=0.7792051061865495\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between L_vlpfc and L_post_putamen: r=0.3346120037118599, p=8.806798020856118e-33, z-score=0.3480127855451309\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between L_vlpfc and L_post_putamen: r=0.5713444262348109, p=6.375559613809978e-105, z-score=0.6495165581207919\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between L_vlpfc and L_post_putamen: r=0.24434814972465915, p=8.995351241976502e-18, z-score=0.24939317133328529\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between L_vlpfc and L_post_putamen: r=0.30623014987383645, p=1.8071069689800117e-27, z-score=0.3163801209415236\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between L_vlpfc and L_post_putamen: r=0.2972195876611159, p=6.697924225716187e-26, z-score=0.3064669946193448\n",
      "Analyzing connectivity between R_vlpfc and R_post_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_vlpfc and R_post_putamen: r=0.6199528355699977, p=2.422505988512278e-128, z-score=0.7249284760086554\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_vlpfc and R_post_putamen: r=0.45071052983339854, p=4.316733463676889e-61, z-score=0.48559158267645397\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_vlpfc and R_post_putamen: r=0.5174512742630151, p=3.77283781105192e-83, z-score=0.572852755768665\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_vlpfc and R_post_putamen: r=0.47001626063037655, p=5.603593584877515e-67, z-score=0.5100912078620397\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_vlpfc and R_post_putamen: r=0.46608511370473577, p=9.50513768987376e-66, z-score=0.5050572509633223\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_vlpfc and R_post_putamen: r=0.2623388277560071, p=2.4528926677611577e-20, z-score=0.26861844442148164\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_vlpfc and R_post_putamen: r=0.1104260215821728, p=0.00012658453784290965, z-score=0.11087817585534121\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_vlpfc and R_post_putamen: r=0.7187251598017483, p=2.653233558206858e-191, z-score=0.9050029192539898\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_vlpfc and R_post_putamen: r=0.5518422905883393, p=1.3956542041385581e-96, z-score=0.621026439143567\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_vlpfc and R_post_putamen: r=0.6713965342768053, p=4.4302940962202175e-158, z-score=0.8132815257682559\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_vlpfc and R_post_putamen: r=0.713265912811091, p=3.982689172993489e-187, z-score=0.8938007288560433\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_vlpfc and R_post_putamen: r=0.3974197747011184, p=1.099454489853192e-46, z-score=0.42058099328082554\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_vlpfc and R_post_putamen: r=0.1408206784268814, p=9.705812777158708e-07, z-score=0.14176275967596738\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_vlpfc and R_post_putamen: r=0.504723930969741, p=1.4747343195547929e-78, z-score=0.5556247017345952\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_vlpfc and R_post_putamen: r=0.607916280371474, p=3.663237420461865e-122, z-score=0.7056094982347215\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_vlpfc and R_post_putamen: r=0.6823816315646817, p=3.1508400424125976e-165, z-score=0.8335575717545903\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_vlpfc and R_post_putamen: r=0.39609414367421747, p=2.3301449860341672e-46, z-score=0.4190077002172589\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_vlpfc and R_post_putamen: r=0.7305520112771742, p=1.0610997700111772e-200, z-score=0.929910169143747\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_vlpfc and R_post_putamen: r=0.3499343759953114, p=6.834756939727508e-36, z-score=0.3653689710381659\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_vlpfc and R_post_putamen: r=0.4997896641143371, p=7.895526224696011e-77, z-score=0.5490257357991389\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_vlpfc and R_post_putamen: r=0.4115198767607411, p=3.008375213077148e-50, z-score=0.4374395893857032\n",
      "Analyzing connectivity between L_vlpfc and L_anterior_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between L_vlpfc and L_anterior_putamen: r=0.07419220439179953, p=0.010141739744239202, z-score=0.07432878567603153\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between L_vlpfc and L_anterior_putamen: r=0.4773069296367597, p=2.663018185214462e-69, z-score=0.5194908194090516\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between L_vlpfc and L_anterior_putamen: r=0.4315030013886194, p=1.3421854583593077e-55, z-score=0.46174209376031344\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between L_vlpfc and L_anterior_putamen: r=0.14617355331262313, p=3.663451310909827e-07, z-score=0.14722818968663304\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between L_vlpfc and L_anterior_putamen: r=0.30134292822984193, p=1.3026944296667498e-26, z-score=0.3109960042200046\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between L_vlpfc and L_anterior_putamen: r=0.4524448968223704, p=1.3232153355894767e-61, z-score=0.48777022476182513\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between L_vlpfc and L_anterior_putamen: r=0.21220893897675028, p=1.1005879670431389e-13, z-score=0.21548331997653766\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between L_vlpfc and L_anterior_putamen: r=0.4174794642910517, p=8.32280032049086e-52, z-score=0.4446355544849719\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between L_vlpfc and L_anterior_putamen: r=0.30381911175338006, p=4.8110660022801264e-27, z-score=0.3137217457053501\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between L_vlpfc and L_anterior_putamen: r=0.3654079168567585, p=3.265939536344636e-39, z-score=0.38311304972074767\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between L_vlpfc and L_anterior_putamen: r=0.6549939061549921, p=5.796679720272604e-148, z-score=0.78399526276429\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between L_vlpfc and L_anterior_putamen: r=0.304676621662782, p=3.399786743338349e-27, z-score=0.31466672981799937\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between L_vlpfc and L_anterior_putamen: r=0.15177944801541093, p=1.2712025394175607e-07, z-score=0.152961342343996\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between L_vlpfc and L_anterior_putamen: r=0.3091762896484266, p=5.393987059471968e-28, z-score=0.3196343815905374\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between L_vlpfc and L_anterior_putamen: r=0.37784902033674295, p=5.11106519116063e-42, z-score=0.3975480426835146\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between L_vlpfc and L_anterior_putamen: r=0.6180657951525013, p=2.3488589189853643e-127, z-score=0.7218692030668593\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between L_vlpfc and L_anterior_putamen: r=0.16694580136326787, p=5.954844514325558e-09, z-score=0.16852324203149052\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between L_vlpfc and L_anterior_putamen: r=0.617188671623711, p=6.716675700940163e-127, z-score=0.7204511401047599\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between L_vlpfc and L_anterior_putamen: r=0.3444900134890908, p=9.115824521122881e-35, z-score=0.3591782549827157\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between L_vlpfc and L_anterior_putamen: r=0.34801195829805465, p=1.7160532036172848e-35, z-score=0.3631799708816876\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between L_vlpfc and L_anterior_putamen: r=0.31609842485146367, p=2.9819439275598955e-29, z-score=0.3273064443611339\n",
      "Analyzing connectivity between R_vlpfc and R_anterior_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_vlpfc and R_anterior_putamen: r=0.45158297595950336, p=2.383447142363028e-61, z-score=0.48668697858954835\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_vlpfc and R_anterior_putamen: r=0.5574472235836259, p=6.37213441034645e-99, z-score=0.6291218193371593\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_vlpfc and R_anterior_putamen: r=0.5706956277656184, p=1.2331640832083642e-104, z-score=0.6485538577392204\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_vlpfc and R_anterior_putamen: r=0.39143381705524743, p=3.180068899038833e-45, z-score=0.4134921734675637\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_vlpfc and R_anterior_putamen: r=0.3215045571627398, p=2.9450570083342092e-30, z-score=0.3333242098945489\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_vlpfc and R_anterior_putamen: r=0.3949867126660973, p=4.352687638437292e-46, z-score=0.4176948744572594\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_vlpfc and R_anterior_putamen: r=-0.05161023908007652, p=0.07391179484068801, z-score=-0.051656135752699346\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_vlpfc and R_anterior_putamen: r=0.6973132127785251, p=1.825280225561242e-175, z-score=0.8620516256979825\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_vlpfc and R_anterior_putamen: r=0.49356065151872774, p=1.095459929140072e-74, z-score=0.5407568384860011\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_vlpfc and R_anterior_putamen: r=0.5700429047078998, p=2.3911823357287752e-104, z-score=0.6475864002447165\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_vlpfc and R_anterior_putamen: r=0.6137839409153858, p=3.843824381812788e-125, z-score=0.7149700114172165\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_vlpfc and R_anterior_putamen: r=0.29040598712643295, p=9.45849135671334e-25, z-score=0.2990095864554624\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_vlpfc and R_anterior_putamen: r=0.18126567992626458, p=2.5298567517479245e-10, z-score=0.183291058510204\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_vlpfc and R_anterior_putamen: r=0.436244423033646, p=6.376310040854414e-57, z-score=0.46758308137946564\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_vlpfc and R_anterior_putamen: r=0.5578502946313276, p=4.307718624240857e-99, z-score=0.6297068044915507\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_vlpfc and R_anterior_putamen: r=0.6919540384050598, p=1.0176424866640764e-171, z-score=0.8516951889679641\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_vlpfc and R_anterior_putamen: r=0.3070206282503472, p=1.308246008879607e-27, z-score=0.3172526321239288\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_vlpfc and R_anterior_putamen: r=0.8039436019310184, p=1.1775485547386281e-272, z-score=1.1096640371282478\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_vlpfc and R_anterior_putamen: r=0.342731863430064, p=2.0815222495190165e-34, z-score=0.35718473190100936\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_vlpfc and R_anterior_putamen: r=0.47502190952288426, p=1.4438582294363983e-68, z-score=0.5165357966405806\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_vlpfc and R_anterior_putamen: r=0.43041006893993417, p=2.6906396288079225e-55, z-score=0.460399880456316\n",
      "Analyzing connectivity between L_vlpfc and L_anterior_caudate\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between L_vlpfc and L_anterior_caudate: r=0.2624480689803992, p=2.363119171626267e-20, z-score=0.2687357630729237\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between L_vlpfc and L_anterior_caudate: r=0.48484081707166515, p=9.226491488855262e-72, z-score=0.5292934528154729\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between L_vlpfc and L_anterior_caudate: r=0.5106551690603532, p=1.1295375816527045e-80, z-score=0.563615652900634\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between L_vlpfc and L_anterior_caudate: r=0.34259195147549354, p=2.2223792057692907e-34, z-score=0.35702620631877163\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between L_vlpfc and L_anterior_caudate: r=0.4229431751696851, p=2.9105188000603913e-53, z-score=0.4512709596358618\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between L_vlpfc and L_anterior_caudate: r=0.4119104373300318, p=2.3833420561530044e-50, z-score=0.4379098663115289\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between L_vlpfc and L_anterior_caudate: r=0.30901174343450266, p=5.772902420866408e-28, z-score=0.31945245419431695\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between L_vlpfc and L_anterior_caudate: r=0.5951635897640473, p=6.731604218732528e-116, z-score=0.6856242569557994\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between L_vlpfc and L_anterior_caudate: r=0.4598997146148247, p=7.590664899105588e-64, z-score=0.4971840938656536\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between L_vlpfc and L_anterior_caudate: r=0.5285294686018265, p=2.6176770542300775e-87, z-score=0.5881024100679627\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between L_vlpfc and L_anterior_caudate: r=0.6250671291440473, p=4.744612851809571e-131, z-score=0.7332787026289282\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between L_vlpfc and L_anterior_caudate: r=0.36621073206364396, p=2.1710275613038596e-39, z-score=0.3840398917260269\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between L_vlpfc and L_anterior_caudate: r=0.26836561676814097, p=3.0545810525313288e-21, z-score=0.27510176100620953\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between L_vlpfc and L_anterior_caudate: r=0.4837002180368087, p=2.195234618031789e-71, z-score=0.5278034121662158\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between L_vlpfc and L_anterior_caudate: r=0.4183080490933787, p=5.025096130018069e-52, z-score=0.4456394559116187\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between L_vlpfc and L_anterior_caudate: r=0.6505058671854913, p=2.6423965330003577e-145, z-score=0.7761751659579162\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between L_vlpfc and L_anterior_caudate: r=0.10875152748169367, p=0.00016030505707160674, z-score=0.1091833267106551\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between L_vlpfc and L_anterior_caudate: r=0.6682351473503323, p=4.43344819449804e-156, z-score=0.8075475528963583\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between L_vlpfc and L_anterior_caudate: r=0.42694521397736007, p=2.3994000906025814e-54, z-score=0.4561549497715927\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between L_vlpfc and L_anterior_caudate: r=0.26001379415054054, p=5.401623736433871e-20, z-score=0.26612320117181043\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between L_vlpfc and L_anterior_caudate: r=0.2504165050493987, p=1.293183858010491e-18, z-score=0.25585713331482224\n",
      "Analyzing connectivity between R_vlpfc and R_anterior_caudate\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_vlpfc and R_anterior_caudate: r=0.40901468497109994, p=1.3302465262255136e-49, z-score=0.43442738233930617\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_vlpfc and R_anterior_caudate: r=0.4954597520479333, p=2.4612969135950775e-75, z-score=0.5432706752435521\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_vlpfc and R_anterior_caudate: r=0.7206170804955201, p=8.977319844969109e-193, z-score=0.9089274805050128\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_vlpfc and R_anterior_caudate: r=0.4974360279400459, p=5.152618963878842e-76, z-score=0.5458933352130522\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_vlpfc and R_anterior_caudate: r=0.37039477990923897, p=2.5363229969030387e-40, z-score=0.3888805748191088\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_vlpfc and R_anterior_caudate: r=0.401059850414507, p=1.3733221521268007e-47, z-score=0.4249112946513211\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_vlpfc and R_anterior_caudate: r=0.16343744325987983, p=1.2404861632720576e-08, z-score=0.1649164568788345\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_vlpfc and R_anterior_caudate: r=0.7600490312263493, p=1.7548195636400427e-226, z-score=0.9963311703006902\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_vlpfc and R_anterior_caudate: r=0.4870627513561684, p=1.6889102382310245e-72, z-score=0.532202315091607\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_vlpfc and R_anterior_caudate: r=0.72550108936665, p=1.2581136387868394e-196, z-score=0.9191627407394338\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_vlpfc and R_anterior_caudate: r=0.5837863244899868, p=1.5290354562484995e-110, z-score=0.6681874478375072\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_vlpfc and R_anterior_caudate: r=0.046301129993449625, p=0.10891116020781201, z-score=0.04633425932213603\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_vlpfc and R_anterior_caudate: r=0.2829693858521005, p=1.568410581477218e-23, z-score=0.29090698285427824\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_vlpfc and R_anterior_caudate: r=0.4578417128390398, p=3.195942180892296e-63, z-score=0.49457717027844905\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_vlpfc and R_anterior_caudate: r=0.6393484884556678, p=6.918743376654822e-139, z-score=0.7570710143218908\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_vlpfc and R_anterior_caudate: r=0.7402186442513732, p=9.22207933734641e-209, z-score=0.950962852065399\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_vlpfc and R_anterior_caudate: r=0.4205899125937114, p=1.243101025833626e-52, z-score=0.4484085002288259\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_vlpfc and R_anterior_caudate: r=0.6625188879961205, p=1.590673340944619e-152, z-score=0.7972897946762888\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_vlpfc and R_anterior_caudate: r=0.42886531291960744, p=7.159413338947914e-55, z-score=0.45850542983315473\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_vlpfc and R_anterior_caudate: r=0.3981871414196806, p=7.106684667338158e-47, z-score=0.4214926233384949\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_vlpfc and R_anterior_caudate: r=0.3726613284774266, p=7.821688083698162e-41, z-score=0.3915100846088129\n",
      "Analyzing connectivity between R_frontopolar and R_anterior_caudate\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_frontopolar and R_anterior_caudate: r=0.46924161751876825, p=9.817752357847673e-67, z-score=0.5090973730429904\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_frontopolar and R_anterior_caudate: r=0.45654506217786217, p=7.866196217313831e-63, z-score=0.4929378612806047\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_frontopolar and R_anterior_caudate: r=0.6571606266728294, p=2.9053509059582198e-149, z-score=0.7877994564160059\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_frontopolar and R_anterior_caudate: r=0.4581886692120144, p=2.5098327681039336e-63, z-score=0.49501623214312523\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_frontopolar and R_anterior_caudate: r=0.3267607717042098, p=2.9626055534301763e-31, z-score=0.3391975042685197\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_frontopolar and R_anterior_caudate: r=0.5505301439787442, p=4.856256994114029e-96, z-score=0.6191416946385645\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_frontopolar and R_anterior_caudate: r=0.5646395346051183, p=5.429871833239831e-102, z-score=0.6396182015478009\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_frontopolar and R_anterior_caudate: r=0.7401980638741139, p=9.602238991268736e-209, z-score=0.9509173294819079\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_frontopolar and R_anterior_caudate: r=0.42244761067112935, p=3.9552059809282338e-53, z-score=0.4506675902673164\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_frontopolar and R_anterior_caudate: r=0.5787277208842672, p=3.152326270425602e-108, z-score=0.6605475966589518\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_frontopolar and R_anterior_caudate: r=0.7045887390220102, p=1.0971581659407694e-180, z-score=0.876355330674786\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_frontopolar and R_anterior_caudate: r=0.40018283538751265, p=2.2722943625830873e-47, z-score=0.4238666103248553\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_frontopolar and R_anterior_caudate: r=0.3835409326662734, p=2.4187658531655776e-43, z-score=0.40420472997255696\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_frontopolar and R_anterior_caudate: r=0.6948587621618301, p=9.712996561839911e-174, z-score=0.8572899729419734\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_frontopolar and R_anterior_caudate: r=0.6394073442262753, p=6.4101765815177144e-139, z-score=0.7571705680784327\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_frontopolar and R_anterior_caudate: r=0.6765708909118956, p=2.081108012100046e-161, z-score=0.8227629487181439\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_frontopolar and R_anterior_caudate: r=0.4789563889179911, p=7.797474581028359e-70, z-score=0.5216291153318173\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_frontopolar and R_anterior_caudate: r=0.5580025294656158, p=3.71505784558609e-99, z-score=0.6299278453373552\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_frontopolar and R_anterior_caudate: r=0.49268234415457307, p=2.1782543581015075e-74, z-score=0.5395963319580813\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_frontopolar and R_anterior_caudate: r=0.5334402898874391, p=3.34593306490449e-89, z-score=0.5949415188000596\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_frontopolar and R_anterior_caudate: r=0.4428441541381137, p=8.46003959154613e-59, z-score=0.4757632778874536\n",
      "Analyzing connectivity between R_frontopolar and R_post_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_frontopolar and R_post_putamen: r=0.5378852410015651, p=6.076228447945276e-91, z-score=0.6011751376054751\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_frontopolar and R_post_putamen: r=0.22073320335207133, p=1.0418477075108778e-14, z-score=0.22442673512823663\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_frontopolar and R_post_putamen: r=0.5696964184758797, p=3.396361135163351e-104, z-score=0.6470732762441039\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_frontopolar and R_post_putamen: r=0.33483652650343143, p=7.952362572415301e-33, z-score=0.3482656380131864\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_frontopolar and R_post_putamen: r=0.3114715659049987, p=2.082914950766065e-28, z-score=0.32217425127604987\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_frontopolar and R_post_putamen: r=0.23998384030653092, p=3.51381033855893e-17, z-score=0.2447569653472053\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_frontopolar and R_post_putamen: r=0.34290357087736273, p=1.9207093001422512e-34, z-score=0.3573793065359454\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_frontopolar and R_post_putamen: r=0.602385161938281, p=2.0681531175031413e-119, z-score=0.6968823656276096\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_frontopolar and R_post_putamen: r=0.4614838486649922, p=2.4934262463024632e-64, z-score=0.49919502197262977\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_frontopolar and R_post_putamen: r=0.5612762147884474, p=1.5119738065434986e-100, z-score=0.6346944140033398\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_frontopolar and R_post_putamen: r=0.5723831222137941, p=2.210591121455841e-105, z-score=0.651060005187755\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_frontopolar and R_post_putamen: r=0.033987642901108936, p=0.23940337203144962, z-score=0.034000739032901614\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_frontopolar and R_post_putamen: r=0.18890732943146107, p=4.206875346222084e-11, z-score=0.19120381955195492\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_frontopolar and R_post_putamen: r=0.534261978057845, p=1.601969736759915e-89, z-score=0.5960907284905945\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_frontopolar and R_post_putamen: r=0.4210764517701552, p=9.216222576813352e-53, z-score=0.4489997501176578\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_frontopolar and R_post_putamen: r=0.6076372699167916, p=5.057930681036216e-122, z-score=0.7051670510512654\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_frontopolar and R_post_putamen: r=0.3586609608006946, p=9.65126817531437e-38, z-score=0.3753483333301806\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_frontopolar and R_post_putamen: r=0.8166446465675101, p=2.924088643617557e-288, z-score=1.146660192891317\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_frontopolar and R_post_putamen: r=0.3600297591430125, p=4.887556301406987e-38, z-score=0.37692009180091757\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_frontopolar and R_post_putamen: r=0.45846394527447665, p=2.0715132817829804e-63, z-score=0.4953647106526347\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_frontopolar and R_post_putamen: r=0.2256905508619572, p=2.5266814308662505e-15, z-score=0.2296440401818462\n",
      "Analyzing connectivity between R_post_putamen and L_post_putamen\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_post_putamen and L_post_putamen: r=0.6844817584504432, p=1.246894920318081e-166, z-score=0.8374983677563067\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_post_putamen and L_post_putamen: r=0.543006630281459, p=5.562778741935148e-93, z-score=0.6084096334231379\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_post_putamen and L_post_putamen: r=0.7511854263509411, p=2.3558961123517443e-218, z-score=0.9756701445858628\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_post_putamen and L_post_putamen: r=0.780374398877201, p=1.564854442096964e-246, z-score=1.0463273370355501\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_post_putamen and L_post_putamen: r=0.7050396252568051, p=5.14559567083846e-181, z-score=0.8772513028270593\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_post_putamen and L_post_putamen: r=0.5441845962341815, p=1.8683518643835353e-93, z-score=0.6100816846668545\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_post_putamen and L_post_putamen: r=0.6368388079402734, p=1.7667090054299874e-137, z-score=0.7528376567973883\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_post_putamen and L_post_putamen: r=0.6443979732931618, p=9.30430096954665e-142, z-score=0.7656587097543635\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_post_putamen and L_post_putamen: r=0.6573917925893351, p=2.107984609397276e-149, z-score=0.7882064472859557\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_post_putamen and L_post_putamen: r=0.7117889581580558, p=5.167242230876438e-186, z-score=0.8908006405224936\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_post_putamen and L_post_putamen: r=0.6434595724690257, p=3.209260747111955e-141, z-score=0.7640555798655235\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_post_putamen and L_post_putamen: r=0.6556222124323066, p=2.4395957437558055e-148, z-score=0.785096450942484\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_post_putamen and L_post_putamen: r=0.5288962217406854, p=1.8948980922091209e-87, z-score=0.5886114622916203\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_post_putamen and L_post_putamen: r=0.6510712055381769, p=1.2290441342107707e-145, z-score=0.7771558488335535\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_post_putamen and L_post_putamen: r=0.8088507506717011, p=1.516997975563446e-278, z-score=1.123696222608264\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_post_putamen and L_post_putamen: r=0.6289734336422022, p=3.7456210625732e-133, z-score=0.7397158163038693\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_post_putamen and L_post_putamen: r=0.4605908494934806, p=4.673648029782629e-64, z-score=0.4980609747387263\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_post_putamen and L_post_putamen: r=0.3364297312395673, p=3.845311659491739e-33, z-score=0.35006110156821874\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_post_putamen and L_post_putamen: r=0.3756201646413245, p=1.66031338754453e-41, z-score=0.39495052177838336\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_post_putamen and L_post_putamen: r=0.8099055409310296, p=7.808943679376098e-280, z-score=1.1267544169758408\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_post_putamen and L_post_putamen: r=0.538031431035807, p=5.320291134857053e-91, z-score=0.6013808649692766\n",
      "Analyzing connectivity between R_anterior_caudate and L_anterior_caudate\n",
      "Analyzing subject 101\n",
      ">> Subject 101: correlation between R_anterior_caudate and L_anterior_caudate: r=0.7001379382006718, p=1.7908739567098663e-177, z-score=0.8675710459771909\n",
      "Analyzing subject 102\n",
      ">> Subject 102: correlation between R_anterior_caudate and L_anterior_caudate: r=0.7078877561306403, p=4.166193940220611e-183, z-score=0.8829372652091552\n",
      "Analyzing subject 103\n",
      ">> Subject 103: correlation between R_anterior_caudate and L_anterior_caudate: r=0.7579565527176042, p=1.5656255110426546e-224, z-score=0.9913950598162801\n",
      "Analyzing subject 104\n",
      ">> Subject 104: correlation between R_anterior_caudate and L_anterior_caudate: r=0.625081342013898, p=4.66234646036591e-131, z-score=0.7333020298652264\n",
      "Analyzing subject 105\n",
      ">> Subject 105: correlation between R_anterior_caudate and L_anterior_caudate: r=0.8560181320929091, p=0.0, z-score=1.278250654204577\n",
      "Analyzing subject 106\n",
      ">> Subject 106: correlation between R_anterior_caudate and L_anterior_caudate: r=0.5943021219364123, p=1.7425944004238943e-115, z-score=0.6842913192373048\n",
      "Analyzing subject 107\n",
      ">> Subject 107: correlation between R_anterior_caudate and L_anterior_caudate: r=0.7526401122861066, p=1.1533162192850243e-219, z-score=0.9790171271006262\n",
      "Analyzing subject 108\n",
      ">> Subject 108: correlation between R_anterior_caudate and L_anterior_caudate: r=0.8830074872824987, p=0.0, z-score=1.3892577830093433\n",
      "Analyzing subject 109\n",
      ">> Subject 109: correlation between R_anterior_caudate and L_anterior_caudate: r=0.656570539756578, p=6.581189524440751e-149, z-score=0.7867615348938208\n",
      "Analyzing subject 110\n",
      ">> Subject 110: correlation between R_anterior_caudate and L_anterior_caudate: r=0.8020535298463172, p=1.9732007940962577e-270, z-score=1.1043427510703405\n",
      "Analyzing subject 111\n",
      ">> Subject 111: correlation between R_anterior_caudate and L_anterior_caudate: r=0.8223555791479813, p=1.116913452708462e-295, z-score=1.1640506503915529\n",
      "Analyzing subject 112\n",
      ">> Subject 112: correlation between R_anterior_caudate and L_anterior_caudate: r=0.5494054455330031, p=1.4078425271036269e-95, z-score=0.6175293049725611\n",
      "Analyzing subject 113\n",
      ">> Subject 113: correlation between R_anterior_caudate and L_anterior_caudate: r=0.5262962043200421, p=1.8566018768350618e-86, z-score=0.5850085376674079\n",
      "Analyzing subject 114\n",
      ">> Subject 114: correlation between R_anterior_caudate and L_anterior_caudate: r=0.7395391524444517, p=3.492837410821656e-208, z-score=0.9494614748026222\n",
      "Analyzing subject 115\n",
      ">> Subject 115: correlation between R_anterior_caudate and L_anterior_caudate: r=0.8649247881770475, p=0.0, z-score=1.312572127646462\n",
      "Analyzing subject 117\n",
      ">> Subject 117: correlation between R_anterior_caudate and L_anterior_caudate: r=0.8339843502645219, p=1.214935188024e-311, z-score=1.201082030117894\n",
      "Analyzing subject 118\n",
      ">> Subject 118: correlation between R_anterior_caudate and L_anterior_caudate: r=0.6665800986204076, p=4.8319854243466004e-155, z-score=0.8045631499179392\n",
      "Analyzing subject 119\n",
      ">> Subject 119: correlation between R_anterior_caudate and L_anterior_caudate: r=0.4900192268946421, p=1.7295361371211294e-73, z-score=0.5360856387990424\n",
      "Analyzing subject 120\n",
      ">> Subject 120: correlation between R_anterior_caudate and L_anterior_caudate: r=0.46080142422356174, p=4.0307604761287986e-64, z-score=0.4983282832855785\n",
      "Analyzing subject 121\n",
      ">> Subject 121: correlation between R_anterior_caudate and L_anterior_caudate: r=0.7584167226209597, p=5.854124558504534e-225, z-score=0.9924774231100696\n",
      "Analyzing subject 122\n",
      ">> Subject 122: correlation between R_anterior_caudate and L_anterior_caudate: r=0.6668241803372341, p=3.400601277958928e-155, z-score=0.8050025344326064\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subID</th>\n",
       "      <th>L_SMA_L_post_putamen</th>\n",
       "      <th>R_SMA_R_post_putamen</th>\n",
       "      <th>L_premotor_L_post_putamen</th>\n",
       "      <th>R_premotor_R_post_putamen</th>\n",
       "      <th>L_anterior_caudate_vmpfc</th>\n",
       "      <th>R_anterior_caudate_vmpfc</th>\n",
       "      <th>L_vlpfc_L_post_putamen</th>\n",
       "      <th>R_vlpfc_R_post_putamen</th>\n",
       "      <th>L_vlpfc_L_anterior_putamen</th>\n",
       "      <th>R_vlpfc_R_anterior_putamen</th>\n",
       "      <th>L_vlpfc_L_anterior_caudate</th>\n",
       "      <th>R_vlpfc_R_anterior_caudate</th>\n",
       "      <th>R_frontopolar_R_anterior_caudate</th>\n",
       "      <th>R_frontopolar_R_post_putamen</th>\n",
       "      <th>R_post_putamen_L_post_putamen</th>\n",
       "      <th>R_anterior_caudate_L_anterior_caudate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>0.851216</td>\n",
       "      <td>0.998780</td>\n",
       "      <td>0.758278</td>\n",
       "      <td>1.088896</td>\n",
       "      <td>0.160140</td>\n",
       "      <td>0.171255</td>\n",
       "      <td>0.186758</td>\n",
       "      <td>0.724928</td>\n",
       "      <td>0.074329</td>\n",
       "      <td>0.486687</td>\n",
       "      <td>0.268736</td>\n",
       "      <td>0.434427</td>\n",
       "      <td>0.509097</td>\n",
       "      <td>0.601175</td>\n",
       "      <td>0.837498</td>\n",
       "      <td>0.867571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>0.772718</td>\n",
       "      <td>0.758162</td>\n",
       "      <td>0.784233</td>\n",
       "      <td>0.910795</td>\n",
       "      <td>0.497427</td>\n",
       "      <td>0.386723</td>\n",
       "      <td>0.470668</td>\n",
       "      <td>0.485592</td>\n",
       "      <td>0.519491</td>\n",
       "      <td>0.629122</td>\n",
       "      <td>0.529293</td>\n",
       "      <td>0.543271</td>\n",
       "      <td>0.492938</td>\n",
       "      <td>0.224427</td>\n",
       "      <td>0.608410</td>\n",
       "      <td>0.882937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>0.781996</td>\n",
       "      <td>1.040435</td>\n",
       "      <td>0.862373</td>\n",
       "      <td>1.010847</td>\n",
       "      <td>0.816637</td>\n",
       "      <td>0.841093</td>\n",
       "      <td>0.652561</td>\n",
       "      <td>0.572853</td>\n",
       "      <td>0.461742</td>\n",
       "      <td>0.648554</td>\n",
       "      <td>0.563616</td>\n",
       "      <td>0.908927</td>\n",
       "      <td>0.787799</td>\n",
       "      <td>0.647073</td>\n",
       "      <td>0.975670</td>\n",
       "      <td>0.991395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>0.695729</td>\n",
       "      <td>0.617592</td>\n",
       "      <td>0.520520</td>\n",
       "      <td>0.608107</td>\n",
       "      <td>0.232703</td>\n",
       "      <td>0.166782</td>\n",
       "      <td>0.179454</td>\n",
       "      <td>0.510091</td>\n",
       "      <td>0.147228</td>\n",
       "      <td>0.413492</td>\n",
       "      <td>0.357026</td>\n",
       "      <td>0.545893</td>\n",
       "      <td>0.495016</td>\n",
       "      <td>0.348266</td>\n",
       "      <td>1.046327</td>\n",
       "      <td>0.733302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>0.470272</td>\n",
       "      <td>0.393517</td>\n",
       "      <td>0.472918</td>\n",
       "      <td>0.488532</td>\n",
       "      <td>0.421866</td>\n",
       "      <td>0.347436</td>\n",
       "      <td>0.374574</td>\n",
       "      <td>0.505057</td>\n",
       "      <td>0.310996</td>\n",
       "      <td>0.333324</td>\n",
       "      <td>0.451271</td>\n",
       "      <td>0.388881</td>\n",
       "      <td>0.339198</td>\n",
       "      <td>0.322174</td>\n",
       "      <td>0.877251</td>\n",
       "      <td>1.278251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106</td>\n",
       "      <td>0.601170</td>\n",
       "      <td>0.641163</td>\n",
       "      <td>0.634044</td>\n",
       "      <td>0.390154</td>\n",
       "      <td>0.388621</td>\n",
       "      <td>0.386643</td>\n",
       "      <td>0.612639</td>\n",
       "      <td>0.268618</td>\n",
       "      <td>0.487770</td>\n",
       "      <td>0.417695</td>\n",
       "      <td>0.437910</td>\n",
       "      <td>0.424911</td>\n",
       "      <td>0.619142</td>\n",
       "      <td>0.244757</td>\n",
       "      <td>0.610082</td>\n",
       "      <td>0.684291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107</td>\n",
       "      <td>0.837320</td>\n",
       "      <td>0.723076</td>\n",
       "      <td>0.920463</td>\n",
       "      <td>0.804596</td>\n",
       "      <td>0.262284</td>\n",
       "      <td>0.337655</td>\n",
       "      <td>0.245266</td>\n",
       "      <td>0.110878</td>\n",
       "      <td>0.215483</td>\n",
       "      <td>-0.051656</td>\n",
       "      <td>0.319452</td>\n",
       "      <td>0.164916</td>\n",
       "      <td>0.639618</td>\n",
       "      <td>0.357379</td>\n",
       "      <td>0.752838</td>\n",
       "      <td>0.979017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>108</td>\n",
       "      <td>0.803382</td>\n",
       "      <td>0.986233</td>\n",
       "      <td>0.938801</td>\n",
       "      <td>1.088190</td>\n",
       "      <td>0.876531</td>\n",
       "      <td>1.093217</td>\n",
       "      <td>0.438439</td>\n",
       "      <td>0.905003</td>\n",
       "      <td>0.444636</td>\n",
       "      <td>0.862052</td>\n",
       "      <td>0.685624</td>\n",
       "      <td>0.996331</td>\n",
       "      <td>0.950917</td>\n",
       "      <td>0.696882</td>\n",
       "      <td>0.765659</td>\n",
       "      <td>1.389258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>109</td>\n",
       "      <td>0.658739</td>\n",
       "      <td>0.711127</td>\n",
       "      <td>0.623994</td>\n",
       "      <td>0.872866</td>\n",
       "      <td>0.323784</td>\n",
       "      <td>0.330265</td>\n",
       "      <td>0.374150</td>\n",
       "      <td>0.621026</td>\n",
       "      <td>0.313722</td>\n",
       "      <td>0.540757</td>\n",
       "      <td>0.497184</td>\n",
       "      <td>0.532202</td>\n",
       "      <td>0.450668</td>\n",
       "      <td>0.499195</td>\n",
       "      <td>0.788206</td>\n",
       "      <td>0.786762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>110</td>\n",
       "      <td>0.909104</td>\n",
       "      <td>0.886818</td>\n",
       "      <td>0.843693</td>\n",
       "      <td>1.112190</td>\n",
       "      <td>0.558206</td>\n",
       "      <td>0.681099</td>\n",
       "      <td>0.399795</td>\n",
       "      <td>0.813282</td>\n",
       "      <td>0.383113</td>\n",
       "      <td>0.647586</td>\n",
       "      <td>0.588102</td>\n",
       "      <td>0.919163</td>\n",
       "      <td>0.660548</td>\n",
       "      <td>0.634694</td>\n",
       "      <td>0.890801</td>\n",
       "      <td>1.104343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>111</td>\n",
       "      <td>0.792521</td>\n",
       "      <td>0.947742</td>\n",
       "      <td>1.002349</td>\n",
       "      <td>1.316475</td>\n",
       "      <td>0.662288</td>\n",
       "      <td>0.665931</td>\n",
       "      <td>0.759795</td>\n",
       "      <td>0.893801</td>\n",
       "      <td>0.783995</td>\n",
       "      <td>0.714970</td>\n",
       "      <td>0.733279</td>\n",
       "      <td>0.668187</td>\n",
       "      <td>0.876355</td>\n",
       "      <td>0.651060</td>\n",
       "      <td>0.764056</td>\n",
       "      <td>1.164051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>112</td>\n",
       "      <td>0.305741</td>\n",
       "      <td>0.443099</td>\n",
       "      <td>0.355037</td>\n",
       "      <td>0.553486</td>\n",
       "      <td>0.219591</td>\n",
       "      <td>0.238168</td>\n",
       "      <td>0.351369</td>\n",
       "      <td>0.420581</td>\n",
       "      <td>0.314667</td>\n",
       "      <td>0.299010</td>\n",
       "      <td>0.384040</td>\n",
       "      <td>0.046334</td>\n",
       "      <td>0.423867</td>\n",
       "      <td>0.034001</td>\n",
       "      <td>0.785096</td>\n",
       "      <td>0.617529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>113</td>\n",
       "      <td>0.612099</td>\n",
       "      <td>0.532061</td>\n",
       "      <td>0.626859</td>\n",
       "      <td>0.426512</td>\n",
       "      <td>0.275775</td>\n",
       "      <td>0.313510</td>\n",
       "      <td>0.195125</td>\n",
       "      <td>0.141763</td>\n",
       "      <td>0.152961</td>\n",
       "      <td>0.183291</td>\n",
       "      <td>0.275102</td>\n",
       "      <td>0.290907</td>\n",
       "      <td>0.404205</td>\n",
       "      <td>0.191204</td>\n",
       "      <td>0.588611</td>\n",
       "      <td>0.585009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>114</td>\n",
       "      <td>0.575619</td>\n",
       "      <td>0.795625</td>\n",
       "      <td>0.650421</td>\n",
       "      <td>0.761265</td>\n",
       "      <td>0.436652</td>\n",
       "      <td>0.594901</td>\n",
       "      <td>0.315597</td>\n",
       "      <td>0.555625</td>\n",
       "      <td>0.319634</td>\n",
       "      <td>0.467583</td>\n",
       "      <td>0.527803</td>\n",
       "      <td>0.494577</td>\n",
       "      <td>0.857290</td>\n",
       "      <td>0.596091</td>\n",
       "      <td>0.777156</td>\n",
       "      <td>0.949461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>115</td>\n",
       "      <td>0.810008</td>\n",
       "      <td>0.671938</td>\n",
       "      <td>0.747981</td>\n",
       "      <td>0.816781</td>\n",
       "      <td>0.552512</td>\n",
       "      <td>0.532942</td>\n",
       "      <td>0.352746</td>\n",
       "      <td>0.705609</td>\n",
       "      <td>0.397548</td>\n",
       "      <td>0.629707</td>\n",
       "      <td>0.445639</td>\n",
       "      <td>0.757071</td>\n",
       "      <td>0.757171</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>1.123696</td>\n",
       "      <td>1.312572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>117</td>\n",
       "      <td>0.739961</td>\n",
       "      <td>0.999593</td>\n",
       "      <td>1.117845</td>\n",
       "      <td>1.141733</td>\n",
       "      <td>0.665900</td>\n",
       "      <td>0.560048</td>\n",
       "      <td>0.779205</td>\n",
       "      <td>0.833558</td>\n",
       "      <td>0.721869</td>\n",
       "      <td>0.851695</td>\n",
       "      <td>0.776175</td>\n",
       "      <td>0.950963</td>\n",
       "      <td>0.822763</td>\n",
       "      <td>0.705167</td>\n",
       "      <td>0.739716</td>\n",
       "      <td>1.201082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>118</td>\n",
       "      <td>0.615284</td>\n",
       "      <td>0.646775</td>\n",
       "      <td>0.579507</td>\n",
       "      <td>0.647748</td>\n",
       "      <td>0.380463</td>\n",
       "      <td>0.344093</td>\n",
       "      <td>0.348013</td>\n",
       "      <td>0.419008</td>\n",
       "      <td>0.168523</td>\n",
       "      <td>0.317253</td>\n",
       "      <td>0.109183</td>\n",
       "      <td>0.448409</td>\n",
       "      <td>0.521629</td>\n",
       "      <td>0.375348</td>\n",
       "      <td>0.498061</td>\n",
       "      <td>0.804563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>119</td>\n",
       "      <td>0.721871</td>\n",
       "      <td>1.236386</td>\n",
       "      <td>1.068366</td>\n",
       "      <td>1.440720</td>\n",
       "      <td>0.582050</td>\n",
       "      <td>0.661441</td>\n",
       "      <td>0.649517</td>\n",
       "      <td>0.929910</td>\n",
       "      <td>0.720451</td>\n",
       "      <td>1.109664</td>\n",
       "      <td>0.807548</td>\n",
       "      <td>0.797290</td>\n",
       "      <td>0.629928</td>\n",
       "      <td>1.146660</td>\n",
       "      <td>0.350061</td>\n",
       "      <td>0.536086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>120</td>\n",
       "      <td>0.716374</td>\n",
       "      <td>0.439354</td>\n",
       "      <td>0.688931</td>\n",
       "      <td>0.999021</td>\n",
       "      <td>0.273544</td>\n",
       "      <td>0.172345</td>\n",
       "      <td>0.249393</td>\n",
       "      <td>0.365369</td>\n",
       "      <td>0.359178</td>\n",
       "      <td>0.357185</td>\n",
       "      <td>0.456155</td>\n",
       "      <td>0.458505</td>\n",
       "      <td>0.539596</td>\n",
       "      <td>0.376920</td>\n",
       "      <td>0.394951</td>\n",
       "      <td>0.498328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>121</td>\n",
       "      <td>0.929147</td>\n",
       "      <td>0.996385</td>\n",
       "      <td>0.902380</td>\n",
       "      <td>1.049132</td>\n",
       "      <td>0.161368</td>\n",
       "      <td>0.287373</td>\n",
       "      <td>0.316380</td>\n",
       "      <td>0.549026</td>\n",
       "      <td>0.363180</td>\n",
       "      <td>0.516536</td>\n",
       "      <td>0.266123</td>\n",
       "      <td>0.421493</td>\n",
       "      <td>0.594942</td>\n",
       "      <td>0.495365</td>\n",
       "      <td>1.126754</td>\n",
       "      <td>0.992477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>122</td>\n",
       "      <td>0.627642</td>\n",
       "      <td>0.714657</td>\n",
       "      <td>0.569680</td>\n",
       "      <td>0.774805</td>\n",
       "      <td>0.469744</td>\n",
       "      <td>0.478004</td>\n",
       "      <td>0.306467</td>\n",
       "      <td>0.437440</td>\n",
       "      <td>0.327306</td>\n",
       "      <td>0.460400</td>\n",
       "      <td>0.255857</td>\n",
       "      <td>0.391510</td>\n",
       "      <td>0.475763</td>\n",
       "      <td>0.229644</td>\n",
       "      <td>0.601381</td>\n",
       "      <td>0.805003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subID  L_SMA_L_post_putamen  R_SMA_R_post_putamen  \\\n",
       "0    101              0.851216              0.998780   \n",
       "1    102              0.772718              0.758162   \n",
       "2    103              0.781996              1.040435   \n",
       "3    104              0.695729              0.617592   \n",
       "4    105              0.470272              0.393517   \n",
       "5    106              0.601170              0.641163   \n",
       "6    107              0.837320              0.723076   \n",
       "7    108              0.803382              0.986233   \n",
       "8    109              0.658739              0.711127   \n",
       "9    110              0.909104              0.886818   \n",
       "10   111              0.792521              0.947742   \n",
       "11   112              0.305741              0.443099   \n",
       "12   113              0.612099              0.532061   \n",
       "13   114              0.575619              0.795625   \n",
       "14   115              0.810008              0.671938   \n",
       "15   117              0.739961              0.999593   \n",
       "16   118              0.615284              0.646775   \n",
       "17   119              0.721871              1.236386   \n",
       "18   120              0.716374              0.439354   \n",
       "19   121              0.929147              0.996385   \n",
       "20   122              0.627642              0.714657   \n",
       "\n",
       "    L_premotor_L_post_putamen  R_premotor_R_post_putamen  \\\n",
       "0                    0.758278                   1.088896   \n",
       "1                    0.784233                   0.910795   \n",
       "2                    0.862373                   1.010847   \n",
       "3                    0.520520                   0.608107   \n",
       "4                    0.472918                   0.488532   \n",
       "5                    0.634044                   0.390154   \n",
       "6                    0.920463                   0.804596   \n",
       "7                    0.938801                   1.088190   \n",
       "8                    0.623994                   0.872866   \n",
       "9                    0.843693                   1.112190   \n",
       "10                   1.002349                   1.316475   \n",
       "11                   0.355037                   0.553486   \n",
       "12                   0.626859                   0.426512   \n",
       "13                   0.650421                   0.761265   \n",
       "14                   0.747981                   0.816781   \n",
       "15                   1.117845                   1.141733   \n",
       "16                   0.579507                   0.647748   \n",
       "17                   1.068366                   1.440720   \n",
       "18                   0.688931                   0.999021   \n",
       "19                   0.902380                   1.049132   \n",
       "20                   0.569680                   0.774805   \n",
       "\n",
       "    L_anterior_caudate_vmpfc  R_anterior_caudate_vmpfc  \\\n",
       "0                   0.160140                  0.171255   \n",
       "1                   0.497427                  0.386723   \n",
       "2                   0.816637                  0.841093   \n",
       "3                   0.232703                  0.166782   \n",
       "4                   0.421866                  0.347436   \n",
       "5                   0.388621                  0.386643   \n",
       "6                   0.262284                  0.337655   \n",
       "7                   0.876531                  1.093217   \n",
       "8                   0.323784                  0.330265   \n",
       "9                   0.558206                  0.681099   \n",
       "10                  0.662288                  0.665931   \n",
       "11                  0.219591                  0.238168   \n",
       "12                  0.275775                  0.313510   \n",
       "13                  0.436652                  0.594901   \n",
       "14                  0.552512                  0.532942   \n",
       "15                  0.665900                  0.560048   \n",
       "16                  0.380463                  0.344093   \n",
       "17                  0.582050                  0.661441   \n",
       "18                  0.273544                  0.172345   \n",
       "19                  0.161368                  0.287373   \n",
       "20                  0.469744                  0.478004   \n",
       "\n",
       "    L_vlpfc_L_post_putamen  R_vlpfc_R_post_putamen  \\\n",
       "0                 0.186758                0.724928   \n",
       "1                 0.470668                0.485592   \n",
       "2                 0.652561                0.572853   \n",
       "3                 0.179454                0.510091   \n",
       "4                 0.374574                0.505057   \n",
       "5                 0.612639                0.268618   \n",
       "6                 0.245266                0.110878   \n",
       "7                 0.438439                0.905003   \n",
       "8                 0.374150                0.621026   \n",
       "9                 0.399795                0.813282   \n",
       "10                0.759795                0.893801   \n",
       "11                0.351369                0.420581   \n",
       "12                0.195125                0.141763   \n",
       "13                0.315597                0.555625   \n",
       "14                0.352746                0.705609   \n",
       "15                0.779205                0.833558   \n",
       "16                0.348013                0.419008   \n",
       "17                0.649517                0.929910   \n",
       "18                0.249393                0.365369   \n",
       "19                0.316380                0.549026   \n",
       "20                0.306467                0.437440   \n",
       "\n",
       "    L_vlpfc_L_anterior_putamen  R_vlpfc_R_anterior_putamen  \\\n",
       "0                     0.074329                    0.486687   \n",
       "1                     0.519491                    0.629122   \n",
       "2                     0.461742                    0.648554   \n",
       "3                     0.147228                    0.413492   \n",
       "4                     0.310996                    0.333324   \n",
       "5                     0.487770                    0.417695   \n",
       "6                     0.215483                   -0.051656   \n",
       "7                     0.444636                    0.862052   \n",
       "8                     0.313722                    0.540757   \n",
       "9                     0.383113                    0.647586   \n",
       "10                    0.783995                    0.714970   \n",
       "11                    0.314667                    0.299010   \n",
       "12                    0.152961                    0.183291   \n",
       "13                    0.319634                    0.467583   \n",
       "14                    0.397548                    0.629707   \n",
       "15                    0.721869                    0.851695   \n",
       "16                    0.168523                    0.317253   \n",
       "17                    0.720451                    1.109664   \n",
       "18                    0.359178                    0.357185   \n",
       "19                    0.363180                    0.516536   \n",
       "20                    0.327306                    0.460400   \n",
       "\n",
       "    L_vlpfc_L_anterior_caudate  R_vlpfc_R_anterior_caudate  \\\n",
       "0                     0.268736                    0.434427   \n",
       "1                     0.529293                    0.543271   \n",
       "2                     0.563616                    0.908927   \n",
       "3                     0.357026                    0.545893   \n",
       "4                     0.451271                    0.388881   \n",
       "5                     0.437910                    0.424911   \n",
       "6                     0.319452                    0.164916   \n",
       "7                     0.685624                    0.996331   \n",
       "8                     0.497184                    0.532202   \n",
       "9                     0.588102                    0.919163   \n",
       "10                    0.733279                    0.668187   \n",
       "11                    0.384040                    0.046334   \n",
       "12                    0.275102                    0.290907   \n",
       "13                    0.527803                    0.494577   \n",
       "14                    0.445639                    0.757071   \n",
       "15                    0.776175                    0.950963   \n",
       "16                    0.109183                    0.448409   \n",
       "17                    0.807548                    0.797290   \n",
       "18                    0.456155                    0.458505   \n",
       "19                    0.266123                    0.421493   \n",
       "20                    0.255857                    0.391510   \n",
       "\n",
       "    R_frontopolar_R_anterior_caudate  R_frontopolar_R_post_putamen  \\\n",
       "0                           0.509097                      0.601175   \n",
       "1                           0.492938                      0.224427   \n",
       "2                           0.787799                      0.647073   \n",
       "3                           0.495016                      0.348266   \n",
       "4                           0.339198                      0.322174   \n",
       "5                           0.619142                      0.244757   \n",
       "6                           0.639618                      0.357379   \n",
       "7                           0.950917                      0.696882   \n",
       "8                           0.450668                      0.499195   \n",
       "9                           0.660548                      0.634694   \n",
       "10                          0.876355                      0.651060   \n",
       "11                          0.423867                      0.034001   \n",
       "12                          0.404205                      0.191204   \n",
       "13                          0.857290                      0.596091   \n",
       "14                          0.757171                      0.449000   \n",
       "15                          0.822763                      0.705167   \n",
       "16                          0.521629                      0.375348   \n",
       "17                          0.629928                      1.146660   \n",
       "18                          0.539596                      0.376920   \n",
       "19                          0.594942                      0.495365   \n",
       "20                          0.475763                      0.229644   \n",
       "\n",
       "    R_post_putamen_L_post_putamen  R_anterior_caudate_L_anterior_caudate  \n",
       "0                        0.837498                               0.867571  \n",
       "1                        0.608410                               0.882937  \n",
       "2                        0.975670                               0.991395  \n",
       "3                        1.046327                               0.733302  \n",
       "4                        0.877251                               1.278251  \n",
       "5                        0.610082                               0.684291  \n",
       "6                        0.752838                               0.979017  \n",
       "7                        0.765659                               1.389258  \n",
       "8                        0.788206                               0.786762  \n",
       "9                        0.890801                               1.104343  \n",
       "10                       0.764056                               1.164051  \n",
       "11                       0.785096                               0.617529  \n",
       "12                       0.588611                               0.585009  \n",
       "13                       0.777156                               0.949461  \n",
       "14                       1.123696                               1.312572  \n",
       "15                       0.739716                               1.201082  \n",
       "16                       0.498061                               0.804563  \n",
       "17                       0.350061                               0.536086  \n",
       "18                       0.394951                               0.498328  \n",
       "19                       1.126754                               0.992477  \n",
       "20                       0.601381                               0.805003  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get sub dirs:\n",
    "IDCH_sub_dirs = [x for x in os.listdir(time_series_dir) if 'sub-' in x]\n",
    "# sort the sub dirs:\n",
    "IDCH_sub_dirs.sort()\n",
    "\n",
    "# List to collect data for DataFrame\n",
    "per_region_data = {}\n",
    "\n",
    "# Loop over the subject directories in the root directory\n",
    "for region_pair in connectivity_regions:\n",
    "    print(f\"Analyzing connectivity between {region_pair[0]} and {region_pair[1]}\")\n",
    "    region_df = []\n",
    "    for subj in IDCH_sub_dirs:\n",
    "        subject_dir = os.path.join(time_series_dir, subj)\n",
    "        sub_ID = subj.split('-')[1]\n",
    "        print(f\"Analyzing subject {sub_ID}\")\n",
    "\n",
    "        # Get the data for both regions:\n",
    "        reg1_dir = os.path.join(subject_dir, f'sub-{sub_ID}_IDCH_{region_pair[0]}_time_series.txt')\n",
    "        reg2_dir = os.path.join(subject_dir, f'sub-{sub_ID}_IDCH_{region_pair[1]}_time_series.txt')\n",
    "\n",
    "        reg1_ts_data = np.loadtxt(reg1_dir)\n",
    "        reg2_ts_data = np.loadtxt(reg2_dir)\n",
    "\n",
    "        # Calculate the Pearson correlation between the time series\n",
    "        correlation, p_val = pearsonr(reg1_ts_data, reg2_ts_data)\n",
    "        z_score = 0.5 * np.log((1 + correlation) / (1 - correlation))\n",
    "\n",
    "        # Print correlation for the subject:\n",
    "        print(f\">> Subject {sub_ID}: correlation between {region_pair[0]} and {region_pair[1]}: r={correlation}, p={p_val}, z-score={z_score}\")\n",
    "\n",
    "        # # Scatterplot\n",
    "        # fig, axs = plt.subplots(1, 2, figsize=(12, 5), sharey=False)\n",
    "        # axs[0].scatter(reg1_ts_data, reg2_ts_data)\n",
    "        # axs[0].set_title(f'Scatterplot for Subject {sub_ID}')\n",
    "        # axs[0].set_xlabel(region_pair[0])\n",
    "        # axs[0].set_ylabel(region_pair[1])\n",
    "        # # Line Plot for the Time-Series Data\n",
    "        # axs[1].plot(reg1_ts_data, color='red', label=region_pair[0])\n",
    "        # axs[1].plot(reg2_ts_data, color='blue', label=region_pair[1])\n",
    "        # axs[1].set_title(f'Time Series for Subject {sub_ID}')\n",
    "        # axs[1].set_xlabel('Time')\n",
    "        # axs[1].set_ylabel('BOLD Signal')\n",
    "        # axs[1].legend()\n",
    "        # plt.show()\n",
    "\n",
    "        #Append the data to list (with means)\n",
    "        region_df.append({\"subID\": sub_ID, \"corr\": correlation, \"p_val\": p_val, \"z_score\": z_score})\n",
    "\n",
    "    # keep data\n",
    "    region_connectivity_df = pd.DataFrame(region_df)\n",
    "    per_region_data[region_pair[0] + \"_\" + region_pair[1]] = region_connectivity_df\n",
    "\n",
    "    # save region_connectivity_df to csv\n",
    "    region_connectivity_df.to_csv(f'{connectiviity_data_dir}/{region_pair[0]}_{region_pair[1]}_connectivity.csv', index=False)\n",
    "\n",
    "    # # Plot the histogram of the Z-scores\n",
    "    # plt.hist(region_connectivity_df.z_score, alpha=0.6, color='g')\n",
    "    # plt.title(\"Histogram of Z-scores\")\n",
    "    # plt.show()\n",
    "\n",
    "    # display(region_connectivity_df)\n",
    "\n",
    "\n",
    "# create a data frame that has only the connectivity score (z-score) for each region pair (and the subject ID):\\\n",
    "connectivity_df = pd.DataFrame(columns=['subID'])\n",
    "for key in per_region_data.keys():\n",
    "    connectivity_score = per_region_data[key][['subID', 'z_score']]\n",
    "    connectivity_score = connectivity_score.rename(columns={'z_score': key})\n",
    "    connectivity_df = pd.merge(connectivity_df, connectivity_score, on='subID', how='outer')\n",
    "# save the connectivity_df to csv\n",
    "connectivity_df.to_csv(f'{connectiviity_data_dir}/all_connectivity_scores.csv', index=False)\n",
    "display(connectivity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L_SMA_L_post_putamen</th>\n",
       "      <th>R_SMA_R_post_putamen</th>\n",
       "      <th>L_premotor_L_post_putamen</th>\n",
       "      <th>R_premotor_R_post_putamen</th>\n",
       "      <th>L_anterior_caudate_vmpfc</th>\n",
       "      <th>R_anterior_caudate_vmpfc</th>\n",
       "      <th>L_vlpfc_L_post_putamen</th>\n",
       "      <th>R_vlpfc_R_post_putamen</th>\n",
       "      <th>L_vlpfc_L_anterior_putamen</th>\n",
       "      <th>R_vlpfc_R_anterior_putamen</th>\n",
       "      <th>L_vlpfc_L_anterior_caudate</th>\n",
       "      <th>R_vlpfc_R_anterior_caudate</th>\n",
       "      <th>R_frontopolar_R_anterior_caudate</th>\n",
       "      <th>R_frontopolar_R_post_putamen</th>\n",
       "      <th>R_post_putamen_L_post_putamen</th>\n",
       "      <th>R_anterior_caudate_L_anterior_caudate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.706091</td>\n",
       "      <td>0.770501</td>\n",
       "      <td>0.746127</td>\n",
       "      <td>0.871564</td>\n",
       "      <td>0.438956</td>\n",
       "      <td>0.456711</td>\n",
       "      <td>0.407520</td>\n",
       "      <td>0.560429</td>\n",
       "      <td>0.380373</td>\n",
       "      <td>0.515948</td>\n",
       "      <td>0.463577</td>\n",
       "      <td>0.551627</td>\n",
       "      <td>0.611831</td>\n",
       "      <td>0.467928</td>\n",
       "      <td>0.757251</td>\n",
       "      <td>0.912538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.148019</td>\n",
       "      <td>0.226677</td>\n",
       "      <td>0.201959</td>\n",
       "      <td>0.286521</td>\n",
       "      <td>0.204649</td>\n",
       "      <td>0.238003</td>\n",
       "      <td>0.182207</td>\n",
       "      <td>0.237012</td>\n",
       "      <td>0.191017</td>\n",
       "      <td>0.253995</td>\n",
       "      <td>0.186282</td>\n",
       "      <td>0.257961</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.244384</td>\n",
       "      <td>0.212618</td>\n",
       "      <td>0.260431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.305741</td>\n",
       "      <td>0.393517</td>\n",
       "      <td>0.355037</td>\n",
       "      <td>0.390154</td>\n",
       "      <td>0.160140</td>\n",
       "      <td>0.166782</td>\n",
       "      <td>0.179454</td>\n",
       "      <td>0.110878</td>\n",
       "      <td>0.074329</td>\n",
       "      <td>-0.051656</td>\n",
       "      <td>0.109183</td>\n",
       "      <td>0.046334</td>\n",
       "      <td>0.339198</td>\n",
       "      <td>0.034001</td>\n",
       "      <td>0.350061</td>\n",
       "      <td>0.498328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.615284</td>\n",
       "      <td>0.641163</td>\n",
       "      <td>0.623994</td>\n",
       "      <td>0.647748</td>\n",
       "      <td>0.273544</td>\n",
       "      <td>0.313510</td>\n",
       "      <td>0.306467</td>\n",
       "      <td>0.420581</td>\n",
       "      <td>0.310996</td>\n",
       "      <td>0.357185</td>\n",
       "      <td>0.319452</td>\n",
       "      <td>0.421493</td>\n",
       "      <td>0.492938</td>\n",
       "      <td>0.322174</td>\n",
       "      <td>0.608410</td>\n",
       "      <td>0.733302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.721871</td>\n",
       "      <td>0.723076</td>\n",
       "      <td>0.747981</td>\n",
       "      <td>0.872866</td>\n",
       "      <td>0.421866</td>\n",
       "      <td>0.386643</td>\n",
       "      <td>0.352746</td>\n",
       "      <td>0.549026</td>\n",
       "      <td>0.359178</td>\n",
       "      <td>0.486687</td>\n",
       "      <td>0.451271</td>\n",
       "      <td>0.494577</td>\n",
       "      <td>0.594942</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>0.765659</td>\n",
       "      <td>0.882937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.803382</td>\n",
       "      <td>0.986233</td>\n",
       "      <td>0.902380</td>\n",
       "      <td>1.088190</td>\n",
       "      <td>0.558206</td>\n",
       "      <td>0.594901</td>\n",
       "      <td>0.470668</td>\n",
       "      <td>0.724928</td>\n",
       "      <td>0.461742</td>\n",
       "      <td>0.647586</td>\n",
       "      <td>0.563616</td>\n",
       "      <td>0.757071</td>\n",
       "      <td>0.757171</td>\n",
       "      <td>0.634694</td>\n",
       "      <td>0.877251</td>\n",
       "      <td>1.104343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.929147</td>\n",
       "      <td>1.236386</td>\n",
       "      <td>1.117845</td>\n",
       "      <td>1.440720</td>\n",
       "      <td>0.876531</td>\n",
       "      <td>1.093217</td>\n",
       "      <td>0.779205</td>\n",
       "      <td>0.929910</td>\n",
       "      <td>0.783995</td>\n",
       "      <td>1.109664</td>\n",
       "      <td>0.807548</td>\n",
       "      <td>0.996331</td>\n",
       "      <td>0.950917</td>\n",
       "      <td>1.146660</td>\n",
       "      <td>1.126754</td>\n",
       "      <td>1.389258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       L_SMA_L_post_putamen  R_SMA_R_post_putamen  L_premotor_L_post_putamen  \\\n",
       "count             21.000000             21.000000                  21.000000   \n",
       "mean               0.706091              0.770501                   0.746127   \n",
       "std                0.148019              0.226677                   0.201959   \n",
       "min                0.305741              0.393517                   0.355037   \n",
       "25%                0.615284              0.641163                   0.623994   \n",
       "50%                0.721871              0.723076                   0.747981   \n",
       "75%                0.803382              0.986233                   0.902380   \n",
       "max                0.929147              1.236386                   1.117845   \n",
       "\n",
       "       R_premotor_R_post_putamen  L_anterior_caudate_vmpfc  \\\n",
       "count                  21.000000                 21.000000   \n",
       "mean                    0.871564                  0.438956   \n",
       "std                     0.286521                  0.204649   \n",
       "min                     0.390154                  0.160140   \n",
       "25%                     0.647748                  0.273544   \n",
       "50%                     0.872866                  0.421866   \n",
       "75%                     1.088190                  0.558206   \n",
       "max                     1.440720                  0.876531   \n",
       "\n",
       "       R_anterior_caudate_vmpfc  L_vlpfc_L_post_putamen  \\\n",
       "count                 21.000000               21.000000   \n",
       "mean                   0.456711                0.407520   \n",
       "std                    0.238003                0.182207   \n",
       "min                    0.166782                0.179454   \n",
       "25%                    0.313510                0.306467   \n",
       "50%                    0.386643                0.352746   \n",
       "75%                    0.594901                0.470668   \n",
       "max                    1.093217                0.779205   \n",
       "\n",
       "       R_vlpfc_R_post_putamen  L_vlpfc_L_anterior_putamen  \\\n",
       "count               21.000000                   21.000000   \n",
       "mean                 0.560429                    0.380373   \n",
       "std                  0.237012                    0.191017   \n",
       "min                  0.110878                    0.074329   \n",
       "25%                  0.420581                    0.310996   \n",
       "50%                  0.549026                    0.359178   \n",
       "75%                  0.724928                    0.461742   \n",
       "max                  0.929910                    0.783995   \n",
       "\n",
       "       R_vlpfc_R_anterior_putamen  L_vlpfc_L_anterior_caudate  \\\n",
       "count                   21.000000                   21.000000   \n",
       "mean                     0.515948                    0.463577   \n",
       "std                      0.253995                    0.186282   \n",
       "min                     -0.051656                    0.109183   \n",
       "25%                      0.357185                    0.319452   \n",
       "50%                      0.486687                    0.451271   \n",
       "75%                      0.647586                    0.563616   \n",
       "max                      1.109664                    0.807548   \n",
       "\n",
       "       R_vlpfc_R_anterior_caudate  R_frontopolar_R_anterior_caudate  \\\n",
       "count                   21.000000                         21.000000   \n",
       "mean                     0.551627                          0.611831   \n",
       "std                      0.257961                          0.172415   \n",
       "min                      0.046334                          0.339198   \n",
       "25%                      0.421493                          0.492938   \n",
       "50%                      0.494577                          0.594942   \n",
       "75%                      0.757071                          0.757171   \n",
       "max                      0.996331                          0.950917   \n",
       "\n",
       "       R_frontopolar_R_post_putamen  R_post_putamen_L_post_putamen  \\\n",
       "count                     21.000000                      21.000000   \n",
       "mean                       0.467928                       0.757251   \n",
       "std                        0.244384                       0.212618   \n",
       "min                        0.034001                       0.350061   \n",
       "25%                        0.322174                       0.608410   \n",
       "50%                        0.449000                       0.765659   \n",
       "75%                        0.634694                       0.877251   \n",
       "max                        1.146660                       1.126754   \n",
       "\n",
       "       R_anterior_caudate_L_anterior_caudate  \n",
       "count                              21.000000  \n",
       "mean                                0.912538  \n",
       "std                                 0.260431  \n",
       "min                                 0.498328  \n",
       "25%                                 0.733302  \n",
       "50%                                 0.882937  \n",
       "75%                                 1.104343  \n",
       "max                                 1.389258  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show summary:\n",
    "connectivity_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
